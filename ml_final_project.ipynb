{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPwoqZ12/XH4+hD8rvPZKlB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/b08202011/Mlproject/blob/main/ml_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1lpwTva7SEtLRNwpBbYKZLoHDoeG7FTxp\n",
        "!gdown 15MfSdxpfkHQi_Z0qdJIdrdPzLrSfbX1E\n",
        "!gdown 187gijxd4T5yuZe_g2K9UNepx7MT1CnAu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2klC1qgz2Oi2",
        "outputId": "f73f1507-d834-4c0d-a5cf-2e610971b47e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lpwTva7SEtLRNwpBbYKZLoHDoeG7FTxp\n",
            "To: /content/train.csv\n",
            "100% 23.3M/23.3M [00:00<00:00, 99.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15MfSdxpfkHQi_Z0qdJIdrdPzLrSfbX1E\n",
            "To: /content/test.csv\n",
            "100% 8.88M/8.88M [00:00<00:00, 92.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=187gijxd4T5yuZe_g2K9UNepx7MT1CnAu\n",
            "To: /content/sample_submission.csv\n",
            "100% 50.5k/50.5k [00:00<00:00, 72.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "10JsWM_brgQw"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "with open('train.csv',newline='') as csvfile:\n",
        "  train = csv.reader(csvfile)\n",
        "  train = list(train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pick = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,23]\n",
        "#可以選要用那些特徵，0是我們要predict的\n",
        "#只選數值或true fale 但且沒有選id\n",
        "feature = []\n",
        "for i in range(1,len(train)):\n",
        "  feature.append([])\n",
        "  for j in pick:\n",
        "    feature[i-1].append(train[i][j])\n",
        "\n",
        "for i in range(len(feature)):\n",
        "  for j in range(len(feature[i])):\n",
        "    if(feature[i][j]!='' and feature[i][j]!='False' and feature[i][j]!= 'True'):\n",
        "      feature[i][j] = float(feature[i][j])\n",
        "    elif(feature[i][j] == 'False'):\n",
        "      feature[i][j] = 0\n",
        "    elif(feature[i][j] == 'True'):\n",
        "      feature[i][j] = 1\n",
        "    else:\n",
        "      feature[i][j] = np.nan\n",
        "print(len(feature))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DscDJdCVr0kH",
        "outputId": "629e1226-356a-4325-9bca-dedfc3d3cd01"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ycimpute"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFwj7Vtjr7C3",
        "outputId": "3941a968-76f0-4ece-b9a6-699eda9a923c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ycimpute in /usr/local/lib/python3.10/dist-packages (0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ycimpute) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from ycimpute) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ycimpute) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from ycimpute) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from ycimpute) (2.0.0+cu118)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->ycimpute) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->ycimpute) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->ycimpute) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->ycimpute) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->ycimpute) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->ycimpute) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->ycimpute) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->ycimpute) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1.0->ycimpute) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1.0->ycimpute) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->ycimpute) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->ycimpute) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature = np.array(feature)\n",
        "from ycimpute.imputer import knnimput\n",
        "feature = knnimput.KNN(k=4).complete(feature) \n",
        "#imp_median.fit(feature)\n",
        "#feature = imp_median.transform(feature)\n",
        "##可以修改這裡 使用不同的data填補方式"
      ],
      "metadata": {
        "id": "RpQkUiqtr-VA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10a6203-8986-4eb7-e693-c02f6013eb23"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputing row 1/17170 with 1 missing, elapsed time: 79.668\n",
            "Imputing row 101/17170 with 1 missing, elapsed time: 79.693\n",
            "Imputing row 201/17170 with 0 missing, elapsed time: 79.720\n",
            "Imputing row 301/17170 with 2 missing, elapsed time: 79.743\n",
            "Imputing row 401/17170 with 1 missing, elapsed time: 79.764\n",
            "Imputing row 501/17170 with 1 missing, elapsed time: 79.784\n",
            "Imputing row 601/17170 with 4 missing, elapsed time: 79.807\n",
            "Imputing row 701/17170 with 2 missing, elapsed time: 79.830\n",
            "Imputing row 801/17170 with 2 missing, elapsed time: 79.854\n",
            "Imputing row 901/17170 with 3 missing, elapsed time: 79.882\n",
            "Imputing row 1001/17170 with 0 missing, elapsed time: 79.906\n",
            "Imputing row 1101/17170 with 0 missing, elapsed time: 79.927\n",
            "Imputing row 1201/17170 with 2 missing, elapsed time: 79.949\n",
            "Imputing row 1301/17170 with 3 missing, elapsed time: 79.971\n",
            "Imputing row 1401/17170 with 3 missing, elapsed time: 79.991\n",
            "Imputing row 1501/17170 with 3 missing, elapsed time: 80.013\n",
            "Imputing row 1601/17170 with 3 missing, elapsed time: 80.033\n",
            "Imputing row 1701/17170 with 1 missing, elapsed time: 80.055\n",
            "Imputing row 1801/17170 with 2 missing, elapsed time: 80.074\n",
            "Imputing row 1901/17170 with 0 missing, elapsed time: 80.098\n",
            "Imputing row 2001/17170 with 1 missing, elapsed time: 80.120\n",
            "Imputing row 2101/17170 with 6 missing, elapsed time: 80.142\n",
            "Imputing row 2201/17170 with 4 missing, elapsed time: 80.165\n",
            "Imputing row 2301/17170 with 2 missing, elapsed time: 80.187\n",
            "Imputing row 2401/17170 with 4 missing, elapsed time: 80.211\n",
            "Imputing row 2501/17170 with 2 missing, elapsed time: 80.232\n",
            "Imputing row 2601/17170 with 1 missing, elapsed time: 80.254\n",
            "Imputing row 2701/17170 with 1 missing, elapsed time: 80.275\n",
            "Imputing row 2801/17170 with 2 missing, elapsed time: 80.301\n",
            "Imputing row 2901/17170 with 0 missing, elapsed time: 80.328\n",
            "Imputing row 3001/17170 with 3 missing, elapsed time: 80.354\n",
            "Imputing row 3101/17170 with 1 missing, elapsed time: 80.378\n",
            "Imputing row 3201/17170 with 3 missing, elapsed time: 80.401\n",
            "Imputing row 3301/17170 with 4 missing, elapsed time: 80.424\n",
            "Imputing row 3401/17170 with 5 missing, elapsed time: 80.448\n",
            "Imputing row 3501/17170 with 1 missing, elapsed time: 80.473\n",
            "Imputing row 3601/17170 with 5 missing, elapsed time: 80.494\n",
            "Imputing row 3701/17170 with 3 missing, elapsed time: 80.518\n",
            "Imputing row 3801/17170 with 2 missing, elapsed time: 80.539\n",
            "Imputing row 3901/17170 with 4 missing, elapsed time: 80.559\n",
            "Imputing row 4001/17170 with 2 missing, elapsed time: 80.581\n",
            "Imputing row 4101/17170 with 2 missing, elapsed time: 80.603\n",
            "Imputing row 4201/17170 with 2 missing, elapsed time: 80.624\n",
            "Imputing row 4301/17170 with 2 missing, elapsed time: 80.646\n",
            "Imputing row 4401/17170 with 1 missing, elapsed time: 80.667\n",
            "Imputing row 4501/17170 with 2 missing, elapsed time: 80.690\n",
            "Imputing row 4601/17170 with 4 missing, elapsed time: 80.713\n",
            "Imputing row 4701/17170 with 2 missing, elapsed time: 80.740\n",
            "Imputing row 4801/17170 with 2 missing, elapsed time: 80.762\n",
            "Imputing row 4901/17170 with 3 missing, elapsed time: 80.783\n",
            "Imputing row 5001/17170 with 3 missing, elapsed time: 80.805\n",
            "Imputing row 5101/17170 with 3 missing, elapsed time: 80.829\n",
            "Imputing row 5201/17170 with 3 missing, elapsed time: 80.851\n",
            "Imputing row 5301/17170 with 2 missing, elapsed time: 80.876\n",
            "Imputing row 5401/17170 with 4 missing, elapsed time: 80.897\n",
            "Imputing row 5501/17170 with 4 missing, elapsed time: 80.921\n",
            "Imputing row 5601/17170 with 2 missing, elapsed time: 80.945\n",
            "Imputing row 5701/17170 with 2 missing, elapsed time: 80.969\n",
            "Imputing row 5801/17170 with 3 missing, elapsed time: 80.992\n",
            "Imputing row 5901/17170 with 2 missing, elapsed time: 81.014\n",
            "Imputing row 6001/17170 with 3 missing, elapsed time: 81.035\n",
            "Imputing row 6101/17170 with 2 missing, elapsed time: 81.057\n",
            "Imputing row 6201/17170 with 4 missing, elapsed time: 81.080\n",
            "Imputing row 6301/17170 with 1 missing, elapsed time: 81.102\n",
            "Imputing row 6401/17170 with 3 missing, elapsed time: 81.124\n",
            "Imputing row 6501/17170 with 1 missing, elapsed time: 81.145\n",
            "Imputing row 6601/17170 with 3 missing, elapsed time: 81.173\n",
            "Imputing row 6701/17170 with 2 missing, elapsed time: 81.195\n",
            "Imputing row 6801/17170 with 1 missing, elapsed time: 81.214\n",
            "Imputing row 6901/17170 with 3 missing, elapsed time: 81.237\n",
            "Imputing row 7001/17170 with 1 missing, elapsed time: 81.259\n",
            "Imputing row 7101/17170 with 2 missing, elapsed time: 81.281\n",
            "Imputing row 7201/17170 with 0 missing, elapsed time: 81.302\n",
            "Imputing row 7301/17170 with 2 missing, elapsed time: 81.325\n",
            "Imputing row 7401/17170 with 2 missing, elapsed time: 81.345\n",
            "Imputing row 7501/17170 with 2 missing, elapsed time: 81.368\n",
            "Imputing row 7601/17170 with 5 missing, elapsed time: 81.394\n",
            "Imputing row 7701/17170 with 2 missing, elapsed time: 81.416\n",
            "Imputing row 7801/17170 with 1 missing, elapsed time: 81.436\n",
            "Imputing row 7901/17170 with 1 missing, elapsed time: 81.460\n",
            "Imputing row 8001/17170 with 2 missing, elapsed time: 81.484\n",
            "Imputing row 8101/17170 with 4 missing, elapsed time: 81.506\n",
            "Imputing row 8201/17170 with 2 missing, elapsed time: 81.530\n",
            "Imputing row 8301/17170 with 3 missing, elapsed time: 81.552\n",
            "Imputing row 8401/17170 with 1 missing, elapsed time: 81.572\n",
            "Imputing row 8501/17170 with 2 missing, elapsed time: 81.592\n",
            "Imputing row 8601/17170 with 2 missing, elapsed time: 81.614\n",
            "Imputing row 8701/17170 with 4 missing, elapsed time: 81.634\n",
            "Imputing row 8801/17170 with 2 missing, elapsed time: 81.653\n",
            "Imputing row 8901/17170 with 4 missing, elapsed time: 81.676\n",
            "Imputing row 9001/17170 with 1 missing, elapsed time: 81.697\n",
            "Imputing row 9101/17170 with 1 missing, elapsed time: 81.719\n",
            "Imputing row 9201/17170 with 1 missing, elapsed time: 81.746\n",
            "Imputing row 9301/17170 with 5 missing, elapsed time: 81.767\n",
            "Imputing row 9401/17170 with 7 missing, elapsed time: 81.786\n",
            "Imputing row 9501/17170 with 0 missing, elapsed time: 81.805\n",
            "Imputing row 9601/17170 with 3 missing, elapsed time: 81.828\n",
            "Imputing row 9701/17170 with 3 missing, elapsed time: 81.848\n",
            "Imputing row 9801/17170 with 3 missing, elapsed time: 81.872\n",
            "Imputing row 9901/17170 with 1 missing, elapsed time: 81.891\n",
            "Imputing row 10001/17170 with 3 missing, elapsed time: 81.914\n",
            "Imputing row 10101/17170 with 3 missing, elapsed time: 81.935\n",
            "Imputing row 10201/17170 with 3 missing, elapsed time: 81.956\n",
            "Imputing row 10301/17170 with 1 missing, elapsed time: 81.980\n",
            "Imputing row 10401/17170 with 3 missing, elapsed time: 82.003\n",
            "Imputing row 10501/17170 with 4 missing, elapsed time: 82.028\n",
            "Imputing row 10601/17170 with 2 missing, elapsed time: 82.056\n",
            "Imputing row 10701/17170 with 1 missing, elapsed time: 82.079\n",
            "Imputing row 10801/17170 with 3 missing, elapsed time: 82.100\n",
            "Imputing row 10901/17170 with 1 missing, elapsed time: 82.121\n",
            "Imputing row 11001/17170 with 3 missing, elapsed time: 82.142\n",
            "Imputing row 11101/17170 with 3 missing, elapsed time: 82.165\n",
            "Imputing row 11201/17170 with 2 missing, elapsed time: 82.188\n",
            "Imputing row 11301/17170 with 1 missing, elapsed time: 82.210\n",
            "Imputing row 11401/17170 with 2 missing, elapsed time: 82.231\n",
            "Imputing row 11501/17170 with 2 missing, elapsed time: 82.250\n",
            "Imputing row 11601/17170 with 2 missing, elapsed time: 82.270\n",
            "Imputing row 11701/17170 with 1 missing, elapsed time: 82.294\n",
            "Imputing row 11801/17170 with 3 missing, elapsed time: 82.319\n",
            "Imputing row 11901/17170 with 2 missing, elapsed time: 82.341\n",
            "Imputing row 12001/17170 with 2 missing, elapsed time: 82.362\n",
            "Imputing row 12101/17170 with 1 missing, elapsed time: 82.386\n",
            "Imputing row 12201/17170 with 3 missing, elapsed time: 82.409\n",
            "Imputing row 12301/17170 with 3 missing, elapsed time: 82.435\n",
            "Imputing row 12401/17170 with 5 missing, elapsed time: 82.458\n",
            "Imputing row 12501/17170 with 2 missing, elapsed time: 82.483\n",
            "Imputing row 12601/17170 with 4 missing, elapsed time: 82.510\n",
            "Imputing row 12701/17170 with 2 missing, elapsed time: 82.532\n",
            "Imputing row 12801/17170 with 4 missing, elapsed time: 82.554\n",
            "Imputing row 12901/17170 with 2 missing, elapsed time: 82.574\n",
            "Imputing row 13001/17170 with 3 missing, elapsed time: 82.595\n",
            "Imputing row 13101/17170 with 2 missing, elapsed time: 82.619\n",
            "Imputing row 13201/17170 with 2 missing, elapsed time: 82.639\n",
            "Imputing row 13301/17170 with 1 missing, elapsed time: 82.661\n",
            "Imputing row 13401/17170 with 2 missing, elapsed time: 82.684\n",
            "Imputing row 13501/17170 with 3 missing, elapsed time: 82.707\n",
            "Imputing row 13601/17170 with 2 missing, elapsed time: 82.727\n",
            "Imputing row 13701/17170 with 3 missing, elapsed time: 82.755\n",
            "Imputing row 13801/17170 with 3 missing, elapsed time: 82.783\n",
            "Imputing row 13901/17170 with 1 missing, elapsed time: 82.809\n",
            "Imputing row 14001/17170 with 5 missing, elapsed time: 82.833\n",
            "Imputing row 14101/17170 with 1 missing, elapsed time: 82.854\n",
            "Imputing row 14201/17170 with 0 missing, elapsed time: 82.875\n",
            "Imputing row 14301/17170 with 2 missing, elapsed time: 82.895\n",
            "Imputing row 14401/17170 with 3 missing, elapsed time: 82.919\n",
            "Imputing row 14501/17170 with 1 missing, elapsed time: 82.940\n",
            "Imputing row 14601/17170 with 0 missing, elapsed time: 82.963\n",
            "Imputing row 14701/17170 with 1 missing, elapsed time: 82.983\n",
            "Imputing row 14801/17170 with 2 missing, elapsed time: 83.003\n",
            "Imputing row 14901/17170 with 3 missing, elapsed time: 83.025\n",
            "Imputing row 15001/17170 with 2 missing, elapsed time: 83.047\n",
            "Imputing row 15101/17170 with 1 missing, elapsed time: 83.069\n",
            "Imputing row 15201/17170 with 1 missing, elapsed time: 83.095\n",
            "Imputing row 15301/17170 with 3 missing, elapsed time: 83.117\n",
            "Imputing row 15401/17170 with 1 missing, elapsed time: 83.142\n",
            "Imputing row 15501/17170 with 2 missing, elapsed time: 83.166\n",
            "Imputing row 15601/17170 with 1 missing, elapsed time: 83.187\n",
            "Imputing row 15701/17170 with 3 missing, elapsed time: 83.210\n",
            "Imputing row 15801/17170 with 2 missing, elapsed time: 83.229\n",
            "Imputing row 15901/17170 with 2 missing, elapsed time: 83.252\n",
            "Imputing row 16001/17170 with 1 missing, elapsed time: 83.273\n",
            "Imputing row 16101/17170 with 2 missing, elapsed time: 83.293\n",
            "Imputing row 16201/17170 with 0 missing, elapsed time: 83.316\n",
            "Imputing row 16301/17170 with 1 missing, elapsed time: 83.338\n",
            "Imputing row 16401/17170 with 3 missing, elapsed time: 83.361\n",
            "Imputing row 16501/17170 with 1 missing, elapsed time: 83.381\n",
            "Imputing row 16601/17170 with 4 missing, elapsed time: 83.400\n",
            "Imputing row 16701/17170 with 3 missing, elapsed time: 83.424\n",
            "Imputing row 16801/17170 with 2 missing, elapsed time: 83.446\n",
            "Imputing row 16901/17170 with 4 missing, elapsed time: 83.468\n",
            "Imputing row 17001/17170 with 4 missing, elapsed time: 83.493\n",
            "Imputing row 17101/17170 with 6 missing, elapsed time: 83.517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical Operations\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# Reading/Writing Data\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "# For Progress Bar\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.feature_selection import f_regression\n",
        "# Pytorch\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.models.feature_extraction import get_graph_node_names\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNN\n",
        "from torchvision.models.detection.backbone_utils import LastLevelMaxPool\n",
        "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn import utils\n",
        "\n",
        "# For plotting learning curve\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "Q2bmK7mVsAmP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def same_seed(seed): \n",
        "    '''Fixes random number generator seeds for reproducibility.'''\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def train_valid_split(data_set, valid_ratio, seed):\n",
        "    '''Split provided training data into training set and validation set'''\n",
        "    valid_set_size = int(valid_ratio * len(data_set)) \n",
        "    train_set_size = len(data_set) - valid_set_size\n",
        "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
        "    return np.array(train_set), np.array(valid_set)\n",
        "\n",
        "def predict(test_loader, model, device):\n",
        "    model.eval() # Set your model to evaluation mode.\n",
        "    preds = []\n",
        "    for x in tqdm(test_loader):\n",
        "        x = x.to(device)                        \n",
        "        with torch.no_grad():                   \n",
        "            pred = torch.clamp(torch.round(model(x)),0,9)\n",
        "                          \n",
        "            preds.append(pred.detach().cpu())   \n",
        "    preds = torch.cat(preds, dim=0).numpy()  \n",
        "    return preds"
      ],
      "metadata": {
        "id": "EuIQ-7tKuocP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataloader"
      ],
      "metadata": {
        "id": "1D320CZu7nkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    '''\n",
        "    x: Features.\n",
        "    y: Targets, if none, do prediction.\n",
        "    '''\n",
        "    def __init__(self, x, y=None):\n",
        "        if y is None:\n",
        "            self.y = y\n",
        "        else:\n",
        "            self.y = torch.FloatTensor(y)\n",
        "        self.x = torch.FloatTensor(x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is None:\n",
        "            return self.x[idx]\n",
        "        else:\n",
        "            return self.x[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ],
      "metadata": {
        "id": "ypSQGM5i7q_g"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "_dFunF8QtoP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Model(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(My_Model, self).__init__()\n",
        "        # TODO: modify model's structure, be aware of dimensions. \n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(64, 16),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(16, 16),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(16, 16),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(16, 1),           \n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = x.view(-1, 16)\n",
        "        x = self.layers(x)\n",
        "        x = x.squeeze(-1) # (B, 1) -> (B)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zIkJ9iRauAy8"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "s9EXYkYmuQzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainer(train_data, model, config, device):\n",
        "\n",
        "    criterion = nn.HuberLoss() # Define your loss function, do not modify this.\n",
        "    #criterion = nn.L1Loss()\n",
        "\n",
        "    # Define your optimization algorithm. \n",
        "    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n",
        "    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr= config['learning_rate'] , weight_decay=0.01, amsgrad=False) \n",
        "    writer = SummaryWriter() # Writer of tensoboard.\n",
        "\n",
        "    if not os.path.isdir('./models'):\n",
        "        os.mkdir('./models') # Create directory of saving models.\n",
        "\n",
        "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
        "\n",
        "\n",
        "    np.random.seed(config['seed'])\n",
        "    splits = np.array_split(train_data, config['n_fold'])\n",
        "    \n",
        "    \n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "      lossvalid_record = []\n",
        "      loss_record = []\n",
        "      for i in range(config['n_fold']):\n",
        "        model.train() # Set your model to train mode.\n",
        "         \n",
        "        train =  np.concatenate(splits[:i]+splits[i+1:])\n",
        "        valid= splits[i]\n",
        "        x_train = train[...,1:]\n",
        "        x_valid = valid[...,1:]\n",
        "        y_train = train[...,0]\n",
        "        y_valid = valid[...,0]\n",
        "        train_dataset  = COVID19Dataset(x_train, y_train)\n",
        "        valid_dataset = COVID19Dataset(x_valid, y_valid)\n",
        "        \n",
        "        # Pytorch data loader loads pytorch dataset into batches.\n",
        "        train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "        valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            optimizer.zero_grad()               # Set gradient to zero.\n",
        "            x, y = x.to(device), y.to(device)   # Move your data to device. \n",
        "            pred = model(x)\n",
        "            \n",
        "            #loss = criterion(pred, y)\n",
        "                \n",
        "            loss = criterion(pred, y)+config['regulizer']*torch.mean(torch.abs(pred))\n",
        "            #print(loss)\n",
        "            loss.backward()                     # Compute gradient(backpropagation).\n",
        "            optimizer.step()                    # Update parameters.\n",
        "            step += 1\n",
        "            \n",
        "            loss_record.append(loss.detach().item())\n",
        "            \n",
        "        model.eval() # Set your model to evaluation mode.\n",
        "        \n",
        "        for x, y in valid_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = torch.clamp(torch.round(model(x)),0,9)\n",
        "                #loss = criterion(pred, y)\n",
        "                loss = criterion(pred, y)+config['regulizer']*torch.mean(torch.abs(pred))\n",
        "\n",
        "            lossvalid_record.append(loss.item())\n",
        "\n",
        "\n",
        "        \n",
        "      mean_train_loss = sum(loss_record)/len(loss_record)         ###compute CV loss\n",
        "      writer.add_scalar('Loss/train', mean_train_loss, step)\n",
        "\n",
        "      mean_valid_loss = sum(lossvalid_record)/len(lossvalid_record)\n",
        "      print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
        "      # writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
        "\n",
        "      if mean_valid_loss < best_loss:\n",
        "          best_loss = mean_valid_loss\n",
        "          torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
        "          print('Saving model with loss {:.3f}...'.format(best_loss))\n",
        "          early_stop_count = 0\n",
        "      else: \n",
        "          early_stop_count += 1\n",
        "\n",
        "      if early_stop_count >= config['early_stop']:\n",
        "          print('\\nModel is not improving, so we halt the training session.')\n",
        "          return"
      ],
      "metadata": {
        "id": "khMhvW1duO9l"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## config"
      ],
      "metadata": {
        "id": "K_Hg8aMlzaqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "config = {\n",
        "    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n",
        "    'select_all': True,   # Whether to use all features.\n",
        "    'n_fold': 5,   # validation_size = train_size * valid_ratio\n",
        "    'n_epochs': 30000,     # Number of epochs.            \n",
        "    'batch_size': 128, \n",
        "    'learning_rate': 1e-2,\n",
        "    'regulizer': 1e-3,              \n",
        "    'early_stop': 2000,    # If model has not improved for this many consecutive epochs, stop training.     \n",
        "    'save_path': './models/model.ckpt'  # Your model will be saved here.\n",
        "}\n"
      ],
      "metadata": {
        "id": "dB14dhABzVxO"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "same_seed(config['seed'])\n",
        "with open('test.csv',newline='') as csvfile:\n",
        "  testcsv = csv.reader(csvfile)\n",
        "  testcsv = list(testcsv)\n",
        "test = []\n",
        "pick = [0,1,2,3,4,5,6,7,8,9,10,11,12,14,15,22]\n",
        "\n",
        "for i in range(1,len(testcsv)):\n",
        "  test.append([])\n",
        "  for j in pick:\n",
        "    test[i-1].append(testcsv[i][j])\n",
        "for i in range(len(test)):\n",
        "  for j in range(len(test[i])):\n",
        "    if(test[i][j]!='' and test[i][j]!='False' and test[i][j]!= 'True'):\n",
        "      test[i][j] = float(test[i][j])\n",
        "    elif(test[i][j] == 'False'):\n",
        "      test[i][j] = 0\n",
        "    elif(test[i][j] == 'True'):\n",
        "      test[i][j] = 1\n",
        "    else:\n",
        "      test[i][j] = np.nan\n",
        "test_data = knnimput.KNN(k=4).complete(np.array(test))\n",
        "#imp_median.fit(test)\n",
        "#test_data = imp_median.transform(test)\n",
        "train_data= feature\n",
        "#train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n",
        "\n",
        "x_test =  test_data\n",
        "test_dataset = COVID19Dataset(x_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "DqtxFou74eQr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "376381f7-6b3b-4705-ecf9-3de9ae0f1241"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputing row 1/6315 with 1 missing, elapsed time: 11.839\n",
            "Imputing row 101/6315 with 2 missing, elapsed time: 11.865\n",
            "Imputing row 201/6315 with 3 missing, elapsed time: 11.881\n",
            "Imputing row 301/6315 with 2 missing, elapsed time: 11.898\n",
            "Imputing row 401/6315 with 4 missing, elapsed time: 11.931\n",
            "Imputing row 501/6315 with 1 missing, elapsed time: 11.969\n",
            "Imputing row 601/6315 with 1 missing, elapsed time: 12.012\n",
            "Imputing row 701/6315 with 2 missing, elapsed time: 12.032\n",
            "Imputing row 801/6315 with 3 missing, elapsed time: 12.054\n",
            "Imputing row 901/6315 with 0 missing, elapsed time: 12.073\n",
            "Imputing row 1001/6315 with 3 missing, elapsed time: 12.090\n",
            "Imputing row 1101/6315 with 1 missing, elapsed time: 12.107\n",
            "Imputing row 1201/6315 with 5 missing, elapsed time: 12.123\n",
            "Imputing row 1301/6315 with 3 missing, elapsed time: 12.141\n",
            "Imputing row 1401/6315 with 2 missing, elapsed time: 12.157\n",
            "Imputing row 1501/6315 with 1 missing, elapsed time: 12.178\n",
            "Imputing row 1601/6315 with 3 missing, elapsed time: 12.200\n",
            "Imputing row 1701/6315 with 1 missing, elapsed time: 12.230\n",
            "Imputing row 1801/6315 with 2 missing, elapsed time: 12.247\n",
            "Imputing row 1901/6315 with 2 missing, elapsed time: 12.272\n",
            "Imputing row 2001/6315 with 2 missing, elapsed time: 12.288\n",
            "Imputing row 2101/6315 with 3 missing, elapsed time: 12.306\n",
            "Imputing row 2201/6315 with 3 missing, elapsed time: 12.323\n",
            "Imputing row 2301/6315 with 4 missing, elapsed time: 12.341\n",
            "Imputing row 2401/6315 with 2 missing, elapsed time: 12.359\n",
            "Imputing row 2501/6315 with 2 missing, elapsed time: 12.376\n",
            "Imputing row 2601/6315 with 3 missing, elapsed time: 12.391\n",
            "Imputing row 2701/6315 with 3 missing, elapsed time: 12.408\n",
            "Imputing row 2801/6315 with 2 missing, elapsed time: 12.423\n",
            "Imputing row 2901/6315 with 1 missing, elapsed time: 12.438\n",
            "Imputing row 3001/6315 with 3 missing, elapsed time: 12.455\n",
            "Imputing row 3101/6315 with 2 missing, elapsed time: 12.474\n",
            "Imputing row 3201/6315 with 3 missing, elapsed time: 12.493\n",
            "Imputing row 3301/6315 with 3 missing, elapsed time: 12.513\n",
            "Imputing row 3401/6315 with 5 missing, elapsed time: 12.527\n",
            "Imputing row 3501/6315 with 3 missing, elapsed time: 12.553\n",
            "Imputing row 3601/6315 with 2 missing, elapsed time: 12.571\n",
            "Imputing row 3701/6315 with 1 missing, elapsed time: 12.588\n",
            "Imputing row 3801/6315 with 3 missing, elapsed time: 12.603\n",
            "Imputing row 3901/6315 with 3 missing, elapsed time: 12.620\n",
            "Imputing row 4001/6315 with 2 missing, elapsed time: 12.644\n",
            "Imputing row 4101/6315 with 2 missing, elapsed time: 12.665\n",
            "Imputing row 4201/6315 with 2 missing, elapsed time: 12.682\n",
            "Imputing row 4301/6315 with 2 missing, elapsed time: 12.697\n",
            "Imputing row 4401/6315 with 2 missing, elapsed time: 12.712\n",
            "Imputing row 4501/6315 with 3 missing, elapsed time: 12.731\n",
            "Imputing row 4601/6315 with 4 missing, elapsed time: 12.757\n",
            "Imputing row 4701/6315 with 5 missing, elapsed time: 12.790\n",
            "Imputing row 4801/6315 with 1 missing, elapsed time: 12.822\n",
            "Imputing row 4901/6315 with 4 missing, elapsed time: 12.855\n",
            "Imputing row 5001/6315 with 2 missing, elapsed time: 12.874\n",
            "Imputing row 5101/6315 with 3 missing, elapsed time: 12.915\n",
            "Imputing row 5201/6315 with 3 missing, elapsed time: 12.932\n",
            "Imputing row 5301/6315 with 2 missing, elapsed time: 12.950\n",
            "Imputing row 5401/6315 with 0 missing, elapsed time: 12.966\n",
            "Imputing row 5501/6315 with 6 missing, elapsed time: 12.981\n",
            "Imputing row 5601/6315 with 2 missing, elapsed time: 12.996\n",
            "Imputing row 5701/6315 with 3 missing, elapsed time: 13.026\n",
            "Imputing row 5801/6315 with 2 missing, elapsed time: 13.056\n",
            "Imputing row 5901/6315 with 4 missing, elapsed time: 13.073\n",
            "Imputing row 6001/6315 with 1 missing, elapsed time: 13.087\n",
            "Imputing row 6101/6315 with 2 missing, elapsed time: 13.110\n",
            "Imputing row 6201/6315 with 2 missing, elapsed time: 13.126\n",
            "Imputing row 6301/6315 with 1 missing, elapsed time: 13.142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and testing"
      ],
      "metadata": {
        "id": "u1zpP7hF1y18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "model = My_Model(input_dim=train_data.shape[1]-1).to(device) # put your model and data on the same computation device.\n",
        "trainer(train_data, model, config, device)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn82Vj0R06Yt",
        "outputId": "dc0dba00-c03f-496a-c1b1-e3f186e5ffdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30000]: Train loss: 2.0890, Valid loss: 2.0148\n",
            "Saving model with loss 2.015...\n",
            "Epoch [2/30000]: Train loss: 2.0149, Valid loss: 2.0290\n",
            "Epoch [3/30000]: Train loss: 2.0066, Valid loss: 2.0276\n",
            "Epoch [4/30000]: Train loss: 1.9949, Valid loss: 2.0228\n",
            "Epoch [5/30000]: Train loss: 1.9875, Valid loss: 2.0068\n",
            "Saving model with loss 2.007...\n",
            "Epoch [6/30000]: Train loss: 1.9825, Valid loss: 1.9979\n",
            "Saving model with loss 1.998...\n",
            "Epoch [7/30000]: Train loss: 1.9695, Valid loss: 2.0187\n",
            "Epoch [8/30000]: Train loss: 1.9698, Valid loss: 1.9868\n",
            "Saving model with loss 1.987...\n",
            "Epoch [9/30000]: Train loss: 1.9611, Valid loss: 1.9887\n",
            "Epoch [10/30000]: Train loss: 1.9601, Valid loss: 1.9845\n",
            "Saving model with loss 1.984...\n",
            "Epoch [11/30000]: Train loss: 1.9618, Valid loss: 1.9789\n",
            "Saving model with loss 1.979...\n",
            "Epoch [12/30000]: Train loss: 1.9547, Valid loss: 1.9727\n",
            "Saving model with loss 1.973...\n",
            "Epoch [13/30000]: Train loss: 1.9586, Valid loss: 1.9717\n",
            "Saving model with loss 1.972...\n",
            "Epoch [14/30000]: Train loss: 1.9497, Valid loss: 1.9670\n",
            "Saving model with loss 1.967...\n",
            "Epoch [15/30000]: Train loss: 1.9531, Valid loss: 1.9597\n",
            "Saving model with loss 1.960...\n",
            "Epoch [16/30000]: Train loss: 1.9560, Valid loss: 1.9711\n",
            "Epoch [17/30000]: Train loss: 1.9543, Valid loss: 1.9845\n",
            "Epoch [18/30000]: Train loss: 1.9510, Valid loss: 1.9810\n",
            "Epoch [19/30000]: Train loss: 1.9542, Valid loss: 1.9768\n",
            "Epoch [20/30000]: Train loss: 1.9523, Valid loss: 1.9638\n",
            "Epoch [21/30000]: Train loss: 1.9547, Valid loss: 2.0059\n",
            "Epoch [22/30000]: Train loss: 1.9550, Valid loss: 2.0006\n",
            "Epoch [23/30000]: Train loss: 1.9510, Valid loss: 1.9888\n",
            "Epoch [24/30000]: Train loss: 1.9511, Valid loss: 1.9858\n",
            "Epoch [25/30000]: Train loss: 1.9506, Valid loss: 1.9864\n",
            "Epoch [26/30000]: Train loss: 1.9532, Valid loss: 1.9750\n",
            "Epoch [27/30000]: Train loss: 1.9503, Valid loss: 1.9914\n",
            "Epoch [28/30000]: Train loss: 1.9541, Valid loss: 1.9696\n",
            "Epoch [29/30000]: Train loss: 1.9501, Valid loss: 1.9730\n",
            "Epoch [30/30000]: Train loss: 1.9455, Valid loss: 1.9773\n",
            "Epoch [31/30000]: Train loss: 1.9511, Valid loss: 1.9775\n",
            "Epoch [32/30000]: Train loss: 1.9523, Valid loss: 1.9695\n",
            "Epoch [33/30000]: Train loss: 1.9472, Valid loss: 1.9532\n",
            "Saving model with loss 1.953...\n",
            "Epoch [34/30000]: Train loss: 1.9490, Valid loss: 1.9854\n",
            "Epoch [35/30000]: Train loss: 1.9485, Valid loss: 1.9516\n",
            "Saving model with loss 1.952...\n",
            "Epoch [36/30000]: Train loss: 1.9483, Valid loss: 1.9552\n",
            "Epoch [37/30000]: Train loss: 1.9474, Valid loss: 1.9523\n",
            "Epoch [38/30000]: Train loss: 1.9494, Valid loss: 1.9632\n",
            "Epoch [39/30000]: Train loss: 1.9467, Valid loss: 1.9580\n",
            "Epoch [40/30000]: Train loss: 1.9502, Valid loss: 1.9909\n",
            "Epoch [41/30000]: Train loss: 1.9500, Valid loss: 1.9945\n",
            "Epoch [42/30000]: Train loss: 1.9462, Valid loss: 1.9620\n",
            "Epoch [43/30000]: Train loss: 1.9532, Valid loss: 1.9769\n",
            "Epoch [44/30000]: Train loss: 1.9505, Valid loss: 1.9831\n",
            "Epoch [45/30000]: Train loss: 1.9478, Valid loss: 2.0184\n",
            "Epoch [46/30000]: Train loss: 1.9485, Valid loss: 1.9609\n",
            "Epoch [47/30000]: Train loss: 1.9489, Valid loss: 1.9686\n",
            "Epoch [48/30000]: Train loss: 1.9482, Valid loss: 1.9596\n",
            "Epoch [49/30000]: Train loss: 1.9489, Valid loss: 1.9799\n",
            "Epoch [50/30000]: Train loss: 1.9479, Valid loss: 1.9527\n",
            "Epoch [51/30000]: Train loss: 1.9501, Valid loss: 1.9633\n",
            "Epoch [52/30000]: Train loss: 1.9482, Valid loss: 1.9718\n",
            "Epoch [53/30000]: Train loss: 1.9507, Valid loss: 2.0269\n",
            "Epoch [54/30000]: Train loss: 1.9459, Valid loss: 1.9697\n",
            "Epoch [55/30000]: Train loss: 1.9521, Valid loss: 1.9901\n",
            "Epoch [56/30000]: Train loss: 1.9499, Valid loss: 1.9922\n",
            "Epoch [57/30000]: Train loss: 1.9513, Valid loss: 1.9576\n",
            "Epoch [58/30000]: Train loss: 1.9488, Valid loss: 1.9792\n",
            "Epoch [59/30000]: Train loss: 1.9543, Valid loss: 1.9834\n",
            "Epoch [60/30000]: Train loss: 1.9491, Valid loss: 1.9790\n",
            "Epoch [61/30000]: Train loss: 1.9506, Valid loss: 1.9759\n",
            "Epoch [62/30000]: Train loss: 1.9475, Valid loss: 1.9624\n",
            "Epoch [63/30000]: Train loss: 1.9575, Valid loss: 1.9676\n",
            "Epoch [64/30000]: Train loss: 1.9484, Valid loss: 1.9861\n",
            "Epoch [65/30000]: Train loss: 1.9428, Valid loss: 1.9634\n",
            "Epoch [66/30000]: Train loss: 1.9455, Valid loss: 1.9847\n",
            "Epoch [67/30000]: Train loss: 1.9432, Valid loss: 2.0102\n",
            "Epoch [68/30000]: Train loss: 1.9541, Valid loss: 1.9935\n",
            "Epoch [69/30000]: Train loss: 1.9508, Valid loss: 1.9759\n",
            "Epoch [70/30000]: Train loss: 1.9504, Valid loss: 1.9851\n",
            "Epoch [71/30000]: Train loss: 1.9485, Valid loss: 1.9769\n",
            "Epoch [72/30000]: Train loss: 1.9477, Valid loss: 1.9712\n",
            "Epoch [73/30000]: Train loss: 1.9495, Valid loss: 1.9683\n",
            "Epoch [74/30000]: Train loss: 1.9520, Valid loss: 1.9664\n",
            "Epoch [75/30000]: Train loss: 1.9511, Valid loss: 1.9753\n",
            "Epoch [76/30000]: Train loss: 1.9520, Valid loss: 1.9866\n",
            "Epoch [77/30000]: Train loss: 1.9479, Valid loss: 1.9899\n",
            "Epoch [78/30000]: Train loss: 1.9468, Valid loss: 1.9665\n",
            "Epoch [79/30000]: Train loss: 1.9489, Valid loss: 1.9730\n",
            "Epoch [80/30000]: Train loss: 1.9482, Valid loss: 1.9998\n",
            "Epoch [81/30000]: Train loss: 1.9440, Valid loss: 1.9903\n",
            "Epoch [82/30000]: Train loss: 1.9447, Valid loss: 1.9670\n",
            "Epoch [83/30000]: Train loss: 1.9486, Valid loss: 1.9676\n",
            "Epoch [84/30000]: Train loss: 1.9443, Valid loss: 2.0111\n",
            "Epoch [85/30000]: Train loss: 1.9453, Valid loss: 1.9868\n",
            "Epoch [86/30000]: Train loss: 1.9439, Valid loss: 1.9806\n",
            "Epoch [87/30000]: Train loss: 1.9464, Valid loss: 1.9677\n",
            "Epoch [88/30000]: Train loss: 1.9492, Valid loss: 1.9860\n",
            "Epoch [89/30000]: Train loss: 1.9465, Valid loss: 1.9885\n",
            "Epoch [90/30000]: Train loss: 1.9450, Valid loss: 1.9787\n",
            "Epoch [91/30000]: Train loss: 1.9449, Valid loss: 1.9548\n",
            "Epoch [92/30000]: Train loss: 1.9481, Valid loss: 1.9907\n",
            "Epoch [93/30000]: Train loss: 1.9564, Valid loss: 2.0155\n",
            "Epoch [94/30000]: Train loss: 1.9476, Valid loss: 1.9697\n",
            "Epoch [95/30000]: Train loss: 1.9456, Valid loss: 1.9603\n",
            "Epoch [96/30000]: Train loss: 1.9473, Valid loss: 1.9677\n",
            "Epoch [97/30000]: Train loss: 1.9423, Valid loss: 2.0321\n",
            "Epoch [98/30000]: Train loss: 1.9504, Valid loss: 1.9923\n",
            "Epoch [99/30000]: Train loss: 1.9469, Valid loss: 2.0199\n",
            "Epoch [100/30000]: Train loss: 1.9492, Valid loss: 1.9667\n",
            "Epoch [101/30000]: Train loss: 1.9478, Valid loss: 1.9844\n",
            "Epoch [102/30000]: Train loss: 1.9494, Valid loss: 1.9663\n",
            "Epoch [103/30000]: Train loss: 1.9454, Valid loss: 1.9526\n",
            "Epoch [104/30000]: Train loss: 1.9450, Valid loss: 1.9939\n",
            "Epoch [105/30000]: Train loss: 1.9510, Valid loss: 2.0022\n",
            "Epoch [106/30000]: Train loss: 1.9487, Valid loss: 1.9666\n",
            "Epoch [107/30000]: Train loss: 1.9458, Valid loss: 1.9695\n",
            "Epoch [108/30000]: Train loss: 1.9494, Valid loss: 1.9710\n",
            "Epoch [109/30000]: Train loss: 1.9435, Valid loss: 1.9833\n",
            "Epoch [110/30000]: Train loss: 1.9462, Valid loss: 1.9899\n",
            "Epoch [111/30000]: Train loss: 1.9472, Valid loss: 1.9528\n",
            "Epoch [112/30000]: Train loss: 1.9430, Valid loss: 1.9836\n",
            "Epoch [113/30000]: Train loss: 1.9484, Valid loss: 2.0152\n",
            "Epoch [114/30000]: Train loss: 1.9436, Valid loss: 1.9931\n",
            "Epoch [115/30000]: Train loss: 1.9455, Valid loss: 1.9908\n",
            "Epoch [116/30000]: Train loss: 1.9470, Valid loss: 1.9745\n",
            "Epoch [117/30000]: Train loss: 1.9503, Valid loss: 2.0162\n",
            "Epoch [118/30000]: Train loss: 1.9472, Valid loss: 2.0076\n",
            "Epoch [119/30000]: Train loss: 1.9469, Valid loss: 1.9877\n",
            "Epoch [120/30000]: Train loss: 1.9462, Valid loss: 2.0087\n",
            "Epoch [121/30000]: Train loss: 1.9487, Valid loss: 1.9911\n",
            "Epoch [122/30000]: Train loss: 1.9471, Valid loss: 2.0003\n",
            "Epoch [123/30000]: Train loss: 1.9456, Valid loss: 1.9512\n",
            "Saving model with loss 1.951...\n",
            "Epoch [124/30000]: Train loss: 1.9441, Valid loss: 1.9834\n",
            "Epoch [125/30000]: Train loss: 1.9433, Valid loss: 1.9691\n",
            "Epoch [126/30000]: Train loss: 1.9478, Valid loss: 1.9751\n",
            "Epoch [127/30000]: Train loss: 1.9480, Valid loss: 1.9862\n",
            "Epoch [128/30000]: Train loss: 1.9491, Valid loss: 1.9870\n",
            "Epoch [129/30000]: Train loss: 1.9525, Valid loss: 1.9608\n",
            "Epoch [130/30000]: Train loss: 1.9475, Valid loss: 1.9854\n",
            "Epoch [131/30000]: Train loss: 1.9471, Valid loss: 1.9757\n",
            "Epoch [132/30000]: Train loss: 1.9488, Valid loss: 1.9702\n",
            "Epoch [133/30000]: Train loss: 1.9471, Valid loss: 1.9546\n",
            "Epoch [134/30000]: Train loss: 1.9444, Valid loss: 1.9757\n",
            "Epoch [135/30000]: Train loss: 1.9569, Valid loss: 1.9954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'Danceability'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([i+17170, p])\n",
        "model.load_state_dict(torch.load(config['save_path']))\n",
        "preds = predict(test_loader, model, device)\n",
        "print(preds)\n",
        "save_pred(preds, 'sample_submission.csv')\n",
        "from google.colab import files\n",
        "files.download('sample_submission.csv')"
      ],
      "metadata": {
        "id": "mNnGeuu72qdu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}