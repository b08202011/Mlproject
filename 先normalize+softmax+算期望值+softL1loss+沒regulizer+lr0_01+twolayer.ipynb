{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/b08202011/Mlproject/blob/main/%E5%85%88normalize%2Bsoftmax%2B%E7%AE%97%E6%9C%9F%E6%9C%9B%E5%80%BC%2BsoftL1loss%2B%E6%B2%92regulizer%2Blr0_01%2Btwolayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2klC1qgz2Oi2",
        "outputId": "649fe9df-8287-47dd-b934-2401fbbde0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lpwTva7SEtLRNwpBbYKZLoHDoeG7FTxp\n",
            "To: /content/train.csv\n",
            "100% 23.3M/23.3M [00:00<00:00, 47.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15MfSdxpfkHQi_Z0qdJIdrdPzLrSfbX1E\n",
            "To: /content/test.csv\n",
            "100% 8.88M/8.88M [00:00<00:00, 84.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=187gijxd4T5yuZe_g2K9UNepx7MT1CnAu\n",
            "To: /content/sample_submission.csv\n",
            "100% 50.5k/50.5k [00:00<00:00, 48.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1lpwTva7SEtLRNwpBbYKZLoHDoeG7FTxp\n",
        "!gdown 15MfSdxpfkHQi_Z0qdJIdrdPzLrSfbX1E\n",
        "!gdown 187gijxd4T5yuZe_g2K9UNepx7MT1CnAu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "10JsWM_brgQw"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "with open('train.csv',newline='') as csvfile:\n",
        "  train = csv.reader(csvfile)\n",
        "  train = list(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DscDJdCVr0kH",
        "outputId": "42c0e234-0ed0-4f7c-84cc-2662f4e4ecc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17170\n"
          ]
        }
      ],
      "source": [
        "pick = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,23]\n",
        "#可以選要用那些特徵，0是我們要predict的\n",
        "#只選數值或true fale 但且沒有選id\n",
        "feature = []\n",
        "for i in range(1,len(train)):\n",
        "  feature.append([])\n",
        "  for j in pick:\n",
        "    feature[i-1].append(train[i][j])\n",
        "\n",
        "for i in range(len(feature)):\n",
        "  for j in range(len(feature[i])):\n",
        "    if(feature[i][j]!='' and feature[i][j]!='False' and feature[i][j]!= 'True'):\n",
        "      feature[i][j] = float(feature[i][j])\n",
        "    elif(feature[i][j] == 'False'):\n",
        "      feature[i][j] = 0\n",
        "    elif(feature[i][j] == 'True'):\n",
        "      feature[i][j] = 1\n",
        "    else:\n",
        "      feature[i][j] = np.nan\n",
        "print(len(feature))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFwj7Vtjr7C3",
        "outputId": "6e921b0e-3dda-4e6f-d118-bcfc336771dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ycimpute\n",
            "  Downloading ycimpute-0.2-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ycimpute) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from ycimpute) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ycimpute) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from ycimpute) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from ycimpute) (2.0.0+cu118)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->ycimpute) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->ycimpute) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->ycimpute) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->ycimpute) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->ycimpute) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->ycimpute) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->ycimpute) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->ycimpute) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1.0->ycimpute) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1.0->ycimpute) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->ycimpute) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->ycimpute) (1.3.0)\n",
            "Installing collected packages: ycimpute\n",
            "Successfully installed ycimpute-0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install ycimpute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpQkUiqtr-VA",
        "outputId": "56b622e7-73a5-4ce3-877e-1c2a149ec2f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputing row 1/17170 with 1 missing, elapsed time: 98.134\n",
            "Imputing row 101/17170 with 1 missing, elapsed time: 98.171\n",
            "Imputing row 201/17170 with 0 missing, elapsed time: 98.217\n",
            "Imputing row 301/17170 with 2 missing, elapsed time: 98.263\n",
            "Imputing row 401/17170 with 1 missing, elapsed time: 98.303\n",
            "Imputing row 501/17170 with 1 missing, elapsed time: 98.344\n",
            "Imputing row 601/17170 with 4 missing, elapsed time: 98.388\n",
            "Imputing row 701/17170 with 2 missing, elapsed time: 98.432\n",
            "Imputing row 801/17170 with 2 missing, elapsed time: 98.479\n",
            "Imputing row 901/17170 with 3 missing, elapsed time: 98.522\n",
            "Imputing row 1001/17170 with 0 missing, elapsed time: 98.574\n",
            "Imputing row 1101/17170 with 0 missing, elapsed time: 98.613\n",
            "Imputing row 1201/17170 with 2 missing, elapsed time: 98.654\n",
            "Imputing row 1301/17170 with 3 missing, elapsed time: 98.701\n",
            "Imputing row 1401/17170 with 3 missing, elapsed time: 98.742\n",
            "Imputing row 1501/17170 with 3 missing, elapsed time: 98.790\n",
            "Imputing row 1601/17170 with 3 missing, elapsed time: 98.833\n",
            "Imputing row 1701/17170 with 1 missing, elapsed time: 98.877\n",
            "Imputing row 1801/17170 with 2 missing, elapsed time: 98.918\n",
            "Imputing row 1901/17170 with 0 missing, elapsed time: 98.961\n",
            "Imputing row 2001/17170 with 1 missing, elapsed time: 99.011\n",
            "Imputing row 2101/17170 with 6 missing, elapsed time: 99.055\n",
            "Imputing row 2201/17170 with 4 missing, elapsed time: 99.099\n",
            "Imputing row 2301/17170 with 2 missing, elapsed time: 99.143\n",
            "Imputing row 2401/17170 with 4 missing, elapsed time: 99.190\n",
            "Imputing row 2501/17170 with 2 missing, elapsed time: 99.238\n",
            "Imputing row 2601/17170 with 1 missing, elapsed time: 99.284\n",
            "Imputing row 2701/17170 with 1 missing, elapsed time: 99.323\n",
            "Imputing row 2801/17170 with 2 missing, elapsed time: 99.360\n",
            "Imputing row 2901/17170 with 0 missing, elapsed time: 99.389\n",
            "Imputing row 3001/17170 with 3 missing, elapsed time: 99.422\n",
            "Imputing row 3101/17170 with 1 missing, elapsed time: 99.454\n",
            "Imputing row 3201/17170 with 3 missing, elapsed time: 99.482\n",
            "Imputing row 3301/17170 with 4 missing, elapsed time: 99.510\n",
            "Imputing row 3401/17170 with 5 missing, elapsed time: 99.537\n",
            "Imputing row 3501/17170 with 1 missing, elapsed time: 99.567\n",
            "Imputing row 3601/17170 with 5 missing, elapsed time: 99.593\n",
            "Imputing row 3701/17170 with 3 missing, elapsed time: 99.621\n",
            "Imputing row 3801/17170 with 2 missing, elapsed time: 99.651\n",
            "Imputing row 3901/17170 with 4 missing, elapsed time: 99.679\n",
            "Imputing row 4001/17170 with 2 missing, elapsed time: 99.705\n",
            "Imputing row 4101/17170 with 2 missing, elapsed time: 99.731\n",
            "Imputing row 4201/17170 with 2 missing, elapsed time: 99.757\n",
            "Imputing row 4301/17170 with 2 missing, elapsed time: 99.783\n",
            "Imputing row 4401/17170 with 1 missing, elapsed time: 99.810\n",
            "Imputing row 4501/17170 with 2 missing, elapsed time: 99.837\n",
            "Imputing row 4601/17170 with 4 missing, elapsed time: 99.863\n",
            "Imputing row 4701/17170 with 2 missing, elapsed time: 99.894\n",
            "Imputing row 4801/17170 with 2 missing, elapsed time: 99.921\n",
            "Imputing row 4901/17170 with 3 missing, elapsed time: 99.946\n",
            "Imputing row 5001/17170 with 3 missing, elapsed time: 99.973\n",
            "Imputing row 5101/17170 with 3 missing, elapsed time: 100.002\n",
            "Imputing row 5201/17170 with 3 missing, elapsed time: 100.028\n",
            "Imputing row 5301/17170 with 2 missing, elapsed time: 100.066\n",
            "Imputing row 5401/17170 with 4 missing, elapsed time: 100.094\n",
            "Imputing row 5501/17170 with 4 missing, elapsed time: 100.126\n",
            "Imputing row 5601/17170 with 2 missing, elapsed time: 100.154\n",
            "Imputing row 5701/17170 with 2 missing, elapsed time: 100.181\n",
            "Imputing row 5801/17170 with 3 missing, elapsed time: 100.209\n",
            "Imputing row 5901/17170 with 2 missing, elapsed time: 100.237\n",
            "Imputing row 6001/17170 with 3 missing, elapsed time: 100.263\n",
            "Imputing row 6101/17170 with 2 missing, elapsed time: 100.294\n",
            "Imputing row 6201/17170 with 4 missing, elapsed time: 100.324\n",
            "Imputing row 6301/17170 with 1 missing, elapsed time: 100.356\n",
            "Imputing row 6401/17170 with 3 missing, elapsed time: 100.385\n",
            "Imputing row 6501/17170 with 1 missing, elapsed time: 100.410\n",
            "Imputing row 6601/17170 with 3 missing, elapsed time: 100.439\n",
            "Imputing row 6701/17170 with 2 missing, elapsed time: 100.465\n",
            "Imputing row 6801/17170 with 1 missing, elapsed time: 100.490\n",
            "Imputing row 6901/17170 with 3 missing, elapsed time: 100.516\n",
            "Imputing row 7001/17170 with 1 missing, elapsed time: 100.544\n",
            "Imputing row 7101/17170 with 2 missing, elapsed time: 100.575\n",
            "Imputing row 7201/17170 with 0 missing, elapsed time: 100.604\n",
            "Imputing row 7301/17170 with 2 missing, elapsed time: 100.631\n",
            "Imputing row 7401/17170 with 2 missing, elapsed time: 100.661\n",
            "Imputing row 7501/17170 with 2 missing, elapsed time: 100.689\n",
            "Imputing row 7601/17170 with 5 missing, elapsed time: 100.718\n",
            "Imputing row 7701/17170 with 2 missing, elapsed time: 100.746\n",
            "Imputing row 7801/17170 with 1 missing, elapsed time: 100.775\n",
            "Imputing row 7901/17170 with 1 missing, elapsed time: 100.806\n",
            "Imputing row 8001/17170 with 2 missing, elapsed time: 100.833\n",
            "Imputing row 8101/17170 with 4 missing, elapsed time: 100.861\n",
            "Imputing row 8201/17170 with 2 missing, elapsed time: 100.893\n",
            "Imputing row 8301/17170 with 3 missing, elapsed time: 100.922\n",
            "Imputing row 8401/17170 with 1 missing, elapsed time: 100.953\n",
            "Imputing row 8501/17170 with 2 missing, elapsed time: 100.978\n",
            "Imputing row 8601/17170 with 2 missing, elapsed time: 101.003\n",
            "Imputing row 8701/17170 with 4 missing, elapsed time: 101.032\n",
            "Imputing row 8801/17170 with 2 missing, elapsed time: 101.058\n",
            "Imputing row 8901/17170 with 4 missing, elapsed time: 101.087\n",
            "Imputing row 9001/17170 with 1 missing, elapsed time: 101.113\n",
            "Imputing row 9101/17170 with 1 missing, elapsed time: 101.141\n",
            "Imputing row 9201/17170 with 1 missing, elapsed time: 101.168\n",
            "Imputing row 9301/17170 with 5 missing, elapsed time: 101.194\n",
            "Imputing row 9401/17170 with 7 missing, elapsed time: 101.220\n",
            "Imputing row 9501/17170 with 0 missing, elapsed time: 101.257\n",
            "Imputing row 9601/17170 with 3 missing, elapsed time: 101.283\n",
            "Imputing row 9701/17170 with 3 missing, elapsed time: 101.312\n",
            "Imputing row 9801/17170 with 3 missing, elapsed time: 101.343\n",
            "Imputing row 9901/17170 with 1 missing, elapsed time: 101.369\n",
            "Imputing row 10001/17170 with 3 missing, elapsed time: 101.399\n",
            "Imputing row 10101/17170 with 3 missing, elapsed time: 101.424\n",
            "Imputing row 10201/17170 with 3 missing, elapsed time: 101.452\n",
            "Imputing row 10301/17170 with 1 missing, elapsed time: 101.491\n",
            "Imputing row 10401/17170 with 3 missing, elapsed time: 101.517\n",
            "Imputing row 10501/17170 with 4 missing, elapsed time: 101.548\n",
            "Imputing row 10601/17170 with 2 missing, elapsed time: 101.578\n",
            "Imputing row 10701/17170 with 1 missing, elapsed time: 101.607\n",
            "Imputing row 10801/17170 with 3 missing, elapsed time: 101.633\n",
            "Imputing row 10901/17170 with 1 missing, elapsed time: 101.659\n",
            "Imputing row 11001/17170 with 3 missing, elapsed time: 101.686\n",
            "Imputing row 11101/17170 with 3 missing, elapsed time: 101.719\n",
            "Imputing row 11201/17170 with 2 missing, elapsed time: 101.749\n",
            "Imputing row 11301/17170 with 1 missing, elapsed time: 101.778\n",
            "Imputing row 11401/17170 with 2 missing, elapsed time: 101.803\n",
            "Imputing row 11501/17170 with 2 missing, elapsed time: 101.830\n",
            "Imputing row 11601/17170 with 2 missing, elapsed time: 101.855\n",
            "Imputing row 11701/17170 with 1 missing, elapsed time: 101.883\n",
            "Imputing row 11801/17170 with 3 missing, elapsed time: 101.912\n",
            "Imputing row 11901/17170 with 2 missing, elapsed time: 101.941\n",
            "Imputing row 12001/17170 with 2 missing, elapsed time: 101.970\n",
            "Imputing row 12101/17170 with 1 missing, elapsed time: 101.997\n",
            "Imputing row 12201/17170 with 3 missing, elapsed time: 102.026\n",
            "Imputing row 12301/17170 with 3 missing, elapsed time: 102.053\n",
            "Imputing row 12401/17170 with 5 missing, elapsed time: 102.082\n",
            "Imputing row 12501/17170 with 2 missing, elapsed time: 102.108\n",
            "Imputing row 12601/17170 with 4 missing, elapsed time: 102.140\n",
            "Imputing row 12701/17170 with 2 missing, elapsed time: 102.171\n",
            "Imputing row 12801/17170 with 4 missing, elapsed time: 102.197\n",
            "Imputing row 12901/17170 with 2 missing, elapsed time: 102.223\n",
            "Imputing row 13001/17170 with 3 missing, elapsed time: 102.251\n",
            "Imputing row 13101/17170 with 2 missing, elapsed time: 102.284\n",
            "Imputing row 13201/17170 with 2 missing, elapsed time: 102.310\n",
            "Imputing row 13301/17170 with 1 missing, elapsed time: 102.346\n",
            "Imputing row 13401/17170 with 2 missing, elapsed time: 102.377\n",
            "Imputing row 13501/17170 with 3 missing, elapsed time: 102.403\n",
            "Imputing row 13601/17170 with 2 missing, elapsed time: 102.433\n",
            "Imputing row 13701/17170 with 3 missing, elapsed time: 102.461\n",
            "Imputing row 13801/17170 with 3 missing, elapsed time: 102.491\n",
            "Imputing row 13901/17170 with 1 missing, elapsed time: 102.518\n",
            "Imputing row 14001/17170 with 5 missing, elapsed time: 102.545\n",
            "Imputing row 14101/17170 with 1 missing, elapsed time: 102.572\n",
            "Imputing row 14201/17170 with 0 missing, elapsed time: 102.604\n",
            "Imputing row 14301/17170 with 2 missing, elapsed time: 102.630\n",
            "Imputing row 14401/17170 with 3 missing, elapsed time: 102.658\n",
            "Imputing row 14501/17170 with 1 missing, elapsed time: 102.685\n",
            "Imputing row 14601/17170 with 0 missing, elapsed time: 102.718\n",
            "Imputing row 14701/17170 with 1 missing, elapsed time: 102.743\n",
            "Imputing row 14801/17170 with 2 missing, elapsed time: 102.771\n",
            "Imputing row 14901/17170 with 3 missing, elapsed time: 102.798\n",
            "Imputing row 15001/17170 with 2 missing, elapsed time: 102.826\n",
            "Imputing row 15101/17170 with 1 missing, elapsed time: 102.853\n",
            "Imputing row 15201/17170 with 1 missing, elapsed time: 102.883\n",
            "Imputing row 15301/17170 with 3 missing, elapsed time: 102.910\n",
            "Imputing row 15401/17170 with 1 missing, elapsed time: 102.937\n",
            "Imputing row 15501/17170 with 2 missing, elapsed time: 102.964\n",
            "Imputing row 15601/17170 with 1 missing, elapsed time: 102.994\n",
            "Imputing row 15701/17170 with 3 missing, elapsed time: 103.021\n",
            "Imputing row 15801/17170 with 2 missing, elapsed time: 103.048\n",
            "Imputing row 15901/17170 with 2 missing, elapsed time: 103.079\n",
            "Imputing row 16001/17170 with 1 missing, elapsed time: 103.105\n",
            "Imputing row 16101/17170 with 2 missing, elapsed time: 103.130\n",
            "Imputing row 16201/17170 with 0 missing, elapsed time: 103.159\n",
            "Imputing row 16301/17170 with 1 missing, elapsed time: 103.187\n",
            "Imputing row 16401/17170 with 3 missing, elapsed time: 103.212\n",
            "Imputing row 16501/17170 with 1 missing, elapsed time: 103.238\n",
            "Imputing row 16601/17170 with 4 missing, elapsed time: 103.267\n",
            "Imputing row 16701/17170 with 3 missing, elapsed time: 103.297\n",
            "Imputing row 16801/17170 with 2 missing, elapsed time: 103.329\n",
            "Imputing row 16901/17170 with 4 missing, elapsed time: 103.361\n",
            "Imputing row 17001/17170 with 4 missing, elapsed time: 103.388\n",
            "Imputing row 17101/17170 with 6 missing, elapsed time: 103.417\n"
          ]
        }
      ],
      "source": [
        "feature = np.array(feature)\n",
        "from ycimpute.imputer import knnimput\n",
        "feature = knnimput.KNN(k=4).complete(feature) \n",
        "#imp_median.fit(feature)\n",
        "#feature = imp_median.transform(feature)\n",
        "##可以修改這裡 使用不同的data填補方式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Q2bmK7mVsAmP"
      },
      "outputs": [],
      "source": [
        "# Numerical Operations\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# Reading/Writing Data\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "# For Progress Bar\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.feature_selection import f_regression\n",
        "# Pytorch\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.models.feature_extraction import get_graph_node_names\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNN\n",
        "from torchvision.models.detection.backbone_utils import LastLevelMaxPool\n",
        "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn import utils\n",
        "\n",
        "# For plotting learning curve\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EuIQ-7tKuocP"
      },
      "outputs": [],
      "source": [
        "def same_seed(seed): \n",
        "    '''Fixes random number generator seeds for reproducibility.'''\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def train_valid_split(data_set, valid_ratio, seed):\n",
        "    '''Split provided training data into training set and validation set'''\n",
        "    valid_set_size = int(valid_ratio * len(data_set)) \n",
        "    train_set_size = len(data_set) - valid_set_size\n",
        "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
        "    return np.array(train_set), np.array(valid_set)\n",
        "\n",
        "def predict(test_loader, model, device):\n",
        "    model.eval() # Set your model to evaluation mode.\n",
        "    preds = []\n",
        "    for x in tqdm(test_loader):\n",
        "        x = x.to(device)                        \n",
        "        with torch.no_grad():                   \n",
        "            pred = torch.clamp(torch.round(model(x)),0,9)\n",
        "                          \n",
        "            preds.append(pred.detach().cpu())   \n",
        "    preds = torch.cat(preds, dim=0).numpy()  \n",
        "    return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D320CZu7nkU"
      },
      "source": [
        "##Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ypSQGM5i7q_g"
      },
      "outputs": [],
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    '''\n",
        "    x: Features.\n",
        "    y: Targets, if none, do prediction.\n",
        "    '''\n",
        "    def __init__(self, x, y=None):\n",
        "        if y is None:\n",
        "            self.y = y\n",
        "        else:\n",
        "            self.y = torch.FloatTensor(y)\n",
        "        self.x = torch.FloatTensor(x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is None:\n",
        "            return self.x[idx]\n",
        "        else:\n",
        "            return self.x[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dFunF8QtoP_"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zIkJ9iRauAy8"
      },
      "outputs": [],
      "source": [
        "class My_Model(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(My_Model, self).__init__()\n",
        "        # TODO: modify model's structure, be aware of dimensions. \n",
        "        self.layers = nn.Sequential(\n",
        "            nn.BatchNorm1d(input_dim),\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(64, 16),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 10),           \n",
        "        )\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "    def forward(self, x):\n",
        "        #x = x.view(-1, 16)\n",
        "        x = self.layers(x)\n",
        "        \n",
        "        x = self.softmax(x)\n",
        "        #print(x)\n",
        "        out = torch.linspace(0,9,10)\n",
        "        #x = torch.sigmoid(x)\n",
        "        #x = torch.mul(x,9)\n",
        "        x = torch.mul(x,out)\n",
        "        x = torch.sum(x, dim=1)\n",
        "        #print(x)\n",
        "        x = x.squeeze(-1) # (B, 1) -> (B)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9EXYkYmuQzB"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "khMhvW1duO9l"
      },
      "outputs": [],
      "source": [
        "def trainer(train_data, model, config, device):\n",
        "\n",
        "    criterion = nn.SmoothL1Loss(beta=0.5) # Define your loss function, do not modify this.\n",
        "    #criterion = nn.L1Loss()\n",
        "\n",
        "    # Define your optimization algorithm. \n",
        "    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n",
        "    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr= config['learning_rate'] , weight_decay=0.01, amsgrad=False) \n",
        "    writer = SummaryWriter() # Writer of tensoboard.\n",
        "\n",
        "    if not os.path.isdir('./models'):\n",
        "        os.mkdir('./models') # Create directory of saving models.\n",
        "\n",
        "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
        "\n",
        "\n",
        "    np.random.seed(config['seed'])\n",
        "    splits = np.array_split(train_data, config['n_fold'])\n",
        "    \n",
        "    \n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "      lossvalid_record = []\n",
        "      loss_record = []\n",
        "      for i in range(config['n_fold']):\n",
        "        model.train() # Set your model to train mode.\n",
        "         \n",
        "        train =  np.concatenate(splits[:i]+splits[i+1:])\n",
        "        valid= splits[i]\n",
        "        x_train = train[...,1:]\n",
        "        x_valid = valid[...,1:]\n",
        "        y_train = train[...,0]\n",
        "        y_valid = valid[...,0]\n",
        "        train_dataset  = COVID19Dataset(x_train, y_train)\n",
        "        valid_dataset = COVID19Dataset(x_valid, y_valid)\n",
        "        \n",
        "        # Pytorch data loader loads pytorch dataset into batches.\n",
        "        train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "        valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            optimizer.zero_grad()               # Set gradient to zero.\n",
        "            x, y = x.to(device), y.to(device)   # Move your data to device. \n",
        "            pred = model(x)\n",
        "            \n",
        "            #loss = criterion(pred, y)\n",
        "            l1_norm = sum(p.abs().sum()for p in model.parameters())\n",
        "                \n",
        "            loss = criterion(pred, y)+config['regulizer']*l1_norm\n",
        "            #print(loss)\n",
        "            loss.backward()                     # Compute gradient(backpropagation).\n",
        "            optimizer.step()                    # Update parameters.\n",
        "            step += 1\n",
        "            \n",
        "            loss_record.append(loss.detach().item())\n",
        "            \n",
        "        model.eval() # Set your model to evaluation mode.\n",
        "        \n",
        "        for x, y in valid_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = torch.clamp(torch.round(model(x)),0,9)\n",
        "                #loss = criterion(pred, y)\n",
        "                l1_norm = sum(p.abs().sum()for p in model.parameters()) \n",
        "                loss = criterion(pred, y)+config['regulizer']*l1_norm\n",
        "\n",
        "            lossvalid_record.append(loss.item())\n",
        "\n",
        "\n",
        "        \n",
        "      mean_train_loss = sum(loss_record)/len(loss_record)         ###compute CV loss\n",
        "      writer.add_scalar('Loss/train', mean_train_loss, step)\n",
        "\n",
        "      mean_valid_loss = sum(lossvalid_record)/len(lossvalid_record)\n",
        "      print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
        "      # writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
        "\n",
        "      if mean_valid_loss < best_loss:\n",
        "          best_loss = mean_valid_loss\n",
        "          torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
        "          print('Saving model with loss {:.3f}...'.format(best_loss))\n",
        "          early_stop_count = 0\n",
        "      else: \n",
        "          early_stop_count += 1\n",
        "\n",
        "      if early_stop_count >= config['early_stop']:\n",
        "          print('\\nModel is not improving, so we halt the training session.')\n",
        "          return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_Hg8aMlzaqk"
      },
      "source": [
        "## config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dB14dhABzVxO"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "config = {\n",
        "    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n",
        "    'select_all': True,   # Whether to use all features.\n",
        "    'n_fold': 5,   # validation_size = train_size * valid_ratio\n",
        "    'n_epochs': 30000,     # Number of epochs.            \n",
        "    'batch_size': 128, \n",
        "    'learning_rate': 1e-2,\n",
        "    'regulizer': 0,              \n",
        "    'early_stop': 2000,    # If model has not improved for this many consecutive epochs, stop training.     \n",
        "    'save_path': './models/model.ckpt'  # Your model will be saved here.\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqtxFou74eQr",
        "outputId": "7a1d09cf-5a82-4086-9bc7-bfc4069bae1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputing row 1/6315 with 1 missing, elapsed time: 20.672\n",
            "Imputing row 101/6315 with 2 missing, elapsed time: 20.685\n",
            "Imputing row 201/6315 with 3 missing, elapsed time: 20.697\n",
            "Imputing row 301/6315 with 2 missing, elapsed time: 20.710\n",
            "Imputing row 401/6315 with 4 missing, elapsed time: 20.721\n",
            "Imputing row 501/6315 with 1 missing, elapsed time: 20.733\n",
            "Imputing row 601/6315 with 1 missing, elapsed time: 20.744\n",
            "Imputing row 701/6315 with 2 missing, elapsed time: 20.757\n",
            "Imputing row 801/6315 with 3 missing, elapsed time: 20.769\n",
            "Imputing row 901/6315 with 0 missing, elapsed time: 20.782\n",
            "Imputing row 1001/6315 with 3 missing, elapsed time: 20.793\n",
            "Imputing row 1101/6315 with 1 missing, elapsed time: 20.805\n",
            "Imputing row 1201/6315 with 5 missing, elapsed time: 20.817\n",
            "Imputing row 1301/6315 with 3 missing, elapsed time: 20.829\n",
            "Imputing row 1401/6315 with 2 missing, elapsed time: 20.840\n",
            "Imputing row 1501/6315 with 1 missing, elapsed time: 20.852\n",
            "Imputing row 1601/6315 with 3 missing, elapsed time: 20.863\n",
            "Imputing row 1701/6315 with 1 missing, elapsed time: 20.878\n",
            "Imputing row 1801/6315 with 2 missing, elapsed time: 20.891\n",
            "Imputing row 1901/6315 with 2 missing, elapsed time: 20.904\n",
            "Imputing row 2001/6315 with 2 missing, elapsed time: 20.915\n",
            "Imputing row 2101/6315 with 3 missing, elapsed time: 20.928\n",
            "Imputing row 2201/6315 with 3 missing, elapsed time: 20.939\n",
            "Imputing row 2301/6315 with 4 missing, elapsed time: 20.959\n",
            "Imputing row 2401/6315 with 2 missing, elapsed time: 20.973\n",
            "Imputing row 2501/6315 with 2 missing, elapsed time: 20.985\n",
            "Imputing row 2601/6315 with 3 missing, elapsed time: 20.999\n",
            "Imputing row 2701/6315 with 3 missing, elapsed time: 21.011\n",
            "Imputing row 2801/6315 with 2 missing, elapsed time: 21.022\n",
            "Imputing row 2901/6315 with 1 missing, elapsed time: 21.036\n",
            "Imputing row 3001/6315 with 3 missing, elapsed time: 21.049\n",
            "Imputing row 3101/6315 with 2 missing, elapsed time: 21.062\n",
            "Imputing row 3201/6315 with 3 missing, elapsed time: 21.075\n",
            "Imputing row 3301/6315 with 3 missing, elapsed time: 21.093\n",
            "Imputing row 3401/6315 with 5 missing, elapsed time: 21.104\n",
            "Imputing row 3501/6315 with 3 missing, elapsed time: 21.116\n",
            "Imputing row 3601/6315 with 2 missing, elapsed time: 21.128\n",
            "Imputing row 3701/6315 with 1 missing, elapsed time: 21.140\n",
            "Imputing row 3801/6315 with 3 missing, elapsed time: 21.151\n",
            "Imputing row 3901/6315 with 3 missing, elapsed time: 21.163\n",
            "Imputing row 4001/6315 with 2 missing, elapsed time: 21.175\n",
            "Imputing row 4101/6315 with 2 missing, elapsed time: 21.186\n",
            "Imputing row 4201/6315 with 2 missing, elapsed time: 21.197\n",
            "Imputing row 4301/6315 with 2 missing, elapsed time: 21.212\n",
            "Imputing row 4401/6315 with 2 missing, elapsed time: 21.225\n",
            "Imputing row 4501/6315 with 3 missing, elapsed time: 21.237\n",
            "Imputing row 4601/6315 with 4 missing, elapsed time: 21.249\n",
            "Imputing row 4701/6315 with 5 missing, elapsed time: 21.260\n",
            "Imputing row 4801/6315 with 1 missing, elapsed time: 21.272\n",
            "Imputing row 4901/6315 with 4 missing, elapsed time: 21.283\n",
            "Imputing row 5001/6315 with 2 missing, elapsed time: 21.295\n",
            "Imputing row 5101/6315 with 3 missing, elapsed time: 21.309\n",
            "Imputing row 5201/6315 with 3 missing, elapsed time: 21.321\n",
            "Imputing row 5301/6315 with 2 missing, elapsed time: 21.335\n",
            "Imputing row 5401/6315 with 0 missing, elapsed time: 21.347\n",
            "Imputing row 5501/6315 with 6 missing, elapsed time: 21.364\n",
            "Imputing row 5601/6315 with 2 missing, elapsed time: 21.379\n",
            "Imputing row 5701/6315 with 3 missing, elapsed time: 21.393\n",
            "Imputing row 5801/6315 with 2 missing, elapsed time: 21.405\n",
            "Imputing row 5901/6315 with 4 missing, elapsed time: 21.417\n",
            "Imputing row 6001/6315 with 1 missing, elapsed time: 21.429\n",
            "Imputing row 6101/6315 with 2 missing, elapsed time: 21.441\n",
            "Imputing row 6201/6315 with 2 missing, elapsed time: 21.452\n",
            "Imputing row 6301/6315 with 1 missing, elapsed time: 21.464\n"
          ]
        }
      ],
      "source": [
        "same_seed(config['seed'])\n",
        "with open('test.csv',newline='') as csvfile:\n",
        "  testcsv = csv.reader(csvfile)\n",
        "  testcsv = list(testcsv)\n",
        "test = []\n",
        "pick = [0,1,2,3,4,5,6,7,8,9,10,11,12,14,15,22]\n",
        "\n",
        "for i in range(1,len(testcsv)):\n",
        "  test.append([])\n",
        "  for j in pick:\n",
        "    test[i-1].append(testcsv[i][j])\n",
        "for i in range(len(test)):\n",
        "  for j in range(len(test[i])):\n",
        "    if(test[i][j]!='' and test[i][j]!='False' and test[i][j]!= 'True'):\n",
        "      test[i][j] = float(test[i][j])\n",
        "    elif(test[i][j] == 'False'):\n",
        "      test[i][j] = 0\n",
        "    elif(test[i][j] == 'True'):\n",
        "      test[i][j] = 1\n",
        "    else:\n",
        "      test[i][j] = np.nan\n",
        "test_data = knnimput.KNN(k=4).complete(np.array(test))\n",
        "#imp_median.fit(test)\n",
        "#test_data = imp_median.transform(test)\n",
        "train_data= feature\n",
        "#train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n",
        "\n",
        "x_test =  test_data\n",
        "test_dataset = COVID19Dataset(x_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1zpP7hF1y18"
      },
      "source": [
        "## Training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hn82Vj0R06Yt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "180bf05e-b919-4c31-ab7c-53219ed1b0e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30000]: Train loss: 1.4484, Valid loss: 1.4226\n",
            "Saving model with loss 1.423...\n",
            "Epoch [2/30000]: Train loss: 1.3903, Valid loss: 1.3963\n",
            "Saving model with loss 1.396...\n",
            "Epoch [3/30000]: Train loss: 1.3769, Valid loss: 1.3995\n",
            "Epoch [4/30000]: Train loss: 1.3675, Valid loss: 1.3616\n",
            "Saving model with loss 1.362...\n",
            "Epoch [5/30000]: Train loss: 1.3604, Valid loss: 1.3726\n",
            "Epoch [6/30000]: Train loss: 1.3558, Valid loss: 1.3562\n",
            "Saving model with loss 1.356...\n",
            "Epoch [7/30000]: Train loss: 1.3498, Valid loss: 1.3697\n",
            "Epoch [8/30000]: Train loss: 1.3484, Valid loss: 1.3320\n",
            "Saving model with loss 1.332...\n",
            "Epoch [9/30000]: Train loss: 1.3387, Valid loss: 1.3320\n",
            "Epoch [10/30000]: Train loss: 1.3351, Valid loss: 1.3167\n",
            "Saving model with loss 1.317...\n",
            "Epoch [11/30000]: Train loss: 1.3330, Valid loss: 1.3277\n",
            "Epoch [12/30000]: Train loss: 1.3271, Valid loss: 1.3242\n",
            "Epoch [13/30000]: Train loss: 1.3258, Valid loss: 1.3112\n",
            "Saving model with loss 1.311...\n",
            "Epoch [14/30000]: Train loss: 1.3258, Valid loss: 1.3152\n",
            "Epoch [15/30000]: Train loss: 1.3232, Valid loss: 1.3149\n",
            "Epoch [16/30000]: Train loss: 1.3186, Valid loss: 1.3279\n",
            "Epoch [17/30000]: Train loss: 1.3228, Valid loss: 1.3039\n",
            "Saving model with loss 1.304...\n",
            "Epoch [18/30000]: Train loss: 1.3205, Valid loss: 1.3097\n",
            "Epoch [19/30000]: Train loss: 1.3137, Valid loss: 1.3021\n",
            "Saving model with loss 1.302...\n",
            "Epoch [20/30000]: Train loss: 1.3141, Valid loss: 1.3132\n",
            "Epoch [21/30000]: Train loss: 1.3178, Valid loss: 1.3188\n",
            "Epoch [22/30000]: Train loss: 1.3127, Valid loss: 1.3110\n",
            "Epoch [23/30000]: Train loss: 1.3160, Valid loss: 1.3069\n",
            "Epoch [24/30000]: Train loss: 1.3173, Valid loss: 1.3011\n",
            "Saving model with loss 1.301...\n",
            "Epoch [25/30000]: Train loss: 1.3142, Valid loss: 1.3158\n",
            "Epoch [26/30000]: Train loss: 1.3090, Valid loss: 1.2966\n",
            "Saving model with loss 1.297...\n",
            "Epoch [27/30000]: Train loss: 1.3098, Valid loss: 1.2965\n",
            "Saving model with loss 1.297...\n",
            "Epoch [28/30000]: Train loss: 1.3075, Valid loss: 1.2988\n",
            "Epoch [29/30000]: Train loss: 1.3104, Valid loss: 1.2836\n",
            "Saving model with loss 1.284...\n",
            "Epoch [30/30000]: Train loss: 1.3102, Valid loss: 1.2990\n",
            "Epoch [31/30000]: Train loss: 1.3034, Valid loss: 1.2924\n",
            "Epoch [32/30000]: Train loss: 1.3064, Valid loss: 1.2943\n",
            "Epoch [33/30000]: Train loss: 1.3072, Valid loss: 1.2884\n",
            "Epoch [34/30000]: Train loss: 1.3045, Valid loss: 1.2911\n",
            "Epoch [35/30000]: Train loss: 1.3041, Valid loss: 1.2925\n",
            "Epoch [36/30000]: Train loss: 1.3086, Valid loss: 1.2842\n",
            "Epoch [37/30000]: Train loss: 1.3051, Valid loss: 1.2919\n",
            "Epoch [38/30000]: Train loss: 1.3057, Valid loss: 1.2931\n",
            "Epoch [39/30000]: Train loss: 1.3025, Valid loss: 1.2939\n",
            "Epoch [40/30000]: Train loss: 1.3005, Valid loss: 1.2889\n",
            "Epoch [41/30000]: Train loss: 1.3061, Valid loss: 1.2778\n",
            "Saving model with loss 1.278...\n",
            "Epoch [42/30000]: Train loss: 1.3040, Valid loss: 1.2965\n",
            "Epoch [43/30000]: Train loss: 1.3077, Valid loss: 1.2870\n",
            "Epoch [44/30000]: Train loss: 1.3042, Valid loss: 1.2781\n",
            "Epoch [45/30000]: Train loss: 1.3082, Valid loss: 1.2991\n",
            "Epoch [46/30000]: Train loss: 1.3025, Valid loss: 1.2892\n",
            "Epoch [47/30000]: Train loss: 1.3005, Valid loss: 1.2889\n",
            "Epoch [48/30000]: Train loss: 1.3012, Valid loss: 1.2760\n",
            "Saving model with loss 1.276...\n",
            "Epoch [49/30000]: Train loss: 1.3032, Valid loss: 1.2800\n",
            "Epoch [50/30000]: Train loss: 1.3054, Valid loss: 1.2855\n",
            "Epoch [51/30000]: Train loss: 1.3004, Valid loss: 1.2920\n",
            "Epoch [52/30000]: Train loss: 1.3030, Valid loss: 1.2810\n",
            "Epoch [53/30000]: Train loss: 1.3062, Valid loss: 1.2917\n",
            "Epoch [54/30000]: Train loss: 1.2984, Valid loss: 1.2760\n",
            "Saving model with loss 1.276...\n",
            "Epoch [55/30000]: Train loss: 1.3033, Valid loss: 1.2804\n",
            "Epoch [56/30000]: Train loss: 1.3055, Valid loss: 1.3017\n",
            "Epoch [57/30000]: Train loss: 1.3029, Valid loss: 1.2864\n",
            "Epoch [58/30000]: Train loss: 1.2976, Valid loss: 1.3032\n",
            "Epoch [59/30000]: Train loss: 1.3044, Valid loss: 1.2680\n",
            "Saving model with loss 1.268...\n",
            "Epoch [60/30000]: Train loss: 1.3001, Valid loss: 1.2860\n",
            "Epoch [61/30000]: Train loss: 1.2976, Valid loss: 1.2873\n",
            "Epoch [62/30000]: Train loss: 1.3026, Valid loss: 1.2849\n",
            "Epoch [63/30000]: Train loss: 1.2979, Valid loss: 1.3005\n",
            "Epoch [64/30000]: Train loss: 1.2990, Valid loss: 1.2814\n",
            "Epoch [65/30000]: Train loss: 1.2976, Valid loss: 1.2782\n",
            "Epoch [66/30000]: Train loss: 1.2996, Valid loss: 1.2708\n",
            "Epoch [67/30000]: Train loss: 1.2978, Valid loss: 1.2798\n",
            "Epoch [68/30000]: Train loss: 1.2956, Valid loss: 1.2792\n",
            "Epoch [69/30000]: Train loss: 1.2943, Valid loss: 1.2768\n",
            "Epoch [70/30000]: Train loss: 1.3003, Valid loss: 1.2850\n",
            "Epoch [71/30000]: Train loss: 1.2976, Valid loss: 1.2945\n",
            "Epoch [72/30000]: Train loss: 1.2978, Valid loss: 1.2802\n",
            "Epoch [73/30000]: Train loss: 1.2956, Valid loss: 1.2884\n",
            "Epoch [74/30000]: Train loss: 1.3042, Valid loss: 1.2853\n",
            "Epoch [75/30000]: Train loss: 1.2977, Valid loss: 1.2756\n",
            "Epoch [76/30000]: Train loss: 1.3025, Valid loss: 1.2923\n",
            "Epoch [77/30000]: Train loss: 1.2978, Valid loss: 1.2825\n",
            "Epoch [78/30000]: Train loss: 1.2995, Valid loss: 1.2774\n",
            "Epoch [79/30000]: Train loss: 1.3030, Valid loss: 1.2645\n",
            "Saving model with loss 1.264...\n",
            "Epoch [80/30000]: Train loss: 1.2959, Valid loss: 1.2659\n",
            "Epoch [81/30000]: Train loss: 1.2973, Valid loss: 1.2873\n",
            "Epoch [82/30000]: Train loss: 1.2963, Valid loss: 1.2754\n",
            "Epoch [83/30000]: Train loss: 1.2977, Valid loss: 1.2850\n",
            "Epoch [84/30000]: Train loss: 1.3065, Valid loss: 1.2752\n",
            "Epoch [85/30000]: Train loss: 1.2970, Valid loss: 1.2804\n",
            "Epoch [86/30000]: Train loss: 1.2995, Valid loss: 1.2989\n",
            "Epoch [87/30000]: Train loss: 1.2993, Valid loss: 1.2802\n",
            "Epoch [88/30000]: Train loss: 1.2990, Valid loss: 1.2920\n",
            "Epoch [89/30000]: Train loss: 1.2987, Valid loss: 1.2926\n",
            "Epoch [90/30000]: Train loss: 1.3023, Valid loss: 1.2899\n",
            "Epoch [91/30000]: Train loss: 1.2963, Valid loss: 1.2922\n",
            "Epoch [92/30000]: Train loss: 1.2955, Valid loss: 1.2721\n",
            "Epoch [93/30000]: Train loss: 1.2995, Valid loss: 1.2916\n",
            "Epoch [94/30000]: Train loss: 1.2967, Valid loss: 1.2716\n",
            "Epoch [95/30000]: Train loss: 1.3003, Valid loss: 1.2777\n",
            "Epoch [96/30000]: Train loss: 1.2950, Valid loss: 1.2851\n",
            "Epoch [97/30000]: Train loss: 1.2962, Valid loss: 1.2863\n",
            "Epoch [98/30000]: Train loss: 1.2948, Valid loss: 1.2776\n",
            "Epoch [99/30000]: Train loss: 1.2949, Valid loss: 1.2889\n",
            "Epoch [100/30000]: Train loss: 1.2985, Valid loss: 1.2850\n",
            "Epoch [101/30000]: Train loss: 1.2992, Valid loss: 1.2927\n",
            "Epoch [102/30000]: Train loss: 1.2990, Valid loss: 1.2773\n",
            "Epoch [103/30000]: Train loss: 1.2976, Valid loss: 1.2806\n",
            "Epoch [104/30000]: Train loss: 1.2952, Valid loss: 1.2936\n",
            "Epoch [105/30000]: Train loss: 1.2967, Valid loss: 1.2894\n",
            "Epoch [106/30000]: Train loss: 1.2952, Valid loss: 1.2944\n",
            "Epoch [107/30000]: Train loss: 1.2955, Valid loss: 1.2840\n",
            "Epoch [108/30000]: Train loss: 1.2928, Valid loss: 1.2930\n",
            "Epoch [109/30000]: Train loss: 1.2962, Valid loss: 1.2909\n",
            "Epoch [110/30000]: Train loss: 1.2938, Valid loss: 1.2751\n",
            "Epoch [111/30000]: Train loss: 1.2969, Valid loss: 1.2758\n",
            "Epoch [112/30000]: Train loss: 1.2949, Valid loss: 1.2844\n",
            "Epoch [113/30000]: Train loss: 1.2989, Valid loss: 1.2886\n",
            "Epoch [114/30000]: Train loss: 1.2946, Valid loss: 1.2711\n",
            "Epoch [115/30000]: Train loss: 1.2988, Valid loss: 1.2881\n",
            "Epoch [116/30000]: Train loss: 1.3001, Valid loss: 1.2850\n",
            "Epoch [117/30000]: Train loss: 1.2951, Valid loss: 1.2880\n",
            "Epoch [118/30000]: Train loss: 1.2946, Valid loss: 1.2791\n",
            "Epoch [119/30000]: Train loss: 1.2944, Valid loss: 1.2884\n",
            "Epoch [120/30000]: Train loss: 1.2975, Valid loss: 1.2935\n",
            "Epoch [121/30000]: Train loss: 1.2950, Valid loss: 1.2761\n",
            "Epoch [122/30000]: Train loss: 1.2950, Valid loss: 1.2690\n",
            "Epoch [123/30000]: Train loss: 1.2941, Valid loss: 1.2898\n",
            "Epoch [124/30000]: Train loss: 1.2979, Valid loss: 1.2821\n",
            "Epoch [125/30000]: Train loss: 1.2979, Valid loss: 1.2790\n",
            "Epoch [126/30000]: Train loss: 1.2954, Valid loss: 1.2896\n",
            "Epoch [127/30000]: Train loss: 1.2977, Valid loss: 1.2754\n",
            "Epoch [128/30000]: Train loss: 1.2903, Valid loss: 1.2658\n",
            "Epoch [129/30000]: Train loss: 1.2990, Valid loss: 1.2794\n",
            "Epoch [130/30000]: Train loss: 1.2959, Valid loss: 1.2767\n",
            "Epoch [131/30000]: Train loss: 1.2954, Valid loss: 1.2824\n",
            "Epoch [132/30000]: Train loss: 1.2948, Valid loss: 1.2742\n",
            "Epoch [133/30000]: Train loss: 1.2923, Valid loss: 1.2689\n",
            "Epoch [134/30000]: Train loss: 1.2924, Valid loss: 1.2768\n",
            "Epoch [135/30000]: Train loss: 1.2899, Valid loss: 1.2859\n",
            "Epoch [136/30000]: Train loss: 1.2963, Valid loss: 1.2631\n",
            "Saving model with loss 1.263...\n",
            "Epoch [137/30000]: Train loss: 1.2915, Valid loss: 1.2758\n",
            "Epoch [138/30000]: Train loss: 1.2942, Valid loss: 1.2610\n",
            "Saving model with loss 1.261...\n",
            "Epoch [139/30000]: Train loss: 1.2916, Valid loss: 1.2829\n",
            "Epoch [140/30000]: Train loss: 1.2947, Valid loss: 1.2801\n",
            "Epoch [141/30000]: Train loss: 1.2956, Valid loss: 1.2825\n",
            "Epoch [142/30000]: Train loss: 1.2941, Valid loss: 1.2742\n",
            "Epoch [143/30000]: Train loss: 1.2908, Valid loss: 1.2808\n",
            "Epoch [144/30000]: Train loss: 1.2938, Valid loss: 1.2733\n",
            "Epoch [145/30000]: Train loss: 1.2971, Valid loss: 1.2720\n",
            "Epoch [146/30000]: Train loss: 1.2929, Valid loss: 1.2593\n",
            "Saving model with loss 1.259...\n",
            "Epoch [147/30000]: Train loss: 1.2908, Valid loss: 1.2693\n",
            "Epoch [148/30000]: Train loss: 1.2900, Valid loss: 1.2710\n",
            "Epoch [149/30000]: Train loss: 1.2911, Valid loss: 1.2732\n",
            "Epoch [150/30000]: Train loss: 1.2918, Valid loss: 1.2855\n",
            "Epoch [151/30000]: Train loss: 1.2948, Valid loss: 1.2659\n",
            "Epoch [152/30000]: Train loss: 1.2896, Valid loss: 1.2701\n",
            "Epoch [153/30000]: Train loss: 1.2941, Valid loss: 1.2761\n",
            "Epoch [154/30000]: Train loss: 1.2920, Valid loss: 1.2700\n",
            "Epoch [155/30000]: Train loss: 1.2914, Valid loss: 1.2759\n",
            "Epoch [156/30000]: Train loss: 1.2904, Valid loss: 1.2751\n",
            "Epoch [157/30000]: Train loss: 1.2934, Valid loss: 1.2881\n",
            "Epoch [158/30000]: Train loss: 1.2939, Valid loss: 1.2813\n",
            "Epoch [159/30000]: Train loss: 1.2879, Valid loss: 1.2725\n",
            "Epoch [160/30000]: Train loss: 1.2900, Valid loss: 1.2587\n",
            "Saving model with loss 1.259...\n",
            "Epoch [161/30000]: Train loss: 1.2893, Valid loss: 1.2617\n",
            "Epoch [162/30000]: Train loss: 1.2899, Valid loss: 1.2859\n",
            "Epoch [163/30000]: Train loss: 1.2950, Valid loss: 1.2815\n",
            "Epoch [164/30000]: Train loss: 1.2905, Valid loss: 1.2847\n",
            "Epoch [165/30000]: Train loss: 1.2919, Valid loss: 1.2702\n",
            "Epoch [166/30000]: Train loss: 1.2854, Valid loss: 1.2832\n",
            "Epoch [167/30000]: Train loss: 1.2914, Valid loss: 1.2742\n",
            "Epoch [168/30000]: Train loss: 1.2910, Valid loss: 1.3105\n",
            "Epoch [169/30000]: Train loss: 1.2921, Valid loss: 1.2640\n",
            "Epoch [170/30000]: Train loss: 1.2889, Valid loss: 1.2686\n",
            "Epoch [171/30000]: Train loss: 1.2918, Valid loss: 1.2649\n",
            "Epoch [172/30000]: Train loss: 1.2927, Valid loss: 1.2516\n",
            "Saving model with loss 1.252...\n",
            "Epoch [173/30000]: Train loss: 1.2936, Valid loss: 1.2758\n",
            "Epoch [174/30000]: Train loss: 1.2919, Valid loss: 1.2704\n",
            "Epoch [175/30000]: Train loss: 1.2926, Valid loss: 1.2756\n",
            "Epoch [176/30000]: Train loss: 1.2949, Valid loss: 1.2770\n",
            "Epoch [177/30000]: Train loss: 1.2918, Valid loss: 1.2678\n",
            "Epoch [178/30000]: Train loss: 1.2890, Valid loss: 1.2925\n",
            "Epoch [179/30000]: Train loss: 1.2808, Valid loss: 1.2814\n",
            "Epoch [180/30000]: Train loss: 1.2920, Valid loss: 1.2773\n",
            "Epoch [181/30000]: Train loss: 1.2879, Valid loss: 1.2878\n",
            "Epoch [182/30000]: Train loss: 1.2909, Valid loss: 1.2702\n",
            "Epoch [183/30000]: Train loss: 1.2884, Valid loss: 1.2666\n",
            "Epoch [184/30000]: Train loss: 1.2942, Valid loss: 1.2847\n",
            "Epoch [185/30000]: Train loss: 1.2901, Valid loss: 1.2665\n",
            "Epoch [186/30000]: Train loss: 1.2876, Valid loss: 1.2948\n",
            "Epoch [187/30000]: Train loss: 1.2892, Valid loss: 1.2834\n",
            "Epoch [188/30000]: Train loss: 1.2882, Valid loss: 1.2637\n",
            "Epoch [189/30000]: Train loss: 1.2861, Valid loss: 1.2407\n",
            "Saving model with loss 1.241...\n",
            "Epoch [190/30000]: Train loss: 1.2938, Valid loss: 1.2732\n",
            "Epoch [191/30000]: Train loss: 1.2881, Valid loss: 1.2685\n",
            "Epoch [192/30000]: Train loss: 1.2917, Valid loss: 1.2853\n",
            "Epoch [193/30000]: Train loss: 1.2908, Valid loss: 1.2682\n",
            "Epoch [194/30000]: Train loss: 1.2897, Valid loss: 1.2670\n",
            "Epoch [195/30000]: Train loss: 1.2937, Valid loss: 1.2717\n",
            "Epoch [196/30000]: Train loss: 1.2906, Valid loss: 1.2611\n",
            "Epoch [197/30000]: Train loss: 1.2880, Valid loss: 1.2665\n",
            "Epoch [198/30000]: Train loss: 1.2859, Valid loss: 1.2658\n",
            "Epoch [199/30000]: Train loss: 1.2941, Valid loss: 1.2582\n",
            "Epoch [200/30000]: Train loss: 1.2886, Valid loss: 1.2820\n",
            "Epoch [201/30000]: Train loss: 1.2850, Valid loss: 1.2645\n",
            "Epoch [202/30000]: Train loss: 1.2918, Valid loss: 1.2772\n",
            "Epoch [203/30000]: Train loss: 1.2890, Valid loss: 1.2924\n",
            "Epoch [204/30000]: Train loss: 1.2917, Valid loss: 1.2792\n",
            "Epoch [205/30000]: Train loss: 1.2892, Valid loss: 1.2776\n",
            "Epoch [206/30000]: Train loss: 1.2921, Valid loss: 1.2691\n",
            "Epoch [207/30000]: Train loss: 1.2906, Valid loss: 1.2679\n",
            "Epoch [208/30000]: Train loss: 1.2869, Valid loss: 1.2726\n",
            "Epoch [209/30000]: Train loss: 1.2885, Valid loss: 1.2816\n",
            "Epoch [210/30000]: Train loss: 1.2940, Valid loss: 1.2716\n",
            "Epoch [211/30000]: Train loss: 1.2910, Valid loss: 1.2741\n",
            "Epoch [212/30000]: Train loss: 1.2957, Valid loss: 1.2587\n",
            "Epoch [213/30000]: Train loss: 1.2827, Valid loss: 1.2674\n",
            "Epoch [214/30000]: Train loss: 1.2912, Valid loss: 1.2681\n",
            "Epoch [215/30000]: Train loss: 1.2885, Valid loss: 1.2657\n",
            "Epoch [216/30000]: Train loss: 1.2902, Valid loss: 1.2775\n",
            "Epoch [217/30000]: Train loss: 1.2909, Valid loss: 1.2598\n",
            "Epoch [218/30000]: Train loss: 1.2872, Valid loss: 1.2724\n",
            "Epoch [219/30000]: Train loss: 1.2904, Valid loss: 1.2700\n",
            "Epoch [220/30000]: Train loss: 1.2864, Valid loss: 1.2722\n",
            "Epoch [221/30000]: Train loss: 1.2850, Valid loss: 1.2851\n",
            "Epoch [222/30000]: Train loss: 1.2898, Valid loss: 1.2546\n",
            "Epoch [223/30000]: Train loss: 1.2880, Valid loss: 1.2618\n",
            "Epoch [224/30000]: Train loss: 1.2876, Valid loss: 1.2774\n",
            "Epoch [225/30000]: Train loss: 1.2871, Valid loss: 1.2580\n",
            "Epoch [226/30000]: Train loss: 1.2863, Valid loss: 1.2604\n",
            "Epoch [227/30000]: Train loss: 1.2920, Valid loss: 1.2785\n",
            "Epoch [228/30000]: Train loss: 1.2923, Valid loss: 1.2615\n",
            "Epoch [229/30000]: Train loss: 1.2856, Valid loss: 1.2597\n",
            "Epoch [230/30000]: Train loss: 1.2875, Valid loss: 1.2724\n",
            "Epoch [231/30000]: Train loss: 1.2890, Valid loss: 1.2737\n",
            "Epoch [232/30000]: Train loss: 1.2911, Valid loss: 1.2545\n",
            "Epoch [233/30000]: Train loss: 1.2909, Valid loss: 1.2772\n",
            "Epoch [234/30000]: Train loss: 1.2878, Valid loss: 1.2637\n",
            "Epoch [235/30000]: Train loss: 1.2861, Valid loss: 1.2740\n",
            "Epoch [236/30000]: Train loss: 1.2887, Valid loss: 1.2653\n",
            "Epoch [237/30000]: Train loss: 1.2907, Valid loss: 1.3068\n",
            "Epoch [238/30000]: Train loss: 1.2853, Valid loss: 1.2622\n",
            "Epoch [239/30000]: Train loss: 1.2895, Valid loss: 1.2670\n",
            "Epoch [240/30000]: Train loss: 1.2916, Valid loss: 1.2878\n",
            "Epoch [241/30000]: Train loss: 1.2884, Valid loss: 1.2731\n",
            "Epoch [242/30000]: Train loss: 1.2863, Valid loss: 1.2747\n",
            "Epoch [243/30000]: Train loss: 1.2869, Valid loss: 1.2666\n",
            "Epoch [244/30000]: Train loss: 1.2881, Valid loss: 1.2757\n",
            "Epoch [245/30000]: Train loss: 1.2846, Valid loss: 1.2637\n",
            "Epoch [246/30000]: Train loss: 1.2849, Valid loss: 1.2665\n",
            "Epoch [247/30000]: Train loss: 1.2871, Valid loss: 1.2626\n",
            "Epoch [248/30000]: Train loss: 1.2819, Valid loss: 1.2629\n",
            "Epoch [249/30000]: Train loss: 1.2876, Valid loss: 1.2521\n",
            "Epoch [250/30000]: Train loss: 1.2887, Valid loss: 1.2846\n",
            "Epoch [251/30000]: Train loss: 1.2895, Valid loss: 1.2621\n",
            "Epoch [252/30000]: Train loss: 1.2870, Valid loss: 1.2680\n",
            "Epoch [253/30000]: Train loss: 1.2932, Valid loss: 1.2770\n",
            "Epoch [254/30000]: Train loss: 1.2879, Valid loss: 1.2484\n",
            "Epoch [255/30000]: Train loss: 1.2880, Valid loss: 1.2667\n",
            "Epoch [256/30000]: Train loss: 1.2876, Valid loss: 1.2684\n",
            "Epoch [257/30000]: Train loss: 1.2837, Valid loss: 1.2725\n",
            "Epoch [258/30000]: Train loss: 1.2864, Valid loss: 1.2813\n",
            "Epoch [259/30000]: Train loss: 1.2848, Valid loss: 1.2547\n",
            "Epoch [260/30000]: Train loss: 1.2923, Valid loss: 1.2719\n",
            "Epoch [261/30000]: Train loss: 1.2879, Valid loss: 1.2660\n",
            "Epoch [262/30000]: Train loss: 1.2845, Valid loss: 1.2634\n",
            "Epoch [263/30000]: Train loss: 1.2884, Valid loss: 1.2658\n",
            "Epoch [264/30000]: Train loss: 1.2867, Valid loss: 1.2578\n",
            "Epoch [265/30000]: Train loss: 1.2895, Valid loss: 1.2724\n",
            "Epoch [266/30000]: Train loss: 1.2861, Valid loss: 1.2665\n",
            "Epoch [267/30000]: Train loss: 1.2884, Valid loss: 1.2621\n",
            "Epoch [268/30000]: Train loss: 1.2865, Valid loss: 1.2630\n",
            "Epoch [269/30000]: Train loss: 1.2868, Valid loss: 1.2635\n",
            "Epoch [270/30000]: Train loss: 1.2796, Valid loss: 1.2673\n",
            "Epoch [271/30000]: Train loss: 1.2823, Valid loss: 1.2577\n",
            "Epoch [272/30000]: Train loss: 1.2850, Valid loss: 1.2806\n",
            "Epoch [273/30000]: Train loss: 1.2903, Valid loss: 1.2610\n",
            "Epoch [274/30000]: Train loss: 1.2847, Valid loss: 1.2701\n",
            "Epoch [275/30000]: Train loss: 1.2852, Valid loss: 1.2726\n",
            "Epoch [276/30000]: Train loss: 1.2883, Valid loss: 1.2669\n",
            "Epoch [277/30000]: Train loss: 1.2878, Valid loss: 1.2812\n",
            "Epoch [278/30000]: Train loss: 1.2852, Valid loss: 1.2565\n",
            "Epoch [279/30000]: Train loss: 1.2871, Valid loss: 1.2709\n",
            "Epoch [280/30000]: Train loss: 1.2884, Valid loss: 1.2845\n",
            "Epoch [281/30000]: Train loss: 1.2848, Valid loss: 1.2548\n",
            "Epoch [282/30000]: Train loss: 1.2863, Valid loss: 1.2570\n",
            "Epoch [283/30000]: Train loss: 1.2836, Valid loss: 1.2691\n",
            "Epoch [284/30000]: Train loss: 1.2875, Valid loss: 1.2676\n",
            "Epoch [285/30000]: Train loss: 1.2847, Valid loss: 1.2676\n",
            "Epoch [286/30000]: Train loss: 1.2884, Valid loss: 1.2579\n",
            "Epoch [287/30000]: Train loss: 1.2817, Valid loss: 1.2664\n",
            "Epoch [288/30000]: Train loss: 1.2813, Valid loss: 1.2653\n",
            "Epoch [289/30000]: Train loss: 1.2878, Valid loss: 1.2744\n",
            "Epoch [290/30000]: Train loss: 1.2904, Valid loss: 1.2638\n",
            "Epoch [291/30000]: Train loss: 1.2878, Valid loss: 1.2651\n",
            "Epoch [292/30000]: Train loss: 1.2867, Valid loss: 1.2647\n",
            "Epoch [293/30000]: Train loss: 1.2880, Valid loss: 1.2917\n",
            "Epoch [294/30000]: Train loss: 1.2899, Valid loss: 1.2738\n",
            "Epoch [295/30000]: Train loss: 1.2854, Valid loss: 1.2739\n",
            "Epoch [296/30000]: Train loss: 1.2847, Valid loss: 1.2758\n",
            "Epoch [297/30000]: Train loss: 1.2883, Valid loss: 1.2627\n",
            "Epoch [298/30000]: Train loss: 1.2888, Valid loss: 1.2713\n",
            "Epoch [299/30000]: Train loss: 1.2840, Valid loss: 1.2640\n",
            "Epoch [300/30000]: Train loss: 1.2890, Valid loss: 1.2678\n",
            "Epoch [301/30000]: Train loss: 1.2865, Valid loss: 1.2682\n",
            "Epoch [302/30000]: Train loss: 1.2931, Valid loss: 1.2957\n",
            "Epoch [303/30000]: Train loss: 1.2892, Valid loss: 1.2720\n",
            "Epoch [304/30000]: Train loss: 1.2878, Valid loss: 1.2783\n",
            "Epoch [305/30000]: Train loss: 1.2839, Valid loss: 1.2676\n",
            "Epoch [306/30000]: Train loss: 1.2901, Valid loss: 1.2609\n",
            "Epoch [307/30000]: Train loss: 1.2880, Valid loss: 1.2542\n",
            "Epoch [308/30000]: Train loss: 1.2889, Valid loss: 1.2711\n",
            "Epoch [309/30000]: Train loss: 1.2906, Valid loss: 1.2672\n",
            "Epoch [310/30000]: Train loss: 1.2872, Valid loss: 1.2593\n",
            "Epoch [311/30000]: Train loss: 1.2892, Valid loss: 1.2780\n",
            "Epoch [312/30000]: Train loss: 1.2869, Valid loss: 1.2663\n",
            "Epoch [313/30000]: Train loss: 1.2857, Valid loss: 1.2748\n",
            "Epoch [314/30000]: Train loss: 1.2875, Valid loss: 1.2846\n",
            "Epoch [315/30000]: Train loss: 1.2853, Valid loss: 1.2699\n",
            "Epoch [316/30000]: Train loss: 1.2891, Valid loss: 1.2726\n",
            "Epoch [317/30000]: Train loss: 1.2833, Valid loss: 1.2574\n",
            "Epoch [318/30000]: Train loss: 1.2874, Valid loss: 1.2662\n",
            "Epoch [319/30000]: Train loss: 1.2859, Valid loss: 1.2618\n",
            "Epoch [320/30000]: Train loss: 1.2886, Valid loss: 1.2708\n",
            "Epoch [321/30000]: Train loss: 1.2837, Valid loss: 1.2588\n",
            "Epoch [322/30000]: Train loss: 1.2867, Valid loss: 1.2683\n",
            "Epoch [323/30000]: Train loss: 1.2841, Valid loss: 1.2605\n",
            "Epoch [324/30000]: Train loss: 1.2838, Valid loss: 1.2554\n",
            "Epoch [325/30000]: Train loss: 1.2876, Valid loss: 1.2482\n",
            "Epoch [326/30000]: Train loss: 1.2849, Valid loss: 1.2732\n",
            "Epoch [327/30000]: Train loss: 1.2837, Valid loss: 1.2781\n",
            "Epoch [328/30000]: Train loss: 1.2898, Valid loss: 1.2726\n",
            "Epoch [329/30000]: Train loss: 1.2882, Valid loss: 1.2584\n",
            "Epoch [330/30000]: Train loss: 1.2826, Valid loss: 1.2548\n",
            "Epoch [331/30000]: Train loss: 1.2848, Valid loss: 1.2673\n",
            "Epoch [332/30000]: Train loss: 1.2836, Valid loss: 1.2580\n",
            "Epoch [333/30000]: Train loss: 1.2872, Valid loss: 1.2540\n",
            "Epoch [334/30000]: Train loss: 1.2878, Valid loss: 1.2537\n",
            "Epoch [335/30000]: Train loss: 1.2877, Valid loss: 1.2847\n",
            "Epoch [336/30000]: Train loss: 1.2861, Valid loss: 1.2598\n",
            "Epoch [337/30000]: Train loss: 1.2775, Valid loss: 1.2707\n",
            "Epoch [338/30000]: Train loss: 1.2907, Valid loss: 1.2522\n",
            "Epoch [339/30000]: Train loss: 1.2856, Valid loss: 1.2618\n",
            "Epoch [340/30000]: Train loss: 1.2872, Valid loss: 1.2620\n",
            "Epoch [341/30000]: Train loss: 1.2832, Valid loss: 1.2782\n",
            "Epoch [342/30000]: Train loss: 1.2904, Valid loss: 1.2817\n",
            "Epoch [343/30000]: Train loss: 1.2861, Valid loss: 1.2634\n",
            "Epoch [344/30000]: Train loss: 1.2841, Valid loss: 1.2737\n",
            "Epoch [345/30000]: Train loss: 1.2878, Valid loss: 1.2669\n",
            "Epoch [346/30000]: Train loss: 1.2858, Valid loss: 1.2857\n",
            "Epoch [347/30000]: Train loss: 1.2835, Valid loss: 1.2493\n",
            "Epoch [348/30000]: Train loss: 1.2886, Valid loss: 1.2636\n",
            "Epoch [349/30000]: Train loss: 1.2880, Valid loss: 1.2698\n",
            "Epoch [350/30000]: Train loss: 1.2915, Valid loss: 1.2685\n",
            "Epoch [351/30000]: Train loss: 1.2820, Valid loss: 1.2847\n",
            "Epoch [352/30000]: Train loss: 1.2871, Valid loss: 1.2651\n",
            "Epoch [353/30000]: Train loss: 1.2878, Valid loss: 1.2614\n",
            "Epoch [354/30000]: Train loss: 1.2867, Valid loss: 1.2731\n",
            "Epoch [355/30000]: Train loss: 1.2867, Valid loss: 1.2576\n",
            "Epoch [356/30000]: Train loss: 1.2861, Valid loss: 1.2696\n",
            "Epoch [357/30000]: Train loss: 1.2873, Valid loss: 1.2647\n",
            "Epoch [358/30000]: Train loss: 1.2857, Valid loss: 1.2709\n",
            "Epoch [359/30000]: Train loss: 1.2835, Valid loss: 1.2440\n",
            "Epoch [360/30000]: Train loss: 1.2863, Valid loss: 1.2700\n",
            "Epoch [361/30000]: Train loss: 1.2859, Valid loss: 1.2650\n",
            "Epoch [362/30000]: Train loss: 1.2846, Valid loss: 1.2608\n",
            "Epoch [363/30000]: Train loss: 1.2851, Valid loss: 1.2753\n",
            "Epoch [364/30000]: Train loss: 1.2892, Valid loss: 1.2519\n",
            "Epoch [365/30000]: Train loss: 1.2818, Valid loss: 1.2546\n",
            "Epoch [366/30000]: Train loss: 1.2883, Valid loss: 1.2682\n",
            "Epoch [367/30000]: Train loss: 1.2885, Valid loss: 1.2703\n",
            "Epoch [368/30000]: Train loss: 1.2922, Valid loss: 1.2748\n",
            "Epoch [369/30000]: Train loss: 1.2859, Valid loss: 1.2730\n",
            "Epoch [370/30000]: Train loss: 1.2849, Valid loss: 1.2722\n",
            "Epoch [371/30000]: Train loss: 1.2873, Valid loss: 1.2522\n",
            "Epoch [372/30000]: Train loss: 1.2869, Valid loss: 1.2819\n",
            "Epoch [373/30000]: Train loss: 1.2868, Valid loss: 1.2676\n",
            "Epoch [374/30000]: Train loss: 1.2873, Valid loss: 1.2586\n",
            "Epoch [375/30000]: Train loss: 1.2859, Valid loss: 1.2554\n",
            "Epoch [376/30000]: Train loss: 1.2871, Valid loss: 1.2499\n",
            "Epoch [377/30000]: Train loss: 1.2848, Valid loss: 1.2795\n",
            "Epoch [378/30000]: Train loss: 1.2878, Valid loss: 1.2512\n",
            "Epoch [379/30000]: Train loss: 1.2903, Valid loss: 1.2803\n",
            "Epoch [380/30000]: Train loss: 1.2852, Valid loss: 1.2652\n",
            "Epoch [381/30000]: Train loss: 1.2856, Valid loss: 1.2470\n",
            "Epoch [382/30000]: Train loss: 1.2867, Valid loss: 1.2585\n",
            "Epoch [383/30000]: Train loss: 1.2869, Valid loss: 1.2782\n",
            "Epoch [384/30000]: Train loss: 1.2876, Valid loss: 1.2686\n",
            "Epoch [385/30000]: Train loss: 1.2832, Valid loss: 1.2622\n",
            "Epoch [386/30000]: Train loss: 1.2850, Valid loss: 1.2559\n",
            "Epoch [387/30000]: Train loss: 1.2833, Valid loss: 1.2766\n",
            "Epoch [388/30000]: Train loss: 1.2845, Valid loss: 1.2703\n",
            "Epoch [389/30000]: Train loss: 1.2869, Valid loss: 1.2636\n",
            "Epoch [390/30000]: Train loss: 1.2870, Valid loss: 1.2787\n",
            "Epoch [391/30000]: Train loss: 1.2868, Valid loss: 1.2645\n",
            "Epoch [392/30000]: Train loss: 1.2841, Valid loss: 1.2708\n",
            "Epoch [393/30000]: Train loss: 1.2848, Valid loss: 1.2585\n",
            "Epoch [394/30000]: Train loss: 1.2875, Valid loss: 1.2758\n",
            "Epoch [395/30000]: Train loss: 1.2843, Valid loss: 1.2650\n",
            "Epoch [396/30000]: Train loss: 1.2809, Valid loss: 1.2719\n",
            "Epoch [397/30000]: Train loss: 1.2821, Valid loss: 1.2743\n",
            "Epoch [398/30000]: Train loss: 1.2842, Valid loss: 1.2791\n",
            "Epoch [399/30000]: Train loss: 1.2841, Valid loss: 1.2560\n",
            "Epoch [400/30000]: Train loss: 1.2862, Valid loss: 1.2545\n",
            "Epoch [401/30000]: Train loss: 1.2872, Valid loss: 1.2519\n",
            "Epoch [402/30000]: Train loss: 1.2867, Valid loss: 1.2595\n",
            "Epoch [403/30000]: Train loss: 1.2832, Valid loss: 1.2645\n",
            "Epoch [404/30000]: Train loss: 1.2876, Valid loss: 1.2511\n",
            "Epoch [405/30000]: Train loss: 1.2900, Valid loss: 1.2675\n",
            "Epoch [406/30000]: Train loss: 1.2842, Valid loss: 1.2639\n",
            "Epoch [407/30000]: Train loss: 1.2859, Valid loss: 1.2691\n",
            "Epoch [408/30000]: Train loss: 1.2828, Valid loss: 1.2644\n",
            "Epoch [409/30000]: Train loss: 1.2856, Valid loss: 1.2568\n",
            "Epoch [410/30000]: Train loss: 1.2882, Valid loss: 1.2646\n",
            "Epoch [411/30000]: Train loss: 1.2918, Valid loss: 1.2605\n",
            "Epoch [412/30000]: Train loss: 1.2914, Valid loss: 1.2697\n",
            "Epoch [413/30000]: Train loss: 1.2877, Valid loss: 1.2599\n",
            "Epoch [414/30000]: Train loss: 1.2874, Valid loss: 1.2736\n",
            "Epoch [415/30000]: Train loss: 1.2845, Valid loss: 1.2652\n",
            "Epoch [416/30000]: Train loss: 1.2844, Valid loss: 1.2681\n",
            "Epoch [417/30000]: Train loss: 1.2854, Valid loss: 1.2603\n",
            "Epoch [418/30000]: Train loss: 1.2861, Valid loss: 1.2708\n",
            "Epoch [419/30000]: Train loss: 1.2858, Valid loss: 1.2538\n",
            "Epoch [420/30000]: Train loss: 1.2900, Valid loss: 1.2628\n",
            "Epoch [421/30000]: Train loss: 1.2826, Valid loss: 1.2603\n",
            "Epoch [422/30000]: Train loss: 1.2868, Valid loss: 1.2545\n",
            "Epoch [423/30000]: Train loss: 1.2852, Valid loss: 1.2886\n",
            "Epoch [424/30000]: Train loss: 1.2849, Valid loss: 1.2756\n",
            "Epoch [425/30000]: Train loss: 1.2913, Valid loss: 1.2803\n",
            "Epoch [426/30000]: Train loss: 1.2836, Valid loss: 1.2761\n",
            "Epoch [427/30000]: Train loss: 1.2843, Valid loss: 1.2590\n",
            "Epoch [428/30000]: Train loss: 1.2844, Valid loss: 1.2698\n",
            "Epoch [429/30000]: Train loss: 1.2891, Valid loss: 1.2581\n",
            "Epoch [430/30000]: Train loss: 1.2852, Valid loss: 1.2621\n",
            "Epoch [431/30000]: Train loss: 1.2881, Valid loss: 1.2562\n",
            "Epoch [432/30000]: Train loss: 1.2868, Valid loss: 1.2605\n",
            "Epoch [433/30000]: Train loss: 1.2869, Valid loss: 1.2725\n",
            "Epoch [434/30000]: Train loss: 1.2866, Valid loss: 1.2608\n",
            "Epoch [435/30000]: Train loss: 1.2876, Valid loss: 1.2569\n",
            "Epoch [436/30000]: Train loss: 1.2848, Valid loss: 1.2727\n",
            "Epoch [437/30000]: Train loss: 1.2833, Valid loss: 1.2769\n",
            "Epoch [438/30000]: Train loss: 1.2827, Valid loss: 1.2542\n",
            "Epoch [439/30000]: Train loss: 1.2854, Valid loss: 1.2741\n",
            "Epoch [440/30000]: Train loss: 1.2848, Valid loss: 1.2753\n",
            "Epoch [441/30000]: Train loss: 1.2880, Valid loss: 1.2633\n",
            "Epoch [442/30000]: Train loss: 1.2850, Valid loss: 1.2606\n",
            "Epoch [443/30000]: Train loss: 1.2841, Valid loss: 1.2551\n",
            "Epoch [444/30000]: Train loss: 1.2813, Valid loss: 1.2669\n",
            "Epoch [445/30000]: Train loss: 1.2869, Valid loss: 1.2574\n",
            "Epoch [446/30000]: Train loss: 1.2860, Valid loss: 1.2707\n",
            "Epoch [447/30000]: Train loss: 1.2843, Valid loss: 1.2662\n",
            "Epoch [448/30000]: Train loss: 1.2859, Valid loss: 1.2609\n",
            "Epoch [449/30000]: Train loss: 1.2863, Valid loss: 1.2681\n",
            "Epoch [450/30000]: Train loss: 1.2867, Valid loss: 1.2620\n",
            "Epoch [451/30000]: Train loss: 1.2861, Valid loss: 1.2658\n",
            "Epoch [452/30000]: Train loss: 1.2892, Valid loss: 1.2559\n",
            "Epoch [453/30000]: Train loss: 1.2849, Valid loss: 1.2595\n",
            "Epoch [454/30000]: Train loss: 1.2870, Valid loss: 1.2677\n",
            "Epoch [455/30000]: Train loss: 1.2843, Valid loss: 1.2716\n",
            "Epoch [456/30000]: Train loss: 1.2843, Valid loss: 1.2731\n",
            "Epoch [457/30000]: Train loss: 1.2876, Valid loss: 1.2645\n",
            "Epoch [458/30000]: Train loss: 1.2854, Valid loss: 1.2791\n",
            "Epoch [459/30000]: Train loss: 1.2856, Valid loss: 1.2809\n",
            "Epoch [460/30000]: Train loss: 1.2851, Valid loss: 1.2651\n",
            "Epoch [461/30000]: Train loss: 1.2871, Valid loss: 1.2739\n",
            "Epoch [462/30000]: Train loss: 1.2873, Valid loss: 1.2641\n",
            "Epoch [463/30000]: Train loss: 1.2890, Valid loss: 1.2637\n",
            "Epoch [464/30000]: Train loss: 1.2834, Valid loss: 1.2635\n",
            "Epoch [465/30000]: Train loss: 1.2850, Valid loss: 1.2638\n",
            "Epoch [466/30000]: Train loss: 1.2870, Valid loss: 1.2735\n",
            "Epoch [467/30000]: Train loss: 1.2843, Valid loss: 1.2782\n",
            "Epoch [468/30000]: Train loss: 1.2805, Valid loss: 1.2695\n",
            "Epoch [469/30000]: Train loss: 1.2868, Valid loss: 1.2636\n",
            "Epoch [470/30000]: Train loss: 1.2860, Valid loss: 1.2687\n",
            "Epoch [471/30000]: Train loss: 1.2873, Valid loss: 1.2695\n",
            "Epoch [472/30000]: Train loss: 1.2879, Valid loss: 1.2534\n",
            "Epoch [473/30000]: Train loss: 1.2900, Valid loss: 1.2615\n",
            "Epoch [474/30000]: Train loss: 1.2871, Valid loss: 1.2696\n",
            "Epoch [475/30000]: Train loss: 1.2898, Valid loss: 1.2503\n",
            "Epoch [476/30000]: Train loss: 1.2867, Valid loss: 1.2649\n",
            "Epoch [477/30000]: Train loss: 1.2859, Valid loss: 1.2633\n",
            "Epoch [478/30000]: Train loss: 1.2827, Valid loss: 1.2629\n",
            "Epoch [479/30000]: Train loss: 1.2851, Valid loss: 1.2745\n",
            "Epoch [480/30000]: Train loss: 1.2850, Valid loss: 1.2554\n",
            "Epoch [481/30000]: Train loss: 1.2856, Valid loss: 1.2753\n",
            "Epoch [482/30000]: Train loss: 1.2891, Valid loss: 1.2634\n",
            "Epoch [483/30000]: Train loss: 1.2855, Valid loss: 1.2815\n",
            "Epoch [484/30000]: Train loss: 1.2839, Valid loss: 1.2813\n",
            "Epoch [485/30000]: Train loss: 1.2895, Valid loss: 1.2704\n",
            "Epoch [486/30000]: Train loss: 1.2889, Valid loss: 1.2740\n",
            "Epoch [487/30000]: Train loss: 1.2852, Valid loss: 1.2550\n",
            "Epoch [488/30000]: Train loss: 1.2824, Valid loss: 1.2716\n",
            "Epoch [489/30000]: Train loss: 1.2851, Valid loss: 1.2673\n",
            "Epoch [490/30000]: Train loss: 1.2851, Valid loss: 1.2402\n",
            "Saving model with loss 1.240...\n",
            "Epoch [491/30000]: Train loss: 1.2837, Valid loss: 1.2835\n",
            "Epoch [492/30000]: Train loss: 1.2899, Valid loss: 1.2628\n",
            "Epoch [493/30000]: Train loss: 1.2813, Valid loss: 1.2774\n",
            "Epoch [494/30000]: Train loss: 1.2841, Valid loss: 1.2666\n",
            "Epoch [495/30000]: Train loss: 1.2890, Valid loss: 1.2623\n",
            "Epoch [496/30000]: Train loss: 1.2828, Valid loss: 1.2706\n",
            "Epoch [497/30000]: Train loss: 1.2887, Valid loss: 1.2541\n",
            "Epoch [498/30000]: Train loss: 1.2865, Valid loss: 1.2699\n",
            "Epoch [499/30000]: Train loss: 1.2873, Valid loss: 1.2718\n",
            "Epoch [500/30000]: Train loss: 1.2867, Valid loss: 1.2723\n",
            "Epoch [501/30000]: Train loss: 1.2851, Valid loss: 1.2676\n",
            "Epoch [502/30000]: Train loss: 1.2870, Valid loss: 1.2756\n",
            "Epoch [503/30000]: Train loss: 1.2851, Valid loss: 1.2766\n",
            "Epoch [504/30000]: Train loss: 1.2820, Valid loss: 1.2744\n",
            "Epoch [505/30000]: Train loss: 1.2848, Valid loss: 1.2642\n",
            "Epoch [506/30000]: Train loss: 1.2832, Valid loss: 1.2573\n",
            "Epoch [507/30000]: Train loss: 1.2854, Valid loss: 1.2781\n",
            "Epoch [508/30000]: Train loss: 1.2846, Valid loss: 1.2818\n",
            "Epoch [509/30000]: Train loss: 1.2889, Valid loss: 1.2647\n",
            "Epoch [510/30000]: Train loss: 1.2817, Valid loss: 1.2684\n",
            "Epoch [511/30000]: Train loss: 1.2854, Valid loss: 1.2698\n",
            "Epoch [512/30000]: Train loss: 1.2864, Valid loss: 1.2580\n",
            "Epoch [513/30000]: Train loss: 1.2830, Valid loss: 1.2552\n",
            "Epoch [514/30000]: Train loss: 1.2884, Valid loss: 1.2754\n",
            "Epoch [515/30000]: Train loss: 1.2868, Valid loss: 1.2736\n",
            "Epoch [516/30000]: Train loss: 1.2847, Valid loss: 1.2644\n",
            "Epoch [517/30000]: Train loss: 1.2908, Valid loss: 1.2666\n",
            "Epoch [518/30000]: Train loss: 1.2860, Valid loss: 1.2683\n",
            "Epoch [519/30000]: Train loss: 1.2842, Valid loss: 1.2606\n",
            "Epoch [520/30000]: Train loss: 1.2810, Valid loss: 1.2744\n",
            "Epoch [521/30000]: Train loss: 1.2806, Valid loss: 1.2986\n",
            "Epoch [522/30000]: Train loss: 1.2896, Valid loss: 1.2766\n",
            "Epoch [523/30000]: Train loss: 1.2836, Valid loss: 1.2700\n",
            "Epoch [524/30000]: Train loss: 1.2857, Valid loss: 1.2673\n",
            "Epoch [525/30000]: Train loss: 1.2844, Valid loss: 1.2482\n",
            "Epoch [526/30000]: Train loss: 1.2851, Valid loss: 1.2721\n",
            "Epoch [527/30000]: Train loss: 1.2897, Valid loss: 1.2587\n",
            "Epoch [528/30000]: Train loss: 1.2861, Valid loss: 1.2680\n",
            "Epoch [529/30000]: Train loss: 1.2862, Valid loss: 1.2590\n",
            "Epoch [530/30000]: Train loss: 1.2838, Valid loss: 1.2787\n",
            "Epoch [531/30000]: Train loss: 1.2852, Valid loss: 1.2498\n",
            "Epoch [532/30000]: Train loss: 1.2850, Valid loss: 1.2647\n",
            "Epoch [533/30000]: Train loss: 1.2865, Valid loss: 1.2753\n",
            "Epoch [534/30000]: Train loss: 1.2871, Valid loss: 1.2643\n",
            "Epoch [535/30000]: Train loss: 1.2843, Valid loss: 1.2648\n",
            "Epoch [536/30000]: Train loss: 1.2899, Valid loss: 1.2562\n",
            "Epoch [537/30000]: Train loss: 1.2855, Valid loss: 1.2750\n",
            "Epoch [538/30000]: Train loss: 1.2851, Valid loss: 1.2508\n",
            "Epoch [539/30000]: Train loss: 1.2869, Valid loss: 1.2649\n",
            "Epoch [540/30000]: Train loss: 1.2830, Valid loss: 1.2640\n",
            "Epoch [541/30000]: Train loss: 1.2868, Valid loss: 1.2752\n",
            "Epoch [542/30000]: Train loss: 1.2805, Valid loss: 1.2610\n",
            "Epoch [543/30000]: Train loss: 1.2843, Valid loss: 1.2624\n",
            "Epoch [544/30000]: Train loss: 1.2854, Valid loss: 1.2625\n",
            "Epoch [545/30000]: Train loss: 1.2828, Valid loss: 1.2621\n",
            "Epoch [546/30000]: Train loss: 1.2850, Valid loss: 1.2690\n",
            "Epoch [547/30000]: Train loss: 1.2839, Valid loss: 1.2563\n",
            "Epoch [548/30000]: Train loss: 1.2802, Valid loss: 1.2539\n",
            "Epoch [549/30000]: Train loss: 1.2852, Valid loss: 1.2642\n",
            "Epoch [550/30000]: Train loss: 1.2876, Valid loss: 1.2632\n",
            "Epoch [551/30000]: Train loss: 1.2856, Valid loss: 1.2652\n",
            "Epoch [552/30000]: Train loss: 1.2850, Valid loss: 1.2534\n",
            "Epoch [553/30000]: Train loss: 1.2852, Valid loss: 1.2589\n",
            "Epoch [554/30000]: Train loss: 1.2855, Valid loss: 1.2728\n",
            "Epoch [555/30000]: Train loss: 1.2806, Valid loss: 1.2706\n",
            "Epoch [556/30000]: Train loss: 1.2888, Valid loss: 1.2690\n",
            "Epoch [557/30000]: Train loss: 1.2912, Valid loss: 1.2632\n",
            "Epoch [558/30000]: Train loss: 1.2840, Valid loss: 1.2566\n",
            "Epoch [559/30000]: Train loss: 1.2879, Valid loss: 1.2564\n",
            "Epoch [560/30000]: Train loss: 1.2814, Valid loss: 1.2769\n",
            "Epoch [561/30000]: Train loss: 1.2820, Valid loss: 1.2601\n",
            "Epoch [562/30000]: Train loss: 1.2844, Valid loss: 1.2662\n",
            "Epoch [563/30000]: Train loss: 1.2861, Valid loss: 1.2568\n",
            "Epoch [564/30000]: Train loss: 1.2879, Valid loss: 1.2615\n",
            "Epoch [565/30000]: Train loss: 1.2844, Valid loss: 1.2770\n",
            "Epoch [566/30000]: Train loss: 1.2838, Valid loss: 1.2723\n",
            "Epoch [567/30000]: Train loss: 1.2862, Valid loss: 1.2626\n",
            "Epoch [568/30000]: Train loss: 1.2845, Valid loss: 1.2511\n",
            "Epoch [569/30000]: Train loss: 1.2806, Valid loss: 1.2666\n",
            "Epoch [570/30000]: Train loss: 1.2855, Valid loss: 1.2695\n",
            "Epoch [571/30000]: Train loss: 1.2827, Valid loss: 1.2641\n",
            "Epoch [572/30000]: Train loss: 1.2857, Valid loss: 1.2682\n",
            "Epoch [573/30000]: Train loss: 1.2829, Valid loss: 1.2710\n",
            "Epoch [574/30000]: Train loss: 1.2869, Valid loss: 1.2632\n",
            "Epoch [575/30000]: Train loss: 1.2887, Valid loss: 1.2763\n",
            "Epoch [576/30000]: Train loss: 1.2838, Valid loss: 1.2648\n",
            "Epoch [577/30000]: Train loss: 1.2874, Valid loss: 1.2615\n",
            "Epoch [578/30000]: Train loss: 1.2809, Valid loss: 1.2732\n",
            "Epoch [579/30000]: Train loss: 1.2832, Valid loss: 1.2574\n",
            "Epoch [580/30000]: Train loss: 1.2829, Valid loss: 1.2524\n",
            "Epoch [581/30000]: Train loss: 1.2869, Valid loss: 1.2489\n",
            "Epoch [582/30000]: Train loss: 1.2840, Valid loss: 1.2597\n",
            "Epoch [583/30000]: Train loss: 1.2843, Valid loss: 1.2555\n",
            "Epoch [584/30000]: Train loss: 1.2842, Valid loss: 1.2698\n",
            "Epoch [585/30000]: Train loss: 1.2843, Valid loss: 1.2678\n",
            "Epoch [586/30000]: Train loss: 1.2844, Valid loss: 1.2645\n",
            "Epoch [587/30000]: Train loss: 1.2872, Valid loss: 1.2634\n",
            "Epoch [588/30000]: Train loss: 1.2862, Valid loss: 1.2589\n",
            "Epoch [589/30000]: Train loss: 1.2864, Valid loss: 1.2634\n",
            "Epoch [590/30000]: Train loss: 1.2812, Valid loss: 1.2597\n",
            "Epoch [591/30000]: Train loss: 1.2801, Valid loss: 1.2711\n",
            "Epoch [592/30000]: Train loss: 1.2839, Valid loss: 1.2647\n",
            "Epoch [593/30000]: Train loss: 1.2837, Valid loss: 1.2651\n",
            "Epoch [594/30000]: Train loss: 1.2839, Valid loss: 1.2780\n",
            "Epoch [595/30000]: Train loss: 1.2866, Valid loss: 1.2836\n",
            "Epoch [596/30000]: Train loss: 1.2866, Valid loss: 1.2671\n",
            "Epoch [597/30000]: Train loss: 1.2835, Valid loss: 1.2743\n",
            "Epoch [598/30000]: Train loss: 1.2886, Valid loss: 1.2597\n",
            "Epoch [599/30000]: Train loss: 1.2845, Valid loss: 1.2661\n",
            "Epoch [600/30000]: Train loss: 1.2843, Valid loss: 1.2523\n",
            "Epoch [601/30000]: Train loss: 1.2853, Valid loss: 1.2687\n",
            "Epoch [602/30000]: Train loss: 1.2862, Valid loss: 1.2635\n",
            "Epoch [603/30000]: Train loss: 1.2825, Valid loss: 1.2662\n",
            "Epoch [604/30000]: Train loss: 1.2822, Valid loss: 1.2725\n",
            "Epoch [605/30000]: Train loss: 1.2853, Valid loss: 1.2741\n",
            "Epoch [606/30000]: Train loss: 1.2831, Valid loss: 1.2575\n",
            "Epoch [607/30000]: Train loss: 1.2834, Valid loss: 1.2617\n",
            "Epoch [608/30000]: Train loss: 1.2801, Valid loss: 1.2724\n",
            "Epoch [609/30000]: Train loss: 1.2827, Valid loss: 1.2616\n",
            "Epoch [610/30000]: Train loss: 1.2851, Valid loss: 1.2763\n",
            "Epoch [611/30000]: Train loss: 1.2871, Valid loss: 1.2765\n",
            "Epoch [612/30000]: Train loss: 1.2862, Valid loss: 1.2800\n",
            "Epoch [613/30000]: Train loss: 1.2837, Valid loss: 1.2787\n",
            "Epoch [614/30000]: Train loss: 1.2852, Valid loss: 1.2716\n",
            "Epoch [615/30000]: Train loss: 1.2825, Valid loss: 1.2777\n",
            "Epoch [616/30000]: Train loss: 1.2817, Valid loss: 1.2677\n",
            "Epoch [617/30000]: Train loss: 1.2864, Valid loss: 1.2787\n",
            "Epoch [618/30000]: Train loss: 1.2869, Valid loss: 1.2672\n",
            "Epoch [619/30000]: Train loss: 1.2847, Valid loss: 1.2704\n",
            "Epoch [620/30000]: Train loss: 1.2836, Valid loss: 1.2559\n",
            "Epoch [621/30000]: Train loss: 1.2861, Valid loss: 1.2923\n",
            "Epoch [622/30000]: Train loss: 1.2868, Valid loss: 1.2607\n",
            "Epoch [623/30000]: Train loss: 1.2840, Valid loss: 1.2626\n",
            "Epoch [624/30000]: Train loss: 1.2845, Valid loss: 1.2684\n",
            "Epoch [625/30000]: Train loss: 1.2876, Valid loss: 1.2738\n",
            "Epoch [626/30000]: Train loss: 1.2856, Valid loss: 1.2591\n",
            "Epoch [627/30000]: Train loss: 1.2871, Valid loss: 1.2735\n",
            "Epoch [628/30000]: Train loss: 1.2844, Valid loss: 1.2495\n",
            "Epoch [629/30000]: Train loss: 1.2842, Valid loss: 1.2652\n",
            "Epoch [630/30000]: Train loss: 1.2820, Valid loss: 1.2867\n",
            "Epoch [631/30000]: Train loss: 1.2787, Valid loss: 1.2580\n",
            "Epoch [632/30000]: Train loss: 1.2831, Valid loss: 1.2552\n",
            "Epoch [633/30000]: Train loss: 1.2839, Valid loss: 1.2753\n",
            "Epoch [634/30000]: Train loss: 1.2831, Valid loss: 1.2684\n",
            "Epoch [635/30000]: Train loss: 1.2847, Valid loss: 1.2591\n",
            "Epoch [636/30000]: Train loss: 1.2840, Valid loss: 1.2588\n",
            "Epoch [637/30000]: Train loss: 1.2820, Valid loss: 1.2697\n",
            "Epoch [638/30000]: Train loss: 1.2841, Valid loss: 1.2606\n",
            "Epoch [639/30000]: Train loss: 1.2840, Valid loss: 1.2636\n",
            "Epoch [640/30000]: Train loss: 1.2834, Valid loss: 1.2716\n",
            "Epoch [641/30000]: Train loss: 1.2882, Valid loss: 1.2616\n",
            "Epoch [642/30000]: Train loss: 1.2895, Valid loss: 1.2636\n",
            "Epoch [643/30000]: Train loss: 1.2819, Valid loss: 1.2461\n",
            "Epoch [644/30000]: Train loss: 1.2815, Valid loss: 1.2634\n",
            "Epoch [645/30000]: Train loss: 1.2821, Valid loss: 1.2626\n",
            "Epoch [646/30000]: Train loss: 1.2866, Valid loss: 1.2577\n",
            "Epoch [647/30000]: Train loss: 1.2834, Valid loss: 1.2681\n",
            "Epoch [648/30000]: Train loss: 1.2827, Valid loss: 1.2562\n",
            "Epoch [649/30000]: Train loss: 1.2813, Valid loss: 1.2489\n",
            "Epoch [650/30000]: Train loss: 1.2830, Valid loss: 1.2778\n",
            "Epoch [651/30000]: Train loss: 1.2829, Valid loss: 1.2831\n",
            "Epoch [652/30000]: Train loss: 1.2859, Valid loss: 1.2732\n",
            "Epoch [653/30000]: Train loss: 1.2823, Valid loss: 1.2782\n",
            "Epoch [654/30000]: Train loss: 1.2843, Valid loss: 1.2652\n",
            "Epoch [655/30000]: Train loss: 1.2790, Valid loss: 1.2602\n",
            "Epoch [656/30000]: Train loss: 1.2864, Valid loss: 1.2622\n",
            "Epoch [657/30000]: Train loss: 1.2861, Valid loss: 1.2729\n",
            "Epoch [658/30000]: Train loss: 1.2864, Valid loss: 1.2521\n",
            "Epoch [659/30000]: Train loss: 1.2818, Valid loss: 1.2767\n",
            "Epoch [660/30000]: Train loss: 1.2847, Valid loss: 1.2618\n",
            "Epoch [661/30000]: Train loss: 1.2847, Valid loss: 1.2745\n",
            "Epoch [662/30000]: Train loss: 1.2864, Valid loss: 1.2521\n",
            "Epoch [663/30000]: Train loss: 1.2823, Valid loss: 1.2593\n",
            "Epoch [664/30000]: Train loss: 1.2776, Valid loss: 1.2551\n",
            "Epoch [665/30000]: Train loss: 1.2843, Valid loss: 1.2757\n",
            "Epoch [666/30000]: Train loss: 1.2872, Valid loss: 1.2643\n",
            "Epoch [667/30000]: Train loss: 1.2822, Valid loss: 1.2473\n",
            "Epoch [668/30000]: Train loss: 1.2815, Valid loss: 1.2829\n",
            "Epoch [669/30000]: Train loss: 1.2866, Valid loss: 1.2604\n",
            "Epoch [670/30000]: Train loss: 1.2813, Valid loss: 1.2687\n",
            "Epoch [671/30000]: Train loss: 1.2784, Valid loss: 1.2642\n",
            "Epoch [672/30000]: Train loss: 1.2858, Valid loss: 1.2497\n",
            "Epoch [673/30000]: Train loss: 1.2810, Valid loss: 1.2541\n",
            "Epoch [674/30000]: Train loss: 1.2822, Valid loss: 1.2612\n",
            "Epoch [675/30000]: Train loss: 1.2858, Valid loss: 1.2632\n",
            "Epoch [676/30000]: Train loss: 1.2821, Valid loss: 1.2594\n",
            "Epoch [677/30000]: Train loss: 1.2833, Valid loss: 1.2677\n",
            "Epoch [678/30000]: Train loss: 1.2862, Valid loss: 1.2584\n",
            "Epoch [679/30000]: Train loss: 1.2867, Valid loss: 1.2635\n",
            "Epoch [680/30000]: Train loss: 1.2816, Valid loss: 1.2553\n",
            "Epoch [681/30000]: Train loss: 1.2832, Valid loss: 1.2757\n",
            "Epoch [682/30000]: Train loss: 1.2863, Valid loss: 1.2663\n",
            "Epoch [683/30000]: Train loss: 1.2817, Valid loss: 1.2635\n",
            "Epoch [684/30000]: Train loss: 1.2820, Valid loss: 1.2516\n",
            "Epoch [685/30000]: Train loss: 1.2840, Valid loss: 1.2777\n",
            "Epoch [686/30000]: Train loss: 1.2807, Valid loss: 1.2672\n",
            "Epoch [687/30000]: Train loss: 1.2794, Valid loss: 1.2602\n",
            "Epoch [688/30000]: Train loss: 1.2827, Valid loss: 1.2507\n",
            "Epoch [689/30000]: Train loss: 1.2822, Valid loss: 1.2657\n",
            "Epoch [690/30000]: Train loss: 1.2854, Valid loss: 1.2633\n",
            "Epoch [691/30000]: Train loss: 1.2819, Valid loss: 1.2656\n",
            "Epoch [692/30000]: Train loss: 1.2842, Valid loss: 1.2532\n",
            "Epoch [693/30000]: Train loss: 1.2780, Valid loss: 1.2505\n",
            "Epoch [694/30000]: Train loss: 1.2811, Valid loss: 1.2610\n",
            "Epoch [695/30000]: Train loss: 1.2815, Valid loss: 1.2577\n",
            "Epoch [696/30000]: Train loss: 1.2794, Valid loss: 1.2644\n",
            "Epoch [697/30000]: Train loss: 1.2844, Valid loss: 1.2644\n",
            "Epoch [698/30000]: Train loss: 1.2805, Valid loss: 1.2571\n",
            "Epoch [699/30000]: Train loss: 1.2831, Valid loss: 1.2729\n",
            "Epoch [700/30000]: Train loss: 1.2879, Valid loss: 1.2626\n",
            "Epoch [701/30000]: Train loss: 1.2839, Valid loss: 1.2679\n",
            "Epoch [702/30000]: Train loss: 1.2820, Valid loss: 1.2653\n",
            "Epoch [703/30000]: Train loss: 1.2843, Valid loss: 1.2627\n",
            "Epoch [704/30000]: Train loss: 1.2845, Valid loss: 1.2427\n",
            "Epoch [705/30000]: Train loss: 1.2877, Valid loss: 1.2653\n",
            "Epoch [706/30000]: Train loss: 1.2852, Valid loss: 1.2591\n",
            "Epoch [707/30000]: Train loss: 1.2801, Valid loss: 1.2615\n",
            "Epoch [708/30000]: Train loss: 1.2816, Valid loss: 1.2506\n",
            "Epoch [709/30000]: Train loss: 1.2843, Valid loss: 1.2775\n",
            "Epoch [710/30000]: Train loss: 1.2845, Valid loss: 1.2658\n",
            "Epoch [711/30000]: Train loss: 1.2828, Valid loss: 1.2545\n",
            "Epoch [712/30000]: Train loss: 1.2772, Valid loss: 1.2494\n",
            "Epoch [713/30000]: Train loss: 1.2868, Valid loss: 1.2556\n",
            "Epoch [714/30000]: Train loss: 1.2820, Valid loss: 1.2609\n",
            "Epoch [715/30000]: Train loss: 1.2836, Valid loss: 1.2521\n",
            "Epoch [716/30000]: Train loss: 1.2831, Valid loss: 1.2706\n",
            "Epoch [717/30000]: Train loss: 1.2826, Valid loss: 1.2841\n",
            "Epoch [718/30000]: Train loss: 1.2817, Valid loss: 1.2459\n",
            "Epoch [719/30000]: Train loss: 1.2842, Valid loss: 1.2658\n",
            "Epoch [720/30000]: Train loss: 1.2843, Valid loss: 1.2739\n",
            "Epoch [721/30000]: Train loss: 1.2861, Valid loss: 1.2570\n",
            "Epoch [722/30000]: Train loss: 1.2889, Valid loss: 1.2663\n",
            "Epoch [723/30000]: Train loss: 1.2835, Valid loss: 1.2641\n",
            "Epoch [724/30000]: Train loss: 1.2841, Valid loss: 1.2745\n",
            "Epoch [725/30000]: Train loss: 1.2828, Valid loss: 1.2688\n",
            "Epoch [726/30000]: Train loss: 1.2836, Valid loss: 1.2799\n",
            "Epoch [727/30000]: Train loss: 1.2868, Valid loss: 1.2488\n",
            "Epoch [728/30000]: Train loss: 1.2830, Valid loss: 1.2558\n",
            "Epoch [729/30000]: Train loss: 1.2827, Valid loss: 1.2577\n",
            "Epoch [730/30000]: Train loss: 1.2851, Valid loss: 1.2555\n",
            "Epoch [731/30000]: Train loss: 1.2837, Valid loss: 1.2702\n",
            "Epoch [732/30000]: Train loss: 1.2842, Valid loss: 1.2675\n",
            "Epoch [733/30000]: Train loss: 1.2789, Valid loss: 1.2679\n",
            "Epoch [734/30000]: Train loss: 1.2847, Valid loss: 1.2534\n",
            "Epoch [735/30000]: Train loss: 1.2807, Valid loss: 1.2544\n",
            "Epoch [736/30000]: Train loss: 1.2823, Valid loss: 1.2617\n",
            "Epoch [737/30000]: Train loss: 1.2819, Valid loss: 1.2641\n",
            "Epoch [738/30000]: Train loss: 1.2819, Valid loss: 1.2657\n",
            "Epoch [739/30000]: Train loss: 1.2825, Valid loss: 1.2628\n",
            "Epoch [740/30000]: Train loss: 1.2785, Valid loss: 1.2740\n",
            "Epoch [741/30000]: Train loss: 1.2846, Valid loss: 1.2544\n",
            "Epoch [742/30000]: Train loss: 1.2834, Valid loss: 1.2713\n",
            "Epoch [743/30000]: Train loss: 1.2797, Valid loss: 1.2601\n",
            "Epoch [744/30000]: Train loss: 1.2800, Valid loss: 1.2534\n",
            "Epoch [745/30000]: Train loss: 1.2837, Valid loss: 1.2649\n",
            "Epoch [746/30000]: Train loss: 1.2842, Valid loss: 1.2630\n",
            "Epoch [747/30000]: Train loss: 1.2821, Valid loss: 1.2566\n",
            "Epoch [748/30000]: Train loss: 1.2854, Valid loss: 1.2665\n",
            "Epoch [749/30000]: Train loss: 1.2819, Valid loss: 1.2676\n",
            "Epoch [750/30000]: Train loss: 1.2836, Valid loss: 1.2641\n",
            "Epoch [751/30000]: Train loss: 1.2851, Valid loss: 1.2632\n",
            "Epoch [752/30000]: Train loss: 1.2783, Valid loss: 1.2606\n",
            "Epoch [753/30000]: Train loss: 1.2846, Valid loss: 1.2768\n",
            "Epoch [754/30000]: Train loss: 1.2831, Valid loss: 1.2717\n",
            "Epoch [755/30000]: Train loss: 1.2816, Valid loss: 1.2517\n",
            "Epoch [756/30000]: Train loss: 1.2861, Valid loss: 1.2619\n",
            "Epoch [757/30000]: Train loss: 1.2820, Valid loss: 1.2559\n",
            "Epoch [758/30000]: Train loss: 1.2841, Valid loss: 1.2530\n",
            "Epoch [759/30000]: Train loss: 1.2809, Valid loss: 1.2683\n",
            "Epoch [760/30000]: Train loss: 1.2872, Valid loss: 1.2647\n",
            "Epoch [761/30000]: Train loss: 1.2814, Valid loss: 1.2615\n",
            "Epoch [762/30000]: Train loss: 1.2881, Valid loss: 1.2606\n",
            "Epoch [763/30000]: Train loss: 1.2856, Valid loss: 1.2575\n",
            "Epoch [764/30000]: Train loss: 1.2855, Valid loss: 1.2572\n",
            "Epoch [765/30000]: Train loss: 1.2849, Valid loss: 1.2611\n",
            "Epoch [766/30000]: Train loss: 1.2836, Valid loss: 1.2631\n",
            "Epoch [767/30000]: Train loss: 1.2821, Valid loss: 1.2562\n",
            "Epoch [768/30000]: Train loss: 1.2835, Valid loss: 1.2822\n",
            "Epoch [769/30000]: Train loss: 1.2810, Valid loss: 1.2517\n",
            "Epoch [770/30000]: Train loss: 1.2876, Valid loss: 1.2678\n",
            "Epoch [771/30000]: Train loss: 1.2832, Valid loss: 1.2738\n",
            "Epoch [772/30000]: Train loss: 1.2868, Valid loss: 1.2636\n",
            "Epoch [773/30000]: Train loss: 1.2823, Valid loss: 1.2500\n",
            "Epoch [774/30000]: Train loss: 1.2822, Valid loss: 1.2599\n",
            "Epoch [775/30000]: Train loss: 1.2832, Valid loss: 1.2556\n",
            "Epoch [776/30000]: Train loss: 1.2858, Valid loss: 1.2457\n",
            "Epoch [777/30000]: Train loss: 1.2833, Valid loss: 1.2735\n",
            "Epoch [778/30000]: Train loss: 1.2815, Valid loss: 1.2667\n",
            "Epoch [779/30000]: Train loss: 1.2806, Valid loss: 1.2529\n",
            "Epoch [780/30000]: Train loss: 1.2876, Valid loss: 1.2658\n",
            "Epoch [781/30000]: Train loss: 1.2833, Valid loss: 1.2606\n",
            "Epoch [782/30000]: Train loss: 1.2858, Valid loss: 1.2767\n",
            "Epoch [783/30000]: Train loss: 1.2839, Valid loss: 1.2679\n",
            "Epoch [784/30000]: Train loss: 1.2853, Valid loss: 1.2607\n",
            "Epoch [785/30000]: Train loss: 1.2837, Valid loss: 1.2645\n",
            "Epoch [786/30000]: Train loss: 1.2853, Valid loss: 1.2654\n",
            "Epoch [787/30000]: Train loss: 1.2867, Valid loss: 1.2418\n",
            "Epoch [788/30000]: Train loss: 1.2821, Valid loss: 1.2667\n",
            "Epoch [789/30000]: Train loss: 1.2796, Valid loss: 1.2672\n",
            "Epoch [790/30000]: Train loss: 1.2811, Valid loss: 1.2704\n",
            "Epoch [791/30000]: Train loss: 1.2843, Valid loss: 1.2799\n",
            "Epoch [792/30000]: Train loss: 1.2847, Valid loss: 1.2728\n",
            "Epoch [793/30000]: Train loss: 1.2846, Valid loss: 1.2556\n",
            "Epoch [794/30000]: Train loss: 1.2833, Valid loss: 1.2484\n",
            "Epoch [795/30000]: Train loss: 1.2804, Valid loss: 1.2615\n",
            "Epoch [796/30000]: Train loss: 1.2804, Valid loss: 1.2707\n",
            "Epoch [797/30000]: Train loss: 1.2846, Valid loss: 1.2693\n",
            "Epoch [798/30000]: Train loss: 1.2827, Valid loss: 1.2612\n",
            "Epoch [799/30000]: Train loss: 1.2820, Valid loss: 1.2539\n",
            "Epoch [800/30000]: Train loss: 1.2802, Valid loss: 1.2526\n",
            "Epoch [801/30000]: Train loss: 1.2797, Valid loss: 1.2568\n",
            "Epoch [802/30000]: Train loss: 1.2843, Valid loss: 1.2663\n",
            "Epoch [803/30000]: Train loss: 1.2827, Valid loss: 1.2634\n",
            "Epoch [804/30000]: Train loss: 1.2822, Valid loss: 1.2562\n",
            "Epoch [805/30000]: Train loss: 1.2829, Valid loss: 1.2608\n",
            "Epoch [806/30000]: Train loss: 1.2839, Valid loss: 1.2737\n",
            "Epoch [807/30000]: Train loss: 1.2878, Valid loss: 1.2499\n",
            "Epoch [808/30000]: Train loss: 1.2837, Valid loss: 1.2522\n",
            "Epoch [809/30000]: Train loss: 1.2874, Valid loss: 1.2585\n",
            "Epoch [810/30000]: Train loss: 1.2838, Valid loss: 1.2852\n",
            "Epoch [811/30000]: Train loss: 1.2821, Valid loss: 1.2600\n",
            "Epoch [812/30000]: Train loss: 1.2804, Valid loss: 1.2493\n",
            "Epoch [813/30000]: Train loss: 1.2845, Valid loss: 1.2618\n",
            "Epoch [814/30000]: Train loss: 1.2865, Valid loss: 1.2778\n",
            "Epoch [815/30000]: Train loss: 1.2853, Valid loss: 1.2576\n",
            "Epoch [816/30000]: Train loss: 1.2827, Valid loss: 1.2691\n",
            "Epoch [817/30000]: Train loss: 1.2814, Valid loss: 1.2627\n",
            "Epoch [818/30000]: Train loss: 1.2797, Valid loss: 1.2592\n",
            "Epoch [819/30000]: Train loss: 1.2826, Valid loss: 1.2708\n",
            "Epoch [820/30000]: Train loss: 1.2857, Valid loss: 1.2641\n",
            "Epoch [821/30000]: Train loss: 1.2801, Valid loss: 1.2448\n",
            "Epoch [822/30000]: Train loss: 1.2843, Valid loss: 1.2704\n",
            "Epoch [823/30000]: Train loss: 1.2822, Valid loss: 1.2715\n",
            "Epoch [824/30000]: Train loss: 1.2848, Valid loss: 1.2433\n",
            "Epoch [825/30000]: Train loss: 1.2834, Valid loss: 1.2603\n",
            "Epoch [826/30000]: Train loss: 1.2867, Valid loss: 1.2602\n",
            "Epoch [827/30000]: Train loss: 1.2861, Valid loss: 1.2747\n",
            "Epoch [828/30000]: Train loss: 1.2829, Valid loss: 1.2827\n",
            "Epoch [829/30000]: Train loss: 1.2810, Valid loss: 1.2492\n",
            "Epoch [830/30000]: Train loss: 1.2820, Valid loss: 1.2724\n",
            "Epoch [831/30000]: Train loss: 1.2831, Valid loss: 1.2603\n",
            "Epoch [832/30000]: Train loss: 1.2841, Valid loss: 1.2742\n",
            "Epoch [833/30000]: Train loss: 1.2877, Valid loss: 1.2467\n",
            "Epoch [834/30000]: Train loss: 1.2843, Valid loss: 1.2575\n",
            "Epoch [835/30000]: Train loss: 1.2854, Valid loss: 1.2587\n",
            "Epoch [836/30000]: Train loss: 1.2880, Valid loss: 1.2777\n",
            "Epoch [837/30000]: Train loss: 1.2838, Valid loss: 1.2559\n",
            "Epoch [838/30000]: Train loss: 1.2819, Valid loss: 1.2592\n",
            "Epoch [839/30000]: Train loss: 1.2839, Valid loss: 1.2546\n",
            "Epoch [840/30000]: Train loss: 1.2847, Valid loss: 1.2738\n",
            "Epoch [841/30000]: Train loss: 1.2850, Valid loss: 1.2540\n",
            "Epoch [842/30000]: Train loss: 1.2815, Valid loss: 1.2652\n",
            "Epoch [843/30000]: Train loss: 1.2841, Valid loss: 1.2460\n",
            "Epoch [844/30000]: Train loss: 1.2848, Valid loss: 1.2480\n",
            "Epoch [845/30000]: Train loss: 1.2829, Valid loss: 1.2823\n",
            "Epoch [846/30000]: Train loss: 1.2878, Valid loss: 1.2527\n",
            "Epoch [847/30000]: Train loss: 1.2816, Valid loss: 1.2524\n",
            "Epoch [848/30000]: Train loss: 1.2894, Valid loss: 1.2666\n",
            "Epoch [849/30000]: Train loss: 1.2821, Valid loss: 1.2650\n",
            "Epoch [850/30000]: Train loss: 1.2799, Valid loss: 1.2620\n",
            "Epoch [851/30000]: Train loss: 1.2844, Valid loss: 1.2427\n",
            "Epoch [852/30000]: Train loss: 1.2777, Valid loss: 1.2574\n",
            "Epoch [853/30000]: Train loss: 1.2791, Valid loss: 1.2667\n",
            "Epoch [854/30000]: Train loss: 1.2857, Valid loss: 1.2600\n",
            "Epoch [855/30000]: Train loss: 1.2893, Valid loss: 1.2582\n",
            "Epoch [856/30000]: Train loss: 1.2834, Valid loss: 1.2541\n",
            "Epoch [857/30000]: Train loss: 1.2829, Valid loss: 1.2530\n",
            "Epoch [858/30000]: Train loss: 1.2793, Valid loss: 1.2595\n",
            "Epoch [859/30000]: Train loss: 1.2876, Valid loss: 1.2875\n",
            "Epoch [860/30000]: Train loss: 1.2832, Valid loss: 1.2714\n",
            "Epoch [861/30000]: Train loss: 1.2829, Valid loss: 1.2502\n",
            "Epoch [862/30000]: Train loss: 1.2831, Valid loss: 1.2715\n",
            "Epoch [863/30000]: Train loss: 1.2820, Valid loss: 1.2692\n",
            "Epoch [864/30000]: Train loss: 1.2823, Valid loss: 1.2680\n",
            "Epoch [865/30000]: Train loss: 1.2773, Valid loss: 1.2885\n",
            "Epoch [866/30000]: Train loss: 1.2839, Valid loss: 1.2676\n",
            "Epoch [867/30000]: Train loss: 1.2865, Valid loss: 1.2676\n",
            "Epoch [868/30000]: Train loss: 1.2848, Valid loss: 1.2650\n",
            "Epoch [869/30000]: Train loss: 1.2878, Valid loss: 1.2546\n",
            "Epoch [870/30000]: Train loss: 1.2792, Valid loss: 1.2515\n",
            "Epoch [871/30000]: Train loss: 1.2851, Valid loss: 1.2595\n",
            "Epoch [872/30000]: Train loss: 1.2815, Valid loss: 1.2727\n",
            "Epoch [873/30000]: Train loss: 1.2805, Valid loss: 1.2668\n",
            "Epoch [874/30000]: Train loss: 1.2849, Valid loss: 1.2571\n",
            "Epoch [875/30000]: Train loss: 1.2851, Valid loss: 1.2728\n",
            "Epoch [876/30000]: Train loss: 1.2837, Valid loss: 1.2612\n",
            "Epoch [877/30000]: Train loss: 1.2793, Valid loss: 1.2592\n",
            "Epoch [878/30000]: Train loss: 1.2862, Valid loss: 1.2703\n",
            "Epoch [879/30000]: Train loss: 1.2856, Valid loss: 1.2578\n",
            "Epoch [880/30000]: Train loss: 1.2823, Valid loss: 1.2613\n",
            "Epoch [881/30000]: Train loss: 1.2859, Valid loss: 1.2741\n",
            "Epoch [882/30000]: Train loss: 1.2853, Valid loss: 1.2725\n",
            "Epoch [883/30000]: Train loss: 1.2813, Valid loss: 1.2598\n",
            "Epoch [884/30000]: Train loss: 1.2822, Valid loss: 1.2617\n",
            "Epoch [885/30000]: Train loss: 1.2832, Valid loss: 1.2727\n",
            "Epoch [886/30000]: Train loss: 1.2873, Valid loss: 1.2759\n",
            "Epoch [887/30000]: Train loss: 1.2832, Valid loss: 1.2498\n",
            "Epoch [888/30000]: Train loss: 1.2809, Valid loss: 1.2596\n",
            "Epoch [889/30000]: Train loss: 1.2881, Valid loss: 1.2715\n",
            "Epoch [890/30000]: Train loss: 1.2780, Valid loss: 1.2665\n",
            "Epoch [891/30000]: Train loss: 1.2804, Valid loss: 1.2537\n",
            "Epoch [892/30000]: Train loss: 1.2832, Valid loss: 1.2636\n",
            "Epoch [893/30000]: Train loss: 1.2864, Valid loss: 1.2468\n",
            "Epoch [894/30000]: Train loss: 1.2823, Valid loss: 1.2597\n",
            "Epoch [895/30000]: Train loss: 1.2816, Valid loss: 1.2574\n",
            "Epoch [896/30000]: Train loss: 1.2833, Valid loss: 1.2585\n",
            "Epoch [897/30000]: Train loss: 1.2843, Valid loss: 1.2561\n",
            "Epoch [898/30000]: Train loss: 1.2824, Valid loss: 1.2564\n",
            "Epoch [899/30000]: Train loss: 1.2812, Valid loss: 1.2595\n",
            "Epoch [900/30000]: Train loss: 1.2842, Valid loss: 1.2565\n",
            "Epoch [901/30000]: Train loss: 1.2826, Valid loss: 1.2479\n",
            "Epoch [902/30000]: Train loss: 1.2813, Valid loss: 1.2702\n",
            "Epoch [903/30000]: Train loss: 1.2869, Valid loss: 1.2671\n",
            "Epoch [904/30000]: Train loss: 1.2833, Valid loss: 1.2652\n",
            "Epoch [905/30000]: Train loss: 1.2826, Valid loss: 1.2842\n",
            "Epoch [906/30000]: Train loss: 1.2868, Valid loss: 1.2641\n",
            "Epoch [907/30000]: Train loss: 1.2862, Valid loss: 1.2640\n",
            "Epoch [908/30000]: Train loss: 1.2816, Valid loss: 1.2456\n",
            "Epoch [909/30000]: Train loss: 1.2770, Valid loss: 1.2619\n",
            "Epoch [910/30000]: Train loss: 1.2803, Valid loss: 1.2769\n",
            "Epoch [911/30000]: Train loss: 1.2814, Valid loss: 1.2480\n",
            "Epoch [912/30000]: Train loss: 1.2843, Valid loss: 1.2659\n",
            "Epoch [913/30000]: Train loss: 1.2859, Valid loss: 1.2534\n",
            "Epoch [914/30000]: Train loss: 1.2846, Valid loss: 1.2572\n",
            "Epoch [915/30000]: Train loss: 1.2840, Valid loss: 1.2583\n",
            "Epoch [916/30000]: Train loss: 1.2834, Valid loss: 1.2385\n",
            "Saving model with loss 1.239...\n",
            "Epoch [917/30000]: Train loss: 1.2841, Valid loss: 1.2674\n",
            "Epoch [918/30000]: Train loss: 1.2821, Valid loss: 1.2557\n",
            "Epoch [919/30000]: Train loss: 1.2826, Valid loss: 1.2617\n",
            "Epoch [920/30000]: Train loss: 1.2837, Valid loss: 1.2584\n",
            "Epoch [921/30000]: Train loss: 1.2818, Valid loss: 1.2673\n",
            "Epoch [922/30000]: Train loss: 1.2848, Valid loss: 1.2656\n",
            "Epoch [923/30000]: Train loss: 1.2783, Valid loss: 1.2600\n",
            "Epoch [924/30000]: Train loss: 1.2863, Valid loss: 1.2745\n",
            "Epoch [925/30000]: Train loss: 1.2847, Valid loss: 1.2842\n",
            "Epoch [926/30000]: Train loss: 1.2839, Valid loss: 1.2635\n",
            "Epoch [927/30000]: Train loss: 1.2809, Valid loss: 1.2502\n",
            "Epoch [928/30000]: Train loss: 1.2827, Valid loss: 1.2709\n",
            "Epoch [929/30000]: Train loss: 1.2842, Valid loss: 1.2718\n",
            "Epoch [930/30000]: Train loss: 1.2775, Valid loss: 1.2655\n",
            "Epoch [931/30000]: Train loss: 1.2838, Valid loss: 1.2581\n",
            "Epoch [932/30000]: Train loss: 1.2784, Valid loss: 1.2493\n",
            "Epoch [933/30000]: Train loss: 1.2830, Valid loss: 1.2670\n",
            "Epoch [934/30000]: Train loss: 1.2809, Valid loss: 1.2670\n",
            "Epoch [935/30000]: Train loss: 1.2834, Valid loss: 1.2825\n",
            "Epoch [936/30000]: Train loss: 1.2860, Valid loss: 1.2650\n",
            "Epoch [937/30000]: Train loss: 1.2806, Valid loss: 1.2548\n",
            "Epoch [938/30000]: Train loss: 1.2838, Valid loss: 1.2635\n",
            "Epoch [939/30000]: Train loss: 1.2840, Valid loss: 1.2766\n",
            "Epoch [940/30000]: Train loss: 1.2852, Valid loss: 1.2529\n",
            "Epoch [941/30000]: Train loss: 1.2821, Valid loss: 1.2711\n",
            "Epoch [942/30000]: Train loss: 1.2835, Valid loss: 1.2629\n",
            "Epoch [943/30000]: Train loss: 1.2845, Valid loss: 1.2768\n",
            "Epoch [944/30000]: Train loss: 1.2864, Valid loss: 1.2572\n",
            "Epoch [945/30000]: Train loss: 1.2813, Valid loss: 1.2605\n",
            "Epoch [946/30000]: Train loss: 1.2843, Valid loss: 1.2601\n",
            "Epoch [947/30000]: Train loss: 1.2876, Valid loss: 1.2582\n",
            "Epoch [948/30000]: Train loss: 1.2878, Valid loss: 1.2697\n",
            "Epoch [949/30000]: Train loss: 1.2859, Valid loss: 1.2637\n",
            "Epoch [950/30000]: Train loss: 1.2853, Valid loss: 1.2779\n",
            "Epoch [951/30000]: Train loss: 1.2812, Valid loss: 1.2701\n",
            "Epoch [952/30000]: Train loss: 1.2843, Valid loss: 1.2788\n",
            "Epoch [953/30000]: Train loss: 1.2822, Valid loss: 1.2685\n",
            "Epoch [954/30000]: Train loss: 1.2860, Valid loss: 1.2825\n",
            "Epoch [955/30000]: Train loss: 1.2834, Valid loss: 1.2674\n",
            "Epoch [956/30000]: Train loss: 1.2816, Valid loss: 1.2543\n",
            "Epoch [957/30000]: Train loss: 1.2904, Valid loss: 1.2807\n",
            "Epoch [958/30000]: Train loss: 1.2845, Valid loss: 1.2520\n",
            "Epoch [959/30000]: Train loss: 1.2854, Valid loss: 1.2677\n",
            "Epoch [960/30000]: Train loss: 1.2836, Valid loss: 1.2647\n",
            "Epoch [961/30000]: Train loss: 1.2823, Valid loss: 1.2582\n",
            "Epoch [962/30000]: Train loss: 1.2838, Valid loss: 1.2654\n",
            "Epoch [963/30000]: Train loss: 1.2820, Valid loss: 1.2599\n",
            "Epoch [964/30000]: Train loss: 1.2796, Valid loss: 1.2573\n",
            "Epoch [965/30000]: Train loss: 1.2849, Valid loss: 1.2619\n",
            "Epoch [966/30000]: Train loss: 1.2846, Valid loss: 1.2548\n",
            "Epoch [967/30000]: Train loss: 1.2806, Valid loss: 1.2602\n",
            "Epoch [968/30000]: Train loss: 1.2831, Valid loss: 1.2695\n",
            "Epoch [969/30000]: Train loss: 1.2857, Valid loss: 1.2578\n",
            "Epoch [970/30000]: Train loss: 1.2851, Valid loss: 1.2515\n",
            "Epoch [971/30000]: Train loss: 1.2846, Valid loss: 1.2674\n",
            "Epoch [972/30000]: Train loss: 1.2806, Valid loss: 1.2659\n",
            "Epoch [973/30000]: Train loss: 1.2839, Valid loss: 1.2727\n",
            "Epoch [974/30000]: Train loss: 1.2815, Valid loss: 1.2639\n",
            "Epoch [975/30000]: Train loss: 1.2815, Valid loss: 1.2451\n",
            "Epoch [976/30000]: Train loss: 1.2869, Valid loss: 1.2609\n",
            "Epoch [977/30000]: Train loss: 1.2819, Valid loss: 1.2736\n",
            "Epoch [978/30000]: Train loss: 1.2883, Valid loss: 1.2548\n",
            "Epoch [979/30000]: Train loss: 1.2868, Valid loss: 1.2539\n",
            "Epoch [980/30000]: Train loss: 1.2808, Valid loss: 1.2558\n",
            "Epoch [981/30000]: Train loss: 1.2795, Valid loss: 1.2599\n",
            "Epoch [982/30000]: Train loss: 1.2788, Valid loss: 1.2742\n",
            "Epoch [983/30000]: Train loss: 1.2817, Valid loss: 1.2725\n",
            "Epoch [984/30000]: Train loss: 1.2849, Valid loss: 1.2879\n",
            "Epoch [985/30000]: Train loss: 1.2803, Valid loss: 1.2505\n",
            "Epoch [986/30000]: Train loss: 1.2803, Valid loss: 1.2443\n",
            "Epoch [987/30000]: Train loss: 1.2842, Valid loss: 1.2567\n",
            "Epoch [988/30000]: Train loss: 1.2824, Valid loss: 1.2528\n",
            "Epoch [989/30000]: Train loss: 1.2838, Valid loss: 1.2482\n",
            "Epoch [990/30000]: Train loss: 1.2856, Valid loss: 1.2607\n",
            "Epoch [991/30000]: Train loss: 1.2824, Valid loss: 1.2567\n",
            "Epoch [992/30000]: Train loss: 1.2796, Valid loss: 1.2474\n",
            "Epoch [993/30000]: Train loss: 1.2796, Valid loss: 1.2578\n",
            "Epoch [994/30000]: Train loss: 1.2849, Valid loss: 1.2718\n",
            "Epoch [995/30000]: Train loss: 1.2805, Valid loss: 1.2649\n",
            "Epoch [996/30000]: Train loss: 1.2763, Valid loss: 1.2631\n",
            "Epoch [997/30000]: Train loss: 1.2852, Valid loss: 1.2628\n",
            "Epoch [998/30000]: Train loss: 1.2841, Valid loss: 1.2590\n",
            "Epoch [999/30000]: Train loss: 1.2815, Valid loss: 1.2619\n",
            "Epoch [1000/30000]: Train loss: 1.2844, Valid loss: 1.2559\n",
            "Epoch [1001/30000]: Train loss: 1.2855, Valid loss: 1.2495\n",
            "Epoch [1002/30000]: Train loss: 1.2869, Valid loss: 1.2647\n",
            "Epoch [1003/30000]: Train loss: 1.2847, Valid loss: 1.2749\n",
            "Epoch [1004/30000]: Train loss: 1.2841, Valid loss: 1.2623\n",
            "Epoch [1005/30000]: Train loss: 1.2870, Valid loss: 1.2633\n",
            "Epoch [1006/30000]: Train loss: 1.2830, Valid loss: 1.2675\n",
            "Epoch [1007/30000]: Train loss: 1.2824, Valid loss: 1.2621\n",
            "Epoch [1008/30000]: Train loss: 1.2859, Valid loss: 1.2653\n",
            "Epoch [1009/30000]: Train loss: 1.2844, Valid loss: 1.2643\n",
            "Epoch [1010/30000]: Train loss: 1.2850, Valid loss: 1.2600\n",
            "Epoch [1011/30000]: Train loss: 1.2827, Valid loss: 1.2763\n",
            "Epoch [1012/30000]: Train loss: 1.2874, Valid loss: 1.2619\n",
            "Epoch [1013/30000]: Train loss: 1.2840, Valid loss: 1.2758\n",
            "Epoch [1014/30000]: Train loss: 1.2891, Valid loss: 1.2697\n",
            "Epoch [1015/30000]: Train loss: 1.2770, Valid loss: 1.2586\n",
            "Epoch [1016/30000]: Train loss: 1.2867, Valid loss: 1.2801\n",
            "Epoch [1017/30000]: Train loss: 1.2862, Valid loss: 1.2684\n",
            "Epoch [1018/30000]: Train loss: 1.2857, Valid loss: 1.2562\n",
            "Epoch [1019/30000]: Train loss: 1.2822, Valid loss: 1.2730\n",
            "Epoch [1020/30000]: Train loss: 1.2789, Valid loss: 1.2580\n",
            "Epoch [1021/30000]: Train loss: 1.2822, Valid loss: 1.2637\n",
            "Epoch [1022/30000]: Train loss: 1.2832, Valid loss: 1.2524\n",
            "Epoch [1023/30000]: Train loss: 1.2837, Valid loss: 1.2671\n",
            "Epoch [1024/30000]: Train loss: 1.2858, Valid loss: 1.2719\n",
            "Epoch [1025/30000]: Train loss: 1.2798, Valid loss: 1.2596\n",
            "Epoch [1026/30000]: Train loss: 1.2851, Valid loss: 1.2565\n",
            "Epoch [1027/30000]: Train loss: 1.2818, Valid loss: 1.2629\n",
            "Epoch [1028/30000]: Train loss: 1.2840, Valid loss: 1.2498\n",
            "Epoch [1029/30000]: Train loss: 1.2790, Valid loss: 1.2693\n",
            "Epoch [1030/30000]: Train loss: 1.2842, Valid loss: 1.2556\n",
            "Epoch [1031/30000]: Train loss: 1.2825, Valid loss: 1.2626\n",
            "Epoch [1032/30000]: Train loss: 1.2847, Valid loss: 1.2518\n",
            "Epoch [1033/30000]: Train loss: 1.2855, Valid loss: 1.2535\n",
            "Epoch [1034/30000]: Train loss: 1.2818, Valid loss: 1.2619\n",
            "Epoch [1035/30000]: Train loss: 1.2812, Valid loss: 1.2621\n",
            "Epoch [1036/30000]: Train loss: 1.2834, Valid loss: 1.2567\n",
            "Epoch [1037/30000]: Train loss: 1.2834, Valid loss: 1.2645\n",
            "Epoch [1038/30000]: Train loss: 1.2827, Valid loss: 1.2745\n",
            "Epoch [1039/30000]: Train loss: 1.2822, Valid loss: 1.2544\n",
            "Epoch [1040/30000]: Train loss: 1.2721, Valid loss: 1.2624\n",
            "Epoch [1041/30000]: Train loss: 1.2843, Valid loss: 1.2536\n",
            "Epoch [1042/30000]: Train loss: 1.2843, Valid loss: 1.2649\n",
            "Epoch [1043/30000]: Train loss: 1.2865, Valid loss: 1.2692\n",
            "Epoch [1044/30000]: Train loss: 1.2819, Valid loss: 1.2640\n",
            "Epoch [1045/30000]: Train loss: 1.2848, Valid loss: 1.2767\n",
            "Epoch [1046/30000]: Train loss: 1.2834, Valid loss: 1.2695\n",
            "Epoch [1047/30000]: Train loss: 1.2813, Valid loss: 1.2618\n",
            "Epoch [1048/30000]: Train loss: 1.2830, Valid loss: 1.2616\n",
            "Epoch [1049/30000]: Train loss: 1.2852, Valid loss: 1.2619\n",
            "Epoch [1050/30000]: Train loss: 1.2873, Valid loss: 1.2574\n",
            "Epoch [1051/30000]: Train loss: 1.2870, Valid loss: 1.2747\n",
            "Epoch [1052/30000]: Train loss: 1.2807, Valid loss: 1.2620\n",
            "Epoch [1053/30000]: Train loss: 1.2885, Valid loss: 1.2660\n",
            "Epoch [1054/30000]: Train loss: 1.2868, Valid loss: 1.2551\n",
            "Epoch [1055/30000]: Train loss: 1.2850, Valid loss: 1.2595\n",
            "Epoch [1056/30000]: Train loss: 1.2818, Valid loss: 1.2528\n",
            "Epoch [1057/30000]: Train loss: 1.2878, Valid loss: 1.2621\n",
            "Epoch [1058/30000]: Train loss: 1.2831, Valid loss: 1.2618\n",
            "Epoch [1059/30000]: Train loss: 1.2842, Valid loss: 1.2514\n",
            "Epoch [1060/30000]: Train loss: 1.2842, Valid loss: 1.2693\n",
            "Epoch [1061/30000]: Train loss: 1.2832, Valid loss: 1.2750\n",
            "Epoch [1062/30000]: Train loss: 1.2806, Valid loss: 1.2491\n",
            "Epoch [1063/30000]: Train loss: 1.2853, Valid loss: 1.2544\n",
            "Epoch [1064/30000]: Train loss: 1.2808, Valid loss: 1.2498\n",
            "Epoch [1065/30000]: Train loss: 1.2880, Valid loss: 1.2510\n",
            "Epoch [1066/30000]: Train loss: 1.2794, Valid loss: 1.2705\n",
            "Epoch [1067/30000]: Train loss: 1.2859, Valid loss: 1.2741\n",
            "Epoch [1068/30000]: Train loss: 1.2851, Valid loss: 1.2680\n",
            "Epoch [1069/30000]: Train loss: 1.2839, Valid loss: 1.2622\n",
            "Epoch [1070/30000]: Train loss: 1.2814, Valid loss: 1.2676\n",
            "Epoch [1071/30000]: Train loss: 1.2814, Valid loss: 1.2674\n",
            "Epoch [1072/30000]: Train loss: 1.2812, Valid loss: 1.2621\n",
            "Epoch [1073/30000]: Train loss: 1.2827, Valid loss: 1.2704\n",
            "Epoch [1074/30000]: Train loss: 1.2802, Valid loss: 1.2578\n",
            "Epoch [1075/30000]: Train loss: 1.2810, Valid loss: 1.2569\n",
            "Epoch [1076/30000]: Train loss: 1.2827, Valid loss: 1.2583\n",
            "Epoch [1077/30000]: Train loss: 1.2830, Valid loss: 1.2580\n",
            "Epoch [1078/30000]: Train loss: 1.2815, Valid loss: 1.2531\n",
            "Epoch [1079/30000]: Train loss: 1.2837, Valid loss: 1.2570\n",
            "Epoch [1080/30000]: Train loss: 1.2846, Valid loss: 1.2656\n",
            "Epoch [1081/30000]: Train loss: 1.2777, Valid loss: 1.2640\n",
            "Epoch [1082/30000]: Train loss: 1.2838, Valid loss: 1.2512\n",
            "Epoch [1083/30000]: Train loss: 1.2795, Valid loss: 1.2577\n",
            "Epoch [1084/30000]: Train loss: 1.2825, Valid loss: 1.2753\n",
            "Epoch [1085/30000]: Train loss: 1.2831, Valid loss: 1.2642\n",
            "Epoch [1086/30000]: Train loss: 1.2789, Valid loss: 1.2628\n",
            "Epoch [1087/30000]: Train loss: 1.2837, Valid loss: 1.2792\n",
            "Epoch [1088/30000]: Train loss: 1.2824, Valid loss: 1.2522\n",
            "Epoch [1089/30000]: Train loss: 1.2783, Valid loss: 1.2499\n",
            "Epoch [1090/30000]: Train loss: 1.2810, Valid loss: 1.2562\n",
            "Epoch [1091/30000]: Train loss: 1.2837, Valid loss: 1.2621\n",
            "Epoch [1092/30000]: Train loss: 1.2837, Valid loss: 1.2573\n",
            "Epoch [1093/30000]: Train loss: 1.2822, Valid loss: 1.2432\n",
            "Epoch [1094/30000]: Train loss: 1.2828, Valid loss: 1.2637\n",
            "Epoch [1095/30000]: Train loss: 1.2808, Valid loss: 1.2554\n",
            "Epoch [1096/30000]: Train loss: 1.2787, Valid loss: 1.2672\n",
            "Epoch [1097/30000]: Train loss: 1.2848, Valid loss: 1.2635\n",
            "Epoch [1098/30000]: Train loss: 1.2854, Valid loss: 1.2673\n",
            "Epoch [1099/30000]: Train loss: 1.2842, Valid loss: 1.2616\n",
            "Epoch [1100/30000]: Train loss: 1.2788, Valid loss: 1.2640\n",
            "Epoch [1101/30000]: Train loss: 1.2839, Valid loss: 1.2622\n",
            "Epoch [1102/30000]: Train loss: 1.2829, Valid loss: 1.2671\n",
            "Epoch [1103/30000]: Train loss: 1.2835, Valid loss: 1.2597\n",
            "Epoch [1104/30000]: Train loss: 1.2845, Valid loss: 1.2595\n",
            "Epoch [1105/30000]: Train loss: 1.2846, Valid loss: 1.2668\n",
            "Epoch [1106/30000]: Train loss: 1.2804, Valid loss: 1.2695\n",
            "Epoch [1107/30000]: Train loss: 1.2821, Valid loss: 1.2619\n",
            "Epoch [1108/30000]: Train loss: 1.2831, Valid loss: 1.2643\n",
            "Epoch [1109/30000]: Train loss: 1.2845, Valid loss: 1.2658\n",
            "Epoch [1110/30000]: Train loss: 1.2842, Valid loss: 1.2617\n",
            "Epoch [1111/30000]: Train loss: 1.2801, Valid loss: 1.2638\n",
            "Epoch [1112/30000]: Train loss: 1.2842, Valid loss: 1.2677\n",
            "Epoch [1113/30000]: Train loss: 1.2824, Valid loss: 1.2557\n",
            "Epoch [1114/30000]: Train loss: 1.2794, Valid loss: 1.2459\n",
            "Epoch [1115/30000]: Train loss: 1.2814, Valid loss: 1.2596\n",
            "Epoch [1116/30000]: Train loss: 1.2811, Valid loss: 1.2517\n",
            "Epoch [1117/30000]: Train loss: 1.2855, Valid loss: 1.2639\n",
            "Epoch [1118/30000]: Train loss: 1.2823, Valid loss: 1.2584\n",
            "Epoch [1119/30000]: Train loss: 1.2824, Valid loss: 1.2519\n",
            "Epoch [1120/30000]: Train loss: 1.2824, Valid loss: 1.2567\n",
            "Epoch [1121/30000]: Train loss: 1.2867, Valid loss: 1.2447\n",
            "Epoch [1122/30000]: Train loss: 1.2780, Valid loss: 1.2551\n",
            "Epoch [1123/30000]: Train loss: 1.2803, Valid loss: 1.2559\n",
            "Epoch [1124/30000]: Train loss: 1.2810, Valid loss: 1.2502\n",
            "Epoch [1125/30000]: Train loss: 1.2802, Valid loss: 1.2747\n",
            "Epoch [1126/30000]: Train loss: 1.2812, Valid loss: 1.2477\n",
            "Epoch [1127/30000]: Train loss: 1.2815, Valid loss: 1.2719\n",
            "Epoch [1128/30000]: Train loss: 1.2817, Valid loss: 1.2536\n",
            "Epoch [1129/30000]: Train loss: 1.2795, Valid loss: 1.2517\n",
            "Epoch [1130/30000]: Train loss: 1.2806, Valid loss: 1.2597\n",
            "Epoch [1131/30000]: Train loss: 1.2839, Valid loss: 1.2565\n",
            "Epoch [1132/30000]: Train loss: 1.2831, Valid loss: 1.2660\n",
            "Epoch [1133/30000]: Train loss: 1.2820, Valid loss: 1.2589\n",
            "Epoch [1134/30000]: Train loss: 1.2809, Valid loss: 1.2537\n",
            "Epoch [1135/30000]: Train loss: 1.2777, Valid loss: 1.2333\n",
            "Saving model with loss 1.233...\n",
            "Epoch [1136/30000]: Train loss: 1.2823, Valid loss: 1.2612\n",
            "Epoch [1137/30000]: Train loss: 1.2810, Valid loss: 1.2574\n",
            "Epoch [1138/30000]: Train loss: 1.2835, Valid loss: 1.2627\n",
            "Epoch [1139/30000]: Train loss: 1.2804, Valid loss: 1.2568\n",
            "Epoch [1140/30000]: Train loss: 1.2843, Valid loss: 1.2585\n",
            "Epoch [1141/30000]: Train loss: 1.2840, Valid loss: 1.2635\n",
            "Epoch [1142/30000]: Train loss: 1.2823, Valid loss: 1.2591\n",
            "Epoch [1143/30000]: Train loss: 1.2804, Valid loss: 1.2550\n",
            "Epoch [1144/30000]: Train loss: 1.2851, Valid loss: 1.2621\n",
            "Epoch [1145/30000]: Train loss: 1.2846, Valid loss: 1.2699\n",
            "Epoch [1146/30000]: Train loss: 1.2830, Valid loss: 1.2480\n",
            "Epoch [1147/30000]: Train loss: 1.2858, Valid loss: 1.2774\n",
            "Epoch [1148/30000]: Train loss: 1.2859, Valid loss: 1.2876\n",
            "Epoch [1149/30000]: Train loss: 1.2845, Valid loss: 1.2546\n",
            "Epoch [1150/30000]: Train loss: 1.2845, Valid loss: 1.2577\n",
            "Epoch [1151/30000]: Train loss: 1.2817, Valid loss: 1.2746\n",
            "Epoch [1152/30000]: Train loss: 1.2833, Valid loss: 1.2486\n",
            "Epoch [1153/30000]: Train loss: 1.2851, Valid loss: 1.2835\n",
            "Epoch [1154/30000]: Train loss: 1.2851, Valid loss: 1.2745\n",
            "Epoch [1155/30000]: Train loss: 1.2817, Valid loss: 1.2574\n",
            "Epoch [1156/30000]: Train loss: 1.2828, Valid loss: 1.2701\n",
            "Epoch [1157/30000]: Train loss: 1.2819, Valid loss: 1.2503\n",
            "Epoch [1158/30000]: Train loss: 1.2778, Valid loss: 1.2626\n",
            "Epoch [1159/30000]: Train loss: 1.2868, Valid loss: 1.2632\n",
            "Epoch [1160/30000]: Train loss: 1.2807, Valid loss: 1.2690\n",
            "Epoch [1161/30000]: Train loss: 1.2779, Valid loss: 1.2520\n",
            "Epoch [1162/30000]: Train loss: 1.2847, Valid loss: 1.2626\n",
            "Epoch [1163/30000]: Train loss: 1.2774, Valid loss: 1.2651\n",
            "Epoch [1164/30000]: Train loss: 1.2804, Valid loss: 1.2689\n",
            "Epoch [1165/30000]: Train loss: 1.2822, Valid loss: 1.2633\n",
            "Epoch [1166/30000]: Train loss: 1.2785, Valid loss: 1.2638\n",
            "Epoch [1167/30000]: Train loss: 1.2866, Valid loss: 1.2591\n",
            "Epoch [1168/30000]: Train loss: 1.2802, Valid loss: 1.2529\n",
            "Epoch [1169/30000]: Train loss: 1.2813, Valid loss: 1.2525\n",
            "Epoch [1170/30000]: Train loss: 1.2787, Valid loss: 1.2489\n",
            "Epoch [1171/30000]: Train loss: 1.2793, Valid loss: 1.2544\n",
            "Epoch [1172/30000]: Train loss: 1.2810, Valid loss: 1.2731\n",
            "Epoch [1173/30000]: Train loss: 1.2849, Valid loss: 1.2604\n",
            "Epoch [1174/30000]: Train loss: 1.2873, Valid loss: 1.2786\n",
            "Epoch [1175/30000]: Train loss: 1.2829, Valid loss: 1.2599\n",
            "Epoch [1176/30000]: Train loss: 1.2812, Valid loss: 1.2602\n",
            "Epoch [1177/30000]: Train loss: 1.2836, Valid loss: 1.2631\n",
            "Epoch [1178/30000]: Train loss: 1.2801, Valid loss: 1.2613\n",
            "Epoch [1179/30000]: Train loss: 1.2867, Valid loss: 1.2709\n",
            "Epoch [1180/30000]: Train loss: 1.2874, Valid loss: 1.2610\n",
            "Epoch [1181/30000]: Train loss: 1.2797, Valid loss: 1.2734\n",
            "Epoch [1182/30000]: Train loss: 1.2855, Valid loss: 1.2506\n",
            "Epoch [1183/30000]: Train loss: 1.2828, Valid loss: 1.2676\n",
            "Epoch [1184/30000]: Train loss: 1.2807, Valid loss: 1.2543\n",
            "Epoch [1185/30000]: Train loss: 1.2818, Valid loss: 1.2458\n",
            "Epoch [1186/30000]: Train loss: 1.2832, Valid loss: 1.2594\n",
            "Epoch [1187/30000]: Train loss: 1.2824, Valid loss: 1.2602\n",
            "Epoch [1188/30000]: Train loss: 1.2806, Valid loss: 1.2620\n",
            "Epoch [1189/30000]: Train loss: 1.2835, Valid loss: 1.2635\n",
            "Epoch [1190/30000]: Train loss: 1.2773, Valid loss: 1.2537\n",
            "Epoch [1191/30000]: Train loss: 1.2827, Valid loss: 1.2691\n",
            "Epoch [1192/30000]: Train loss: 1.2803, Valid loss: 1.2715\n",
            "Epoch [1193/30000]: Train loss: 1.2833, Valid loss: 1.2628\n",
            "Epoch [1194/30000]: Train loss: 1.2838, Valid loss: 1.2526\n",
            "Epoch [1195/30000]: Train loss: 1.2861, Valid loss: 1.2559\n",
            "Epoch [1196/30000]: Train loss: 1.2807, Valid loss: 1.2649\n",
            "Epoch [1197/30000]: Train loss: 1.2857, Valid loss: 1.2523\n",
            "Epoch [1198/30000]: Train loss: 1.2828, Valid loss: 1.2466\n",
            "Epoch [1199/30000]: Train loss: 1.2844, Valid loss: 1.2467\n",
            "Epoch [1200/30000]: Train loss: 1.2865, Valid loss: 1.2696\n",
            "Epoch [1201/30000]: Train loss: 1.2854, Valid loss: 1.2757\n",
            "Epoch [1202/30000]: Train loss: 1.2798, Valid loss: 1.2564\n",
            "Epoch [1203/30000]: Train loss: 1.2795, Valid loss: 1.2579\n",
            "Epoch [1204/30000]: Train loss: 1.2787, Valid loss: 1.2683\n",
            "Epoch [1205/30000]: Train loss: 1.2812, Valid loss: 1.2896\n",
            "Epoch [1206/30000]: Train loss: 1.2837, Valid loss: 1.2926\n",
            "Epoch [1207/30000]: Train loss: 1.2835, Valid loss: 1.2617\n",
            "Epoch [1208/30000]: Train loss: 1.2827, Valid loss: 1.2624\n",
            "Epoch [1209/30000]: Train loss: 1.2833, Valid loss: 1.2586\n",
            "Epoch [1210/30000]: Train loss: 1.2792, Valid loss: 1.2627\n",
            "Epoch [1211/30000]: Train loss: 1.2839, Valid loss: 1.2564\n",
            "Epoch [1212/30000]: Train loss: 1.2821, Valid loss: 1.2679\n",
            "Epoch [1213/30000]: Train loss: 1.2832, Valid loss: 1.2611\n",
            "Epoch [1214/30000]: Train loss: 1.2792, Valid loss: 1.2679\n",
            "Epoch [1215/30000]: Train loss: 1.2829, Valid loss: 1.2565\n",
            "Epoch [1216/30000]: Train loss: 1.2812, Valid loss: 1.2748\n",
            "Epoch [1217/30000]: Train loss: 1.2818, Valid loss: 1.2580\n",
            "Epoch [1218/30000]: Train loss: 1.2802, Valid loss: 1.2606\n",
            "Epoch [1219/30000]: Train loss: 1.2825, Valid loss: 1.2554\n",
            "Epoch [1220/30000]: Train loss: 1.2823, Valid loss: 1.2505\n",
            "Epoch [1221/30000]: Train loss: 1.2820, Valid loss: 1.2672\n",
            "Epoch [1222/30000]: Train loss: 1.2820, Valid loss: 1.2637\n",
            "Epoch [1223/30000]: Train loss: 1.2810, Valid loss: 1.2510\n",
            "Epoch [1224/30000]: Train loss: 1.2843, Valid loss: 1.2492\n",
            "Epoch [1225/30000]: Train loss: 1.2847, Valid loss: 1.2527\n",
            "Epoch [1226/30000]: Train loss: 1.2827, Valid loss: 1.2718\n",
            "Epoch [1227/30000]: Train loss: 1.2873, Valid loss: 1.2483\n",
            "Epoch [1228/30000]: Train loss: 1.2824, Valid loss: 1.2504\n",
            "Epoch [1229/30000]: Train loss: 1.2861, Valid loss: 1.2662\n",
            "Epoch [1230/30000]: Train loss: 1.2781, Valid loss: 1.2550\n",
            "Epoch [1231/30000]: Train loss: 1.2849, Valid loss: 1.2473\n",
            "Epoch [1232/30000]: Train loss: 1.2831, Valid loss: 1.2507\n",
            "Epoch [1233/30000]: Train loss: 1.2865, Valid loss: 1.2697\n",
            "Epoch [1234/30000]: Train loss: 1.2841, Valid loss: 1.2641\n",
            "Epoch [1235/30000]: Train loss: 1.2789, Valid loss: 1.2699\n",
            "Epoch [1236/30000]: Train loss: 1.2825, Valid loss: 1.2640\n",
            "Epoch [1237/30000]: Train loss: 1.2782, Valid loss: 1.2688\n",
            "Epoch [1238/30000]: Train loss: 1.2811, Valid loss: 1.2649\n",
            "Epoch [1239/30000]: Train loss: 1.2837, Valid loss: 1.2540\n",
            "Epoch [1240/30000]: Train loss: 1.2824, Valid loss: 1.2563\n",
            "Epoch [1241/30000]: Train loss: 1.2823, Valid loss: 1.2652\n",
            "Epoch [1242/30000]: Train loss: 1.2864, Valid loss: 1.2493\n",
            "Epoch [1243/30000]: Train loss: 1.2848, Valid loss: 1.2761\n",
            "Epoch [1244/30000]: Train loss: 1.2853, Valid loss: 1.2536\n",
            "Epoch [1245/30000]: Train loss: 1.2851, Valid loss: 1.2623\n",
            "Epoch [1246/30000]: Train loss: 1.2828, Valid loss: 1.2743\n",
            "Epoch [1247/30000]: Train loss: 1.2840, Valid loss: 1.2713\n",
            "Epoch [1248/30000]: Train loss: 1.2852, Valid loss: 1.2579\n",
            "Epoch [1249/30000]: Train loss: 1.2811, Valid loss: 1.2808\n",
            "Epoch [1250/30000]: Train loss: 1.2828, Valid loss: 1.2604\n",
            "Epoch [1251/30000]: Train loss: 1.2830, Valid loss: 1.2542\n",
            "Epoch [1252/30000]: Train loss: 1.2818, Valid loss: 1.2551\n",
            "Epoch [1253/30000]: Train loss: 1.2808, Valid loss: 1.2801\n",
            "Epoch [1254/30000]: Train loss: 1.2833, Valid loss: 1.2676\n",
            "Epoch [1255/30000]: Train loss: 1.2824, Valid loss: 1.2681\n",
            "Epoch [1256/30000]: Train loss: 1.2857, Valid loss: 1.2773\n",
            "Epoch [1257/30000]: Train loss: 1.2851, Valid loss: 1.2474\n",
            "Epoch [1258/30000]: Train loss: 1.2826, Valid loss: 1.2525\n",
            "Epoch [1259/30000]: Train loss: 1.2841, Valid loss: 1.2588\n",
            "Epoch [1260/30000]: Train loss: 1.2793, Valid loss: 1.2758\n",
            "Epoch [1261/30000]: Train loss: 1.2828, Valid loss: 1.2725\n",
            "Epoch [1262/30000]: Train loss: 1.2862, Valid loss: 1.2432\n",
            "Epoch [1263/30000]: Train loss: 1.2783, Valid loss: 1.2612\n",
            "Epoch [1264/30000]: Train loss: 1.2816, Valid loss: 1.2554\n",
            "Epoch [1265/30000]: Train loss: 1.2766, Valid loss: 1.2484\n",
            "Epoch [1266/30000]: Train loss: 1.2833, Valid loss: 1.2613\n",
            "Epoch [1267/30000]: Train loss: 1.2813, Valid loss: 1.2624\n",
            "Epoch [1268/30000]: Train loss: 1.2808, Valid loss: 1.2532\n",
            "Epoch [1269/30000]: Train loss: 1.2809, Valid loss: 1.2667\n",
            "Epoch [1270/30000]: Train loss: 1.2806, Valid loss: 1.2524\n",
            "Epoch [1271/30000]: Train loss: 1.2820, Valid loss: 1.2650\n",
            "Epoch [1272/30000]: Train loss: 1.2786, Valid loss: 1.2442\n",
            "Epoch [1273/30000]: Train loss: 1.2781, Valid loss: 1.2703\n",
            "Epoch [1274/30000]: Train loss: 1.2823, Valid loss: 1.2666\n",
            "Epoch [1275/30000]: Train loss: 1.2865, Valid loss: 1.2528\n",
            "Epoch [1276/30000]: Train loss: 1.2805, Valid loss: 1.2504\n",
            "Epoch [1277/30000]: Train loss: 1.2827, Valid loss: 1.2714\n",
            "Epoch [1278/30000]: Train loss: 1.2888, Valid loss: 1.2675\n",
            "Epoch [1279/30000]: Train loss: 1.2824, Valid loss: 1.2486\n",
            "Epoch [1280/30000]: Train loss: 1.2817, Valid loss: 1.2598\n",
            "Epoch [1281/30000]: Train loss: 1.2845, Valid loss: 1.2605\n",
            "Epoch [1282/30000]: Train loss: 1.2827, Valid loss: 1.2483\n",
            "Epoch [1283/30000]: Train loss: 1.2828, Valid loss: 1.2600\n",
            "Epoch [1284/30000]: Train loss: 1.2781, Valid loss: 1.2729\n",
            "Epoch [1285/30000]: Train loss: 1.2854, Valid loss: 1.2496\n",
            "Epoch [1286/30000]: Train loss: 1.2821, Valid loss: 1.2649\n",
            "Epoch [1287/30000]: Train loss: 1.2777, Valid loss: 1.2573\n",
            "Epoch [1288/30000]: Train loss: 1.2847, Valid loss: 1.2633\n",
            "Epoch [1289/30000]: Train loss: 1.2853, Valid loss: 1.2779\n",
            "Epoch [1290/30000]: Train loss: 1.2853, Valid loss: 1.2641\n",
            "Epoch [1291/30000]: Train loss: 1.2795, Valid loss: 1.2548\n",
            "Epoch [1292/30000]: Train loss: 1.2825, Valid loss: 1.2592\n",
            "Epoch [1293/30000]: Train loss: 1.2815, Valid loss: 1.2634\n",
            "Epoch [1294/30000]: Train loss: 1.2845, Valid loss: 1.2580\n",
            "Epoch [1295/30000]: Train loss: 1.2815, Valid loss: 1.2598\n",
            "Epoch [1296/30000]: Train loss: 1.2885, Valid loss: 1.2613\n",
            "Epoch [1297/30000]: Train loss: 1.2827, Valid loss: 1.2698\n",
            "Epoch [1298/30000]: Train loss: 1.2764, Valid loss: 1.2586\n",
            "Epoch [1299/30000]: Train loss: 1.2817, Valid loss: 1.2633\n",
            "Epoch [1300/30000]: Train loss: 1.2800, Valid loss: 1.2587\n",
            "Epoch [1301/30000]: Train loss: 1.2805, Valid loss: 1.2567\n",
            "Epoch [1302/30000]: Train loss: 1.2819, Valid loss: 1.2585\n",
            "Epoch [1303/30000]: Train loss: 1.2822, Valid loss: 1.2727\n",
            "Epoch [1304/30000]: Train loss: 1.2857, Valid loss: 1.2495\n",
            "Epoch [1305/30000]: Train loss: 1.2810, Valid loss: 1.2677\n",
            "Epoch [1306/30000]: Train loss: 1.2813, Valid loss: 1.2566\n",
            "Epoch [1307/30000]: Train loss: 1.2823, Valid loss: 1.2530\n",
            "Epoch [1308/30000]: Train loss: 1.2860, Valid loss: 1.2550\n",
            "Epoch [1309/30000]: Train loss: 1.2811, Valid loss: 1.2616\n",
            "Epoch [1310/30000]: Train loss: 1.2816, Valid loss: 1.2629\n",
            "Epoch [1311/30000]: Train loss: 1.2807, Valid loss: 1.2578\n",
            "Epoch [1312/30000]: Train loss: 1.2788, Valid loss: 1.2462\n",
            "Epoch [1313/30000]: Train loss: 1.2841, Valid loss: 1.2556\n",
            "Epoch [1314/30000]: Train loss: 1.2827, Valid loss: 1.2533\n",
            "Epoch [1315/30000]: Train loss: 1.2786, Valid loss: 1.2555\n",
            "Epoch [1316/30000]: Train loss: 1.2840, Valid loss: 1.2721\n",
            "Epoch [1317/30000]: Train loss: 1.2857, Valid loss: 1.2656\n",
            "Epoch [1318/30000]: Train loss: 1.2803, Valid loss: 1.2561\n",
            "Epoch [1319/30000]: Train loss: 1.2840, Valid loss: 1.2564\n",
            "Epoch [1320/30000]: Train loss: 1.2859, Valid loss: 1.2463\n",
            "Epoch [1321/30000]: Train loss: 1.2852, Valid loss: 1.2583\n",
            "Epoch [1322/30000]: Train loss: 1.2828, Valid loss: 1.2612\n",
            "Epoch [1323/30000]: Train loss: 1.2804, Valid loss: 1.2762\n",
            "Epoch [1324/30000]: Train loss: 1.2800, Valid loss: 1.2641\n",
            "Epoch [1325/30000]: Train loss: 1.2809, Valid loss: 1.2456\n",
            "Epoch [1326/30000]: Train loss: 1.2826, Valid loss: 1.2495\n",
            "Epoch [1327/30000]: Train loss: 1.2819, Valid loss: 1.2524\n",
            "Epoch [1328/30000]: Train loss: 1.2811, Valid loss: 1.2544\n",
            "Epoch [1329/30000]: Train loss: 1.2796, Valid loss: 1.2641\n",
            "Epoch [1330/30000]: Train loss: 1.2854, Valid loss: 1.2657\n",
            "Epoch [1331/30000]: Train loss: 1.2772, Valid loss: 1.2613\n",
            "Epoch [1332/30000]: Train loss: 1.2819, Valid loss: 1.2737\n",
            "Epoch [1333/30000]: Train loss: 1.2839, Valid loss: 1.2582\n",
            "Epoch [1334/30000]: Train loss: 1.2835, Valid loss: 1.2600\n",
            "Epoch [1335/30000]: Train loss: 1.2839, Valid loss: 1.2504\n",
            "Epoch [1336/30000]: Train loss: 1.2830, Valid loss: 1.2589\n",
            "Epoch [1337/30000]: Train loss: 1.2799, Valid loss: 1.2592\n",
            "Epoch [1338/30000]: Train loss: 1.2827, Valid loss: 1.2600\n",
            "Epoch [1339/30000]: Train loss: 1.2808, Valid loss: 1.2699\n",
            "Epoch [1340/30000]: Train loss: 1.2822, Valid loss: 1.2650\n",
            "Epoch [1341/30000]: Train loss: 1.2802, Valid loss: 1.2569\n",
            "Epoch [1342/30000]: Train loss: 1.2818, Valid loss: 1.2572\n",
            "Epoch [1343/30000]: Train loss: 1.2844, Valid loss: 1.2492\n",
            "Epoch [1344/30000]: Train loss: 1.2808, Valid loss: 1.2748\n",
            "Epoch [1345/30000]: Train loss: 1.2786, Valid loss: 1.2572\n",
            "Epoch [1346/30000]: Train loss: 1.2799, Valid loss: 1.2583\n",
            "Epoch [1347/30000]: Train loss: 1.2846, Valid loss: 1.2547\n",
            "Epoch [1348/30000]: Train loss: 1.2812, Valid loss: 1.2465\n",
            "Epoch [1349/30000]: Train loss: 1.2818, Valid loss: 1.2573\n",
            "Epoch [1350/30000]: Train loss: 1.2792, Valid loss: 1.2572\n",
            "Epoch [1351/30000]: Train loss: 1.2809, Valid loss: 1.2691\n",
            "Epoch [1352/30000]: Train loss: 1.2807, Valid loss: 1.2622\n",
            "Epoch [1353/30000]: Train loss: 1.2792, Valid loss: 1.2397\n",
            "Epoch [1354/30000]: Train loss: 1.2845, Valid loss: 1.2552\n",
            "Epoch [1355/30000]: Train loss: 1.2836, Valid loss: 1.2397\n",
            "Epoch [1356/30000]: Train loss: 1.2809, Valid loss: 1.2599\n",
            "Epoch [1357/30000]: Train loss: 1.2848, Valid loss: 1.2756\n",
            "Epoch [1358/30000]: Train loss: 1.2835, Valid loss: 1.2590\n",
            "Epoch [1359/30000]: Train loss: 1.2822, Valid loss: 1.2712\n",
            "Epoch [1360/30000]: Train loss: 1.2828, Valid loss: 1.2549\n",
            "Epoch [1361/30000]: Train loss: 1.2893, Valid loss: 1.2636\n",
            "Epoch [1362/30000]: Train loss: 1.2833, Valid loss: 1.2752\n",
            "Epoch [1363/30000]: Train loss: 1.2833, Valid loss: 1.2697\n",
            "Epoch [1364/30000]: Train loss: 1.2859, Valid loss: 1.2554\n",
            "Epoch [1365/30000]: Train loss: 1.2847, Valid loss: 1.2660\n",
            "Epoch [1366/30000]: Train loss: 1.2857, Valid loss: 1.2547\n",
            "Epoch [1367/30000]: Train loss: 1.2804, Valid loss: 1.2578\n",
            "Epoch [1368/30000]: Train loss: 1.2840, Valid loss: 1.2601\n",
            "Epoch [1369/30000]: Train loss: 1.2811, Valid loss: 1.2564\n",
            "Epoch [1370/30000]: Train loss: 1.2859, Valid loss: 1.2576\n",
            "Epoch [1371/30000]: Train loss: 1.2792, Valid loss: 1.2565\n",
            "Epoch [1372/30000]: Train loss: 1.2803, Valid loss: 1.2686\n",
            "Epoch [1373/30000]: Train loss: 1.2818, Valid loss: 1.2579\n",
            "Epoch [1374/30000]: Train loss: 1.2808, Valid loss: 1.2758\n",
            "Epoch [1375/30000]: Train loss: 1.2792, Valid loss: 1.2777\n",
            "Epoch [1376/30000]: Train loss: 1.2820, Valid loss: 1.2484\n",
            "Epoch [1377/30000]: Train loss: 1.2837, Valid loss: 1.2637\n",
            "Epoch [1378/30000]: Train loss: 1.2841, Valid loss: 1.2741\n",
            "Epoch [1379/30000]: Train loss: 1.2833, Valid loss: 1.2443\n",
            "Epoch [1380/30000]: Train loss: 1.2816, Valid loss: 1.2770\n",
            "Epoch [1381/30000]: Train loss: 1.2816, Valid loss: 1.2480\n",
            "Epoch [1382/30000]: Train loss: 1.2815, Valid loss: 1.2539\n",
            "Epoch [1383/30000]: Train loss: 1.2838, Valid loss: 1.2575\n",
            "Epoch [1384/30000]: Train loss: 1.2801, Valid loss: 1.2549\n",
            "Epoch [1385/30000]: Train loss: 1.2807, Valid loss: 1.2712\n",
            "Epoch [1386/30000]: Train loss: 1.2853, Valid loss: 1.2573\n",
            "Epoch [1387/30000]: Train loss: 1.2782, Valid loss: 1.2494\n",
            "Epoch [1388/30000]: Train loss: 1.2829, Valid loss: 1.2731\n",
            "Epoch [1389/30000]: Train loss: 1.2844, Valid loss: 1.2638\n",
            "Epoch [1390/30000]: Train loss: 1.2816, Valid loss: 1.2556\n",
            "Epoch [1391/30000]: Train loss: 1.2848, Valid loss: 1.2567\n",
            "Epoch [1392/30000]: Train loss: 1.2831, Valid loss: 1.2521\n",
            "Epoch [1393/30000]: Train loss: 1.2794, Valid loss: 1.2567\n",
            "Epoch [1394/30000]: Train loss: 1.2784, Valid loss: 1.2600\n",
            "Epoch [1395/30000]: Train loss: 1.2837, Valid loss: 1.2485\n",
            "Epoch [1396/30000]: Train loss: 1.2773, Valid loss: 1.2546\n",
            "Epoch [1397/30000]: Train loss: 1.2856, Valid loss: 1.2728\n",
            "Epoch [1398/30000]: Train loss: 1.2769, Valid loss: 1.2598\n",
            "Epoch [1399/30000]: Train loss: 1.2847, Valid loss: 1.2735\n",
            "Epoch [1400/30000]: Train loss: 1.2815, Valid loss: 1.2610\n",
            "Epoch [1401/30000]: Train loss: 1.2804, Valid loss: 1.2609\n",
            "Epoch [1402/30000]: Train loss: 1.2788, Valid loss: 1.2694\n",
            "Epoch [1403/30000]: Train loss: 1.2756, Valid loss: 1.2600\n",
            "Epoch [1404/30000]: Train loss: 1.2832, Valid loss: 1.2724\n",
            "Epoch [1405/30000]: Train loss: 1.2839, Valid loss: 1.2583\n",
            "Epoch [1406/30000]: Train loss: 1.2788, Valid loss: 1.2614\n",
            "Epoch [1407/30000]: Train loss: 1.2820, Valid loss: 1.2470\n",
            "Epoch [1408/30000]: Train loss: 1.2790, Valid loss: 1.2614\n",
            "Epoch [1409/30000]: Train loss: 1.2817, Valid loss: 1.2632\n",
            "Epoch [1410/30000]: Train loss: 1.2825, Valid loss: 1.2655\n",
            "Epoch [1411/30000]: Train loss: 1.2792, Valid loss: 1.2622\n",
            "Epoch [1412/30000]: Train loss: 1.2831, Valid loss: 1.2591\n",
            "Epoch [1413/30000]: Train loss: 1.2847, Valid loss: 1.2738\n",
            "Epoch [1414/30000]: Train loss: 1.2844, Valid loss: 1.2560\n",
            "Epoch [1415/30000]: Train loss: 1.2814, Valid loss: 1.2627\n",
            "Epoch [1416/30000]: Train loss: 1.2794, Valid loss: 1.2642\n",
            "Epoch [1417/30000]: Train loss: 1.2826, Valid loss: 1.2502\n",
            "Epoch [1418/30000]: Train loss: 1.2794, Valid loss: 1.2469\n",
            "Epoch [1419/30000]: Train loss: 1.2850, Valid loss: 1.2719\n",
            "Epoch [1420/30000]: Train loss: 1.2819, Valid loss: 1.2588\n",
            "Epoch [1421/30000]: Train loss: 1.2831, Valid loss: 1.2516\n",
            "Epoch [1422/30000]: Train loss: 1.2874, Valid loss: 1.2529\n",
            "Epoch [1423/30000]: Train loss: 1.2818, Valid loss: 1.2709\n",
            "Epoch [1424/30000]: Train loss: 1.2877, Valid loss: 1.2636\n",
            "Epoch [1425/30000]: Train loss: 1.2844, Valid loss: 1.2462\n",
            "Epoch [1426/30000]: Train loss: 1.2828, Valid loss: 1.2565\n",
            "Epoch [1427/30000]: Train loss: 1.2818, Valid loss: 1.2612\n",
            "Epoch [1428/30000]: Train loss: 1.2832, Valid loss: 1.2610\n",
            "Epoch [1429/30000]: Train loss: 1.2803, Valid loss: 1.2724\n",
            "Epoch [1430/30000]: Train loss: 1.2821, Valid loss: 1.2688\n",
            "Epoch [1431/30000]: Train loss: 1.2825, Valid loss: 1.2578\n",
            "Epoch [1432/30000]: Train loss: 1.2814, Valid loss: 1.2558\n",
            "Epoch [1433/30000]: Train loss: 1.2830, Valid loss: 1.2450\n",
            "Epoch [1434/30000]: Train loss: 1.2797, Valid loss: 1.2647\n",
            "Epoch [1435/30000]: Train loss: 1.2867, Valid loss: 1.2617\n",
            "Epoch [1436/30000]: Train loss: 1.2791, Valid loss: 1.2654\n",
            "Epoch [1437/30000]: Train loss: 1.2815, Valid loss: 1.2559\n",
            "Epoch [1438/30000]: Train loss: 1.2829, Valid loss: 1.2482\n",
            "Epoch [1439/30000]: Train loss: 1.2810, Valid loss: 1.2718\n",
            "Epoch [1440/30000]: Train loss: 1.2822, Valid loss: 1.2494\n",
            "Epoch [1441/30000]: Train loss: 1.2797, Valid loss: 1.2632\n",
            "Epoch [1442/30000]: Train loss: 1.2806, Valid loss: 1.2665\n",
            "Epoch [1443/30000]: Train loss: 1.2825, Valid loss: 1.2683\n",
            "Epoch [1444/30000]: Train loss: 1.2804, Valid loss: 1.2416\n",
            "Epoch [1445/30000]: Train loss: 1.2810, Valid loss: 1.2655\n",
            "Epoch [1446/30000]: Train loss: 1.2862, Valid loss: 1.2619\n",
            "Epoch [1447/30000]: Train loss: 1.2809, Valid loss: 1.2465\n",
            "Epoch [1448/30000]: Train loss: 1.2807, Valid loss: 1.2601\n",
            "Epoch [1449/30000]: Train loss: 1.2798, Valid loss: 1.2701\n",
            "Epoch [1450/30000]: Train loss: 1.2795, Valid loss: 1.2587\n",
            "Epoch [1451/30000]: Train loss: 1.2798, Valid loss: 1.2714\n",
            "Epoch [1452/30000]: Train loss: 1.2824, Valid loss: 1.2700\n",
            "Epoch [1453/30000]: Train loss: 1.2807, Valid loss: 1.2578\n",
            "Epoch [1454/30000]: Train loss: 1.2788, Valid loss: 1.2525\n",
            "Epoch [1455/30000]: Train loss: 1.2863, Valid loss: 1.2698\n",
            "Epoch [1456/30000]: Train loss: 1.2833, Valid loss: 1.2595\n",
            "Epoch [1457/30000]: Train loss: 1.2849, Valid loss: 1.2751\n",
            "Epoch [1458/30000]: Train loss: 1.2808, Valid loss: 1.2636\n",
            "Epoch [1459/30000]: Train loss: 1.2819, Valid loss: 1.2569\n",
            "Epoch [1460/30000]: Train loss: 1.2783, Valid loss: 1.2498\n",
            "Epoch [1461/30000]: Train loss: 1.2792, Valid loss: 1.2572\n",
            "Epoch [1462/30000]: Train loss: 1.2834, Valid loss: 1.2585\n",
            "Epoch [1463/30000]: Train loss: 1.2791, Valid loss: 1.2611\n",
            "Epoch [1464/30000]: Train loss: 1.2777, Valid loss: 1.2542\n",
            "Epoch [1465/30000]: Train loss: 1.2896, Valid loss: 1.2970\n",
            "Epoch [1466/30000]: Train loss: 1.2812, Valid loss: 1.2559\n",
            "Epoch [1467/30000]: Train loss: 1.2811, Valid loss: 1.2714\n",
            "Epoch [1468/30000]: Train loss: 1.2823, Valid loss: 1.2672\n",
            "Epoch [1469/30000]: Train loss: 1.2856, Valid loss: 1.2608\n",
            "Epoch [1470/30000]: Train loss: 1.2785, Valid loss: 1.2550\n",
            "Epoch [1471/30000]: Train loss: 1.2845, Valid loss: 1.2639\n",
            "Epoch [1472/30000]: Train loss: 1.2805, Valid loss: 1.2542\n",
            "Epoch [1473/30000]: Train loss: 1.2852, Valid loss: 1.2710\n",
            "Epoch [1474/30000]: Train loss: 1.2844, Valid loss: 1.2579\n",
            "Epoch [1475/30000]: Train loss: 1.2809, Valid loss: 1.2819\n",
            "Epoch [1476/30000]: Train loss: 1.2868, Valid loss: 1.2530\n",
            "Epoch [1477/30000]: Train loss: 1.2856, Valid loss: 1.2677\n",
            "Epoch [1478/30000]: Train loss: 1.2831, Valid loss: 1.2611\n",
            "Epoch [1479/30000]: Train loss: 1.2793, Valid loss: 1.2659\n",
            "Epoch [1480/30000]: Train loss: 1.2856, Valid loss: 1.2587\n",
            "Epoch [1481/30000]: Train loss: 1.2877, Valid loss: 1.2596\n",
            "Epoch [1482/30000]: Train loss: 1.2812, Valid loss: 1.2670\n",
            "Epoch [1483/30000]: Train loss: 1.2810, Valid loss: 1.2516\n",
            "Epoch [1484/30000]: Train loss: 1.2829, Valid loss: 1.2562\n",
            "Epoch [1485/30000]: Train loss: 1.2827, Valid loss: 1.2780\n",
            "Epoch [1486/30000]: Train loss: 1.2825, Valid loss: 1.2460\n",
            "Epoch [1487/30000]: Train loss: 1.2807, Valid loss: 1.2385\n",
            "Epoch [1488/30000]: Train loss: 1.2886, Valid loss: 1.2662\n",
            "Epoch [1489/30000]: Train loss: 1.2864, Valid loss: 1.2707\n",
            "Epoch [1490/30000]: Train loss: 1.2814, Valid loss: 1.2572\n",
            "Epoch [1491/30000]: Train loss: 1.2785, Valid loss: 1.2512\n",
            "Epoch [1492/30000]: Train loss: 1.2806, Valid loss: 1.2653\n",
            "Epoch [1493/30000]: Train loss: 1.2814, Valid loss: 1.2718\n",
            "Epoch [1494/30000]: Train loss: 1.2798, Valid loss: 1.2486\n",
            "Epoch [1495/30000]: Train loss: 1.2802, Valid loss: 1.2583\n",
            "Epoch [1496/30000]: Train loss: 1.2794, Valid loss: 1.2660\n",
            "Epoch [1497/30000]: Train loss: 1.2766, Valid loss: 1.2615\n",
            "Epoch [1498/30000]: Train loss: 1.2827, Valid loss: 1.2747\n",
            "Epoch [1499/30000]: Train loss: 1.2826, Valid loss: 1.2545\n",
            "Epoch [1500/30000]: Train loss: 1.2833, Valid loss: 1.2526\n",
            "Epoch [1501/30000]: Train loss: 1.2836, Valid loss: 1.2603\n",
            "Epoch [1502/30000]: Train loss: 1.2816, Valid loss: 1.2429\n",
            "Epoch [1503/30000]: Train loss: 1.2817, Valid loss: 1.2611\n",
            "Epoch [1504/30000]: Train loss: 1.2834, Valid loss: 1.2786\n",
            "Epoch [1505/30000]: Train loss: 1.2840, Valid loss: 1.2470\n",
            "Epoch [1506/30000]: Train loss: 1.2771, Valid loss: 1.2518\n",
            "Epoch [1507/30000]: Train loss: 1.2784, Valid loss: 1.2363\n",
            "Epoch [1508/30000]: Train loss: 1.2834, Valid loss: 1.2658\n",
            "Epoch [1509/30000]: Train loss: 1.2793, Valid loss: 1.2595\n",
            "Epoch [1510/30000]: Train loss: 1.2858, Valid loss: 1.2650\n",
            "Epoch [1511/30000]: Train loss: 1.2824, Valid loss: 1.2627\n",
            "Epoch [1512/30000]: Train loss: 1.2811, Valid loss: 1.2540\n",
            "Epoch [1513/30000]: Train loss: 1.2798, Valid loss: 1.2482\n",
            "Epoch [1514/30000]: Train loss: 1.2818, Valid loss: 1.2694\n",
            "Epoch [1515/30000]: Train loss: 1.2817, Valid loss: 1.2541\n",
            "Epoch [1516/30000]: Train loss: 1.2774, Valid loss: 1.2566\n",
            "Epoch [1517/30000]: Train loss: 1.2803, Valid loss: 1.2720\n",
            "Epoch [1518/30000]: Train loss: 1.2834, Valid loss: 1.2566\n",
            "Epoch [1519/30000]: Train loss: 1.2828, Valid loss: 1.2532\n",
            "Epoch [1520/30000]: Train loss: 1.2836, Valid loss: 1.2490\n",
            "Epoch [1521/30000]: Train loss: 1.2836, Valid loss: 1.2593\n",
            "Epoch [1522/30000]: Train loss: 1.2873, Valid loss: 1.2550\n",
            "Epoch [1523/30000]: Train loss: 1.2823, Valid loss: 1.2507\n",
            "Epoch [1524/30000]: Train loss: 1.2808, Valid loss: 1.2608\n",
            "Epoch [1525/30000]: Train loss: 1.2806, Valid loss: 1.2651\n",
            "Epoch [1526/30000]: Train loss: 1.2859, Valid loss: 1.2661\n",
            "Epoch [1527/30000]: Train loss: 1.2872, Valid loss: 1.2663\n",
            "Epoch [1528/30000]: Train loss: 1.2872, Valid loss: 1.2687\n",
            "Epoch [1529/30000]: Train loss: 1.2851, Valid loss: 1.2518\n",
            "Epoch [1530/30000]: Train loss: 1.2866, Valid loss: 1.2653\n",
            "Epoch [1531/30000]: Train loss: 1.2812, Valid loss: 1.2484\n",
            "Epoch [1532/30000]: Train loss: 1.2793, Valid loss: 1.2569\n",
            "Epoch [1533/30000]: Train loss: 1.2805, Valid loss: 1.2617\n",
            "Epoch [1534/30000]: Train loss: 1.2821, Valid loss: 1.2654\n",
            "Epoch [1535/30000]: Train loss: 1.2864, Valid loss: 1.2636\n",
            "Epoch [1536/30000]: Train loss: 1.2814, Valid loss: 1.2535\n",
            "Epoch [1537/30000]: Train loss: 1.2875, Valid loss: 1.2538\n",
            "Epoch [1538/30000]: Train loss: 1.2792, Valid loss: 1.2475\n",
            "Epoch [1539/30000]: Train loss: 1.2834, Valid loss: 1.2516\n",
            "Epoch [1540/30000]: Train loss: 1.2812, Valid loss: 1.2382\n",
            "Epoch [1541/30000]: Train loss: 1.2782, Valid loss: 1.2628\n",
            "Epoch [1542/30000]: Train loss: 1.2783, Valid loss: 1.2569\n",
            "Epoch [1543/30000]: Train loss: 1.2811, Valid loss: 1.2468\n",
            "Epoch [1544/30000]: Train loss: 1.2799, Valid loss: 1.2538\n",
            "Epoch [1545/30000]: Train loss: 1.2811, Valid loss: 1.2571\n",
            "Epoch [1546/30000]: Train loss: 1.2813, Valid loss: 1.2593\n",
            "Epoch [1547/30000]: Train loss: 1.2810, Valid loss: 1.2680\n",
            "Epoch [1548/30000]: Train loss: 1.2806, Valid loss: 1.2520\n",
            "Epoch [1549/30000]: Train loss: 1.2787, Valid loss: 1.2596\n",
            "Epoch [1550/30000]: Train loss: 1.2855, Valid loss: 1.2513\n",
            "Epoch [1551/30000]: Train loss: 1.2800, Valid loss: 1.2640\n",
            "Epoch [1552/30000]: Train loss: 1.2797, Valid loss: 1.2526\n",
            "Epoch [1553/30000]: Train loss: 1.2790, Valid loss: 1.2496\n",
            "Epoch [1554/30000]: Train loss: 1.2844, Valid loss: 1.2734\n",
            "Epoch [1555/30000]: Train loss: 1.2876, Valid loss: 1.2553\n",
            "Epoch [1556/30000]: Train loss: 1.2857, Valid loss: 1.2478\n",
            "Epoch [1557/30000]: Train loss: 1.2790, Valid loss: 1.2547\n",
            "Epoch [1558/30000]: Train loss: 1.2854, Valid loss: 1.2586\n",
            "Epoch [1559/30000]: Train loss: 1.2801, Valid loss: 1.2675\n",
            "Epoch [1560/30000]: Train loss: 1.2816, Valid loss: 1.2709\n",
            "Epoch [1561/30000]: Train loss: 1.2811, Valid loss: 1.2650\n",
            "Epoch [1562/30000]: Train loss: 1.2837, Valid loss: 1.2567\n",
            "Epoch [1563/30000]: Train loss: 1.2810, Valid loss: 1.2656\n",
            "Epoch [1564/30000]: Train loss: 1.2773, Valid loss: 1.2376\n",
            "Epoch [1565/30000]: Train loss: 1.2818, Valid loss: 1.2519\n",
            "Epoch [1566/30000]: Train loss: 1.2791, Valid loss: 1.2491\n",
            "Epoch [1567/30000]: Train loss: 1.2794, Valid loss: 1.2584\n",
            "Epoch [1568/30000]: Train loss: 1.2809, Valid loss: 1.2628\n",
            "Epoch [1569/30000]: Train loss: 1.2771, Valid loss: 1.2617\n",
            "Epoch [1570/30000]: Train loss: 1.2829, Valid loss: 1.2490\n",
            "Epoch [1571/30000]: Train loss: 1.2859, Valid loss: 1.2555\n",
            "Epoch [1572/30000]: Train loss: 1.2769, Valid loss: 1.2685\n",
            "Epoch [1573/30000]: Train loss: 1.2810, Valid loss: 1.2642\n",
            "Epoch [1574/30000]: Train loss: 1.2817, Valid loss: 1.2523\n",
            "Epoch [1575/30000]: Train loss: 1.2837, Valid loss: 1.2565\n",
            "Epoch [1576/30000]: Train loss: 1.2790, Valid loss: 1.2833\n",
            "Epoch [1577/30000]: Train loss: 1.2863, Valid loss: 1.2727\n",
            "Epoch [1578/30000]: Train loss: 1.2867, Valid loss: 1.2687\n",
            "Epoch [1579/30000]: Train loss: 1.2824, Valid loss: 1.2676\n",
            "Epoch [1580/30000]: Train loss: 1.2800, Valid loss: 1.2676\n",
            "Epoch [1581/30000]: Train loss: 1.2848, Valid loss: 1.2451\n",
            "Epoch [1582/30000]: Train loss: 1.2820, Valid loss: 1.2418\n",
            "Epoch [1583/30000]: Train loss: 1.2788, Valid loss: 1.2605\n",
            "Epoch [1584/30000]: Train loss: 1.2784, Valid loss: 1.2502\n",
            "Epoch [1585/30000]: Train loss: 1.2835, Valid loss: 1.2561\n",
            "Epoch [1586/30000]: Train loss: 1.2839, Valid loss: 1.2474\n",
            "Epoch [1587/30000]: Train loss: 1.2859, Valid loss: 1.2537\n",
            "Epoch [1588/30000]: Train loss: 1.2782, Valid loss: 1.2512\n",
            "Epoch [1589/30000]: Train loss: 1.2857, Valid loss: 1.2605\n",
            "Epoch [1590/30000]: Train loss: 1.2851, Valid loss: 1.2510\n",
            "Epoch [1591/30000]: Train loss: 1.2860, Valid loss: 1.2504\n",
            "Epoch [1592/30000]: Train loss: 1.2842, Valid loss: 1.2673\n",
            "Epoch [1593/30000]: Train loss: 1.2797, Valid loss: 1.2731\n",
            "Epoch [1594/30000]: Train loss: 1.2860, Valid loss: 1.2665\n",
            "Epoch [1595/30000]: Train loss: 1.2838, Valid loss: 1.2399\n",
            "Epoch [1596/30000]: Train loss: 1.2822, Valid loss: 1.2740\n",
            "Epoch [1597/30000]: Train loss: 1.2836, Valid loss: 1.2586\n",
            "Epoch [1598/30000]: Train loss: 1.2808, Valid loss: 1.2722\n",
            "Epoch [1599/30000]: Train loss: 1.2828, Valid loss: 1.2626\n",
            "Epoch [1600/30000]: Train loss: 1.2802, Valid loss: 1.2437\n",
            "Epoch [1601/30000]: Train loss: 1.2853, Valid loss: 1.2581\n",
            "Epoch [1602/30000]: Train loss: 1.2806, Valid loss: 1.2594\n",
            "Epoch [1603/30000]: Train loss: 1.2825, Valid loss: 1.2441\n",
            "Epoch [1604/30000]: Train loss: 1.2792, Valid loss: 1.2579\n",
            "Epoch [1605/30000]: Train loss: 1.2831, Valid loss: 1.2571\n",
            "Epoch [1606/30000]: Train loss: 1.2819, Valid loss: 1.2604\n",
            "Epoch [1607/30000]: Train loss: 1.2796, Valid loss: 1.2646\n",
            "Epoch [1608/30000]: Train loss: 1.2790, Valid loss: 1.2534\n",
            "Epoch [1609/30000]: Train loss: 1.2831, Valid loss: 1.2567\n",
            "Epoch [1610/30000]: Train loss: 1.2801, Valid loss: 1.2538\n",
            "Epoch [1611/30000]: Train loss: 1.2809, Valid loss: 1.2553\n",
            "Epoch [1612/30000]: Train loss: 1.2836, Valid loss: 1.2568\n",
            "Epoch [1613/30000]: Train loss: 1.2785, Valid loss: 1.2570\n",
            "Epoch [1614/30000]: Train loss: 1.2820, Valid loss: 1.2533\n",
            "Epoch [1615/30000]: Train loss: 1.2803, Valid loss: 1.2615\n",
            "Epoch [1616/30000]: Train loss: 1.2764, Valid loss: 1.2612\n",
            "Epoch [1617/30000]: Train loss: 1.2832, Valid loss: 1.2655\n",
            "Epoch [1618/30000]: Train loss: 1.2812, Valid loss: 1.2661\n",
            "Epoch [1619/30000]: Train loss: 1.2826, Valid loss: 1.2732\n",
            "Epoch [1620/30000]: Train loss: 1.2818, Valid loss: 1.2564\n",
            "Epoch [1621/30000]: Train loss: 1.2822, Valid loss: 1.2602\n",
            "Epoch [1622/30000]: Train loss: 1.2825, Valid loss: 1.2596\n",
            "Epoch [1623/30000]: Train loss: 1.2798, Valid loss: 1.2565\n",
            "Epoch [1624/30000]: Train loss: 1.2848, Valid loss: 1.2535\n",
            "Epoch [1625/30000]: Train loss: 1.2831, Valid loss: 1.2535\n",
            "Epoch [1626/30000]: Train loss: 1.2837, Valid loss: 1.2578\n",
            "Epoch [1627/30000]: Train loss: 1.2811, Valid loss: 1.2498\n",
            "Epoch [1628/30000]: Train loss: 1.2785, Valid loss: 1.2627\n",
            "Epoch [1629/30000]: Train loss: 1.2783, Valid loss: 1.2606\n",
            "Epoch [1630/30000]: Train loss: 1.2796, Valid loss: 1.2529\n",
            "Epoch [1631/30000]: Train loss: 1.2813, Valid loss: 1.2550\n",
            "Epoch [1632/30000]: Train loss: 1.2805, Valid loss: 1.2689\n",
            "Epoch [1633/30000]: Train loss: 1.2836, Valid loss: 1.2464\n",
            "Epoch [1634/30000]: Train loss: 1.2816, Valid loss: 1.2749\n",
            "Epoch [1635/30000]: Train loss: 1.2814, Valid loss: 1.2598\n",
            "Epoch [1636/30000]: Train loss: 1.2821, Valid loss: 1.2619\n",
            "Epoch [1637/30000]: Train loss: 1.2791, Valid loss: 1.2500\n",
            "Epoch [1638/30000]: Train loss: 1.2876, Valid loss: 1.2782\n",
            "Epoch [1639/30000]: Train loss: 1.2829, Valid loss: 1.2575\n",
            "Epoch [1640/30000]: Train loss: 1.2794, Valid loss: 1.2667\n",
            "Epoch [1641/30000]: Train loss: 1.2858, Valid loss: 1.2493\n",
            "Epoch [1642/30000]: Train loss: 1.2821, Valid loss: 1.2440\n",
            "Epoch [1643/30000]: Train loss: 1.2808, Valid loss: 1.2831\n",
            "Epoch [1644/30000]: Train loss: 1.2788, Valid loss: 1.2385\n",
            "Epoch [1645/30000]: Train loss: 1.2804, Valid loss: 1.2476\n",
            "Epoch [1646/30000]: Train loss: 1.2814, Valid loss: 1.2542\n",
            "Epoch [1647/30000]: Train loss: 1.2792, Valid loss: 1.2436\n",
            "Epoch [1648/30000]: Train loss: 1.2813, Valid loss: 1.2598\n",
            "Epoch [1649/30000]: Train loss: 1.2770, Valid loss: 1.2558\n",
            "Epoch [1650/30000]: Train loss: 1.2851, Valid loss: 1.2652\n",
            "Epoch [1651/30000]: Train loss: 1.2842, Valid loss: 1.2442\n",
            "Epoch [1652/30000]: Train loss: 1.2792, Valid loss: 1.2558\n",
            "Epoch [1653/30000]: Train loss: 1.2788, Valid loss: 1.2597\n",
            "Epoch [1654/30000]: Train loss: 1.2842, Valid loss: 1.2498\n",
            "Epoch [1655/30000]: Train loss: 1.2810, Valid loss: 1.2530\n",
            "Epoch [1656/30000]: Train loss: 1.2832, Valid loss: 1.2594\n",
            "Epoch [1657/30000]: Train loss: 1.2843, Valid loss: 1.2678\n",
            "Epoch [1658/30000]: Train loss: 1.2773, Valid loss: 1.2643\n",
            "Epoch [1659/30000]: Train loss: 1.2816, Valid loss: 1.2631\n",
            "Epoch [1660/30000]: Train loss: 1.2823, Valid loss: 1.2454\n",
            "Epoch [1661/30000]: Train loss: 1.2831, Valid loss: 1.2703\n",
            "Epoch [1662/30000]: Train loss: 1.2843, Valid loss: 1.2665\n",
            "Epoch [1663/30000]: Train loss: 1.2835, Valid loss: 1.2551\n",
            "Epoch [1664/30000]: Train loss: 1.2824, Valid loss: 1.2718\n",
            "Epoch [1665/30000]: Train loss: 1.2776, Valid loss: 1.2567\n",
            "Epoch [1666/30000]: Train loss: 1.2787, Valid loss: 1.2492\n",
            "Epoch [1667/30000]: Train loss: 1.2810, Valid loss: 1.2696\n",
            "Epoch [1668/30000]: Train loss: 1.2829, Valid loss: 1.2633\n",
            "Epoch [1669/30000]: Train loss: 1.2815, Valid loss: 1.2619\n",
            "Epoch [1670/30000]: Train loss: 1.2802, Valid loss: 1.2475\n",
            "Epoch [1671/30000]: Train loss: 1.2829, Valid loss: 1.2656\n",
            "Epoch [1672/30000]: Train loss: 1.2781, Valid loss: 1.2565\n",
            "Epoch [1673/30000]: Train loss: 1.2818, Valid loss: 1.2523\n",
            "Epoch [1674/30000]: Train loss: 1.2798, Valid loss: 1.2528\n",
            "Epoch [1675/30000]: Train loss: 1.2802, Valid loss: 1.2627\n",
            "Epoch [1676/30000]: Train loss: 1.2747, Valid loss: 1.2616\n",
            "Epoch [1677/30000]: Train loss: 1.2839, Valid loss: 1.2620\n",
            "Epoch [1678/30000]: Train loss: 1.2804, Valid loss: 1.2522\n",
            "Epoch [1679/30000]: Train loss: 1.2792, Valid loss: 1.2582\n",
            "Epoch [1680/30000]: Train loss: 1.2808, Valid loss: 1.2677\n",
            "Epoch [1681/30000]: Train loss: 1.2816, Valid loss: 1.2653\n",
            "Epoch [1682/30000]: Train loss: 1.2787, Valid loss: 1.2649\n",
            "Epoch [1683/30000]: Train loss: 1.2803, Valid loss: 1.2554\n",
            "Epoch [1684/30000]: Train loss: 1.2788, Valid loss: 1.2491\n",
            "Epoch [1685/30000]: Train loss: 1.2803, Valid loss: 1.2615\n",
            "Epoch [1686/30000]: Train loss: 1.2817, Valid loss: 1.2436\n",
            "Epoch [1687/30000]: Train loss: 1.2824, Valid loss: 1.2543\n",
            "Epoch [1688/30000]: Train loss: 1.2833, Valid loss: 1.2558\n",
            "Epoch [1689/30000]: Train loss: 1.2825, Valid loss: 1.2599\n",
            "Epoch [1690/30000]: Train loss: 1.2792, Valid loss: 1.2643\n",
            "Epoch [1691/30000]: Train loss: 1.2806, Valid loss: 1.2571\n",
            "Epoch [1692/30000]: Train loss: 1.2798, Valid loss: 1.2758\n",
            "Epoch [1693/30000]: Train loss: 1.2827, Valid loss: 1.2614\n",
            "Epoch [1694/30000]: Train loss: 1.2762, Valid loss: 1.2514\n",
            "Epoch [1695/30000]: Train loss: 1.2815, Valid loss: 1.2616\n",
            "Epoch [1696/30000]: Train loss: 1.2802, Valid loss: 1.2622\n",
            "Epoch [1697/30000]: Train loss: 1.2779, Valid loss: 1.2548\n",
            "Epoch [1698/30000]: Train loss: 1.2798, Valid loss: 1.2570\n",
            "Epoch [1699/30000]: Train loss: 1.2795, Valid loss: 1.2504\n",
            "Epoch [1700/30000]: Train loss: 1.2829, Valid loss: 1.2574\n",
            "Epoch [1701/30000]: Train loss: 1.2797, Valid loss: 1.2510\n",
            "Epoch [1702/30000]: Train loss: 1.2800, Valid loss: 1.2687\n",
            "Epoch [1703/30000]: Train loss: 1.2792, Valid loss: 1.2552\n",
            "Epoch [1704/30000]: Train loss: 1.2818, Valid loss: 1.2587\n",
            "Epoch [1705/30000]: Train loss: 1.2822, Valid loss: 1.2650\n",
            "Epoch [1706/30000]: Train loss: 1.2847, Valid loss: 1.2633\n",
            "Epoch [1707/30000]: Train loss: 1.2807, Valid loss: 1.2560\n",
            "Epoch [1708/30000]: Train loss: 1.2786, Valid loss: 1.2459\n",
            "Epoch [1709/30000]: Train loss: 1.2840, Valid loss: 1.2512\n",
            "Epoch [1710/30000]: Train loss: 1.2799, Valid loss: 1.2662\n",
            "Epoch [1711/30000]: Train loss: 1.2826, Valid loss: 1.2436\n",
            "Epoch [1712/30000]: Train loss: 1.2793, Valid loss: 1.2473\n",
            "Epoch [1713/30000]: Train loss: 1.2825, Valid loss: 1.2430\n",
            "Epoch [1714/30000]: Train loss: 1.2839, Valid loss: 1.2890\n",
            "Epoch [1715/30000]: Train loss: 1.2761, Valid loss: 1.2574\n",
            "Epoch [1716/30000]: Train loss: 1.2804, Valid loss: 1.2467\n",
            "Epoch [1717/30000]: Train loss: 1.2819, Valid loss: 1.2640\n",
            "Epoch [1718/30000]: Train loss: 1.2831, Valid loss: 1.2611\n",
            "Epoch [1719/30000]: Train loss: 1.2817, Valid loss: 1.2676\n",
            "Epoch [1720/30000]: Train loss: 1.2851, Valid loss: 1.2461\n",
            "Epoch [1721/30000]: Train loss: 1.2827, Valid loss: 1.2698\n",
            "Epoch [1722/30000]: Train loss: 1.2812, Valid loss: 1.2560\n",
            "Epoch [1723/30000]: Train loss: 1.2829, Valid loss: 1.2572\n",
            "Epoch [1724/30000]: Train loss: 1.2800, Valid loss: 1.2505\n",
            "Epoch [1725/30000]: Train loss: 1.2813, Valid loss: 1.2659\n",
            "Epoch [1726/30000]: Train loss: 1.2814, Valid loss: 1.2476\n",
            "Epoch [1727/30000]: Train loss: 1.2858, Valid loss: 1.2627\n",
            "Epoch [1728/30000]: Train loss: 1.2793, Valid loss: 1.2536\n",
            "Epoch [1729/30000]: Train loss: 1.2825, Valid loss: 1.2505\n",
            "Epoch [1730/30000]: Train loss: 1.2794, Valid loss: 1.2516\n",
            "Epoch [1731/30000]: Train loss: 1.2817, Valid loss: 1.2596\n",
            "Epoch [1732/30000]: Train loss: 1.2795, Valid loss: 1.2515\n",
            "Epoch [1733/30000]: Train loss: 1.2800, Valid loss: 1.2439\n",
            "Epoch [1734/30000]: Train loss: 1.2796, Valid loss: 1.2724\n",
            "Epoch [1735/30000]: Train loss: 1.2747, Valid loss: 1.2612\n",
            "Epoch [1736/30000]: Train loss: 1.2757, Valid loss: 1.2627\n",
            "Epoch [1737/30000]: Train loss: 1.2857, Valid loss: 1.2524\n",
            "Epoch [1738/30000]: Train loss: 1.2825, Valid loss: 1.2425\n",
            "Epoch [1739/30000]: Train loss: 1.2837, Valid loss: 1.2576\n",
            "Epoch [1740/30000]: Train loss: 1.2815, Valid loss: 1.2603\n",
            "Epoch [1741/30000]: Train loss: 1.2800, Valid loss: 1.2545\n",
            "Epoch [1742/30000]: Train loss: 1.2785, Valid loss: 1.2499\n",
            "Epoch [1743/30000]: Train loss: 1.2774, Valid loss: 1.2547\n",
            "Epoch [1744/30000]: Train loss: 1.2845, Valid loss: 1.2637\n",
            "Epoch [1745/30000]: Train loss: 1.2859, Valid loss: 1.2545\n",
            "Epoch [1746/30000]: Train loss: 1.2828, Valid loss: 1.2672\n",
            "Epoch [1747/30000]: Train loss: 1.2848, Valid loss: 1.2504\n",
            "Epoch [1748/30000]: Train loss: 1.2836, Valid loss: 1.2586\n",
            "Epoch [1749/30000]: Train loss: 1.2793, Valid loss: 1.2824\n",
            "Epoch [1750/30000]: Train loss: 1.2818, Valid loss: 1.2651\n",
            "Epoch [1751/30000]: Train loss: 1.2787, Valid loss: 1.2660\n",
            "Epoch [1752/30000]: Train loss: 1.2814, Valid loss: 1.2657\n",
            "Epoch [1753/30000]: Train loss: 1.2855, Valid loss: 1.2436\n",
            "Epoch [1754/30000]: Train loss: 1.2857, Valid loss: 1.2619\n",
            "Epoch [1755/30000]: Train loss: 1.2808, Valid loss: 1.2600\n",
            "Epoch [1756/30000]: Train loss: 1.2785, Valid loss: 1.2629\n",
            "Epoch [1757/30000]: Train loss: 1.2834, Valid loss: 1.2699\n",
            "Epoch [1758/30000]: Train loss: 1.2802, Valid loss: 1.2481\n",
            "Epoch [1759/30000]: Train loss: 1.2834, Valid loss: 1.2612\n",
            "Epoch [1760/30000]: Train loss: 1.2803, Valid loss: 1.2708\n",
            "Epoch [1761/30000]: Train loss: 1.2818, Valid loss: 1.2530\n",
            "Epoch [1762/30000]: Train loss: 1.2807, Valid loss: 1.2511\n",
            "Epoch [1763/30000]: Train loss: 1.2805, Valid loss: 1.2614\n",
            "Epoch [1764/30000]: Train loss: 1.2812, Valid loss: 1.2602\n",
            "Epoch [1765/30000]: Train loss: 1.2822, Valid loss: 1.2575\n",
            "Epoch [1766/30000]: Train loss: 1.2766, Valid loss: 1.2618\n",
            "Epoch [1767/30000]: Train loss: 1.2792, Valid loss: 1.2613\n",
            "Epoch [1768/30000]: Train loss: 1.2824, Valid loss: 1.2500\n",
            "Epoch [1769/30000]: Train loss: 1.2822, Valid loss: 1.2600\n",
            "Epoch [1770/30000]: Train loss: 1.2810, Valid loss: 1.2490\n",
            "Epoch [1771/30000]: Train loss: 1.2806, Valid loss: 1.2547\n",
            "Epoch [1772/30000]: Train loss: 1.2855, Valid loss: 1.2647\n",
            "Epoch [1773/30000]: Train loss: 1.2830, Valid loss: 1.2609\n",
            "Epoch [1774/30000]: Train loss: 1.2825, Valid loss: 1.2723\n",
            "Epoch [1775/30000]: Train loss: 1.2797, Valid loss: 1.2514\n",
            "Epoch [1776/30000]: Train loss: 1.2803, Valid loss: 1.2600\n",
            "Epoch [1777/30000]: Train loss: 1.2792, Valid loss: 1.2720\n",
            "Epoch [1778/30000]: Train loss: 1.2833, Valid loss: 1.2607\n",
            "Epoch [1779/30000]: Train loss: 1.2818, Valid loss: 1.2574\n",
            "Epoch [1780/30000]: Train loss: 1.2843, Valid loss: 1.2627\n",
            "Epoch [1781/30000]: Train loss: 1.2769, Valid loss: 1.2637\n",
            "Epoch [1782/30000]: Train loss: 1.2868, Valid loss: 1.2668\n",
            "Epoch [1783/30000]: Train loss: 1.2807, Valid loss: 1.2438\n",
            "Epoch [1784/30000]: Train loss: 1.2814, Valid loss: 1.2611\n",
            "Epoch [1785/30000]: Train loss: 1.2795, Valid loss: 1.2472\n",
            "Epoch [1786/30000]: Train loss: 1.2761, Valid loss: 1.2541\n",
            "Epoch [1787/30000]: Train loss: 1.2826, Valid loss: 1.2552\n",
            "Epoch [1788/30000]: Train loss: 1.2797, Valid loss: 1.2659\n",
            "Epoch [1789/30000]: Train loss: 1.2851, Valid loss: 1.2755\n",
            "Epoch [1790/30000]: Train loss: 1.2781, Valid loss: 1.2829\n",
            "Epoch [1791/30000]: Train loss: 1.2797, Valid loss: 1.2713\n",
            "Epoch [1792/30000]: Train loss: 1.2866, Valid loss: 1.2522\n",
            "Epoch [1793/30000]: Train loss: 1.2855, Valid loss: 1.2653\n",
            "Epoch [1794/30000]: Train loss: 1.2808, Valid loss: 1.2711\n",
            "Epoch [1795/30000]: Train loss: 1.2827, Valid loss: 1.2634\n",
            "Epoch [1796/30000]: Train loss: 1.2824, Valid loss: 1.2524\n",
            "Epoch [1797/30000]: Train loss: 1.2789, Valid loss: 1.2620\n",
            "Epoch [1798/30000]: Train loss: 1.2831, Valid loss: 1.2589\n",
            "Epoch [1799/30000]: Train loss: 1.2821, Valid loss: 1.2691\n",
            "Epoch [1800/30000]: Train loss: 1.2817, Valid loss: 1.2528\n",
            "Epoch [1801/30000]: Train loss: 1.2792, Valid loss: 1.2645\n",
            "Epoch [1802/30000]: Train loss: 1.2811, Valid loss: 1.2666\n",
            "Epoch [1803/30000]: Train loss: 1.2840, Valid loss: 1.2704\n",
            "Epoch [1804/30000]: Train loss: 1.2815, Valid loss: 1.2750\n",
            "Epoch [1805/30000]: Train loss: 1.2848, Valid loss: 1.2675\n",
            "Epoch [1806/30000]: Train loss: 1.2875, Valid loss: 1.2607\n",
            "Epoch [1807/30000]: Train loss: 1.2825, Valid loss: 1.2610\n",
            "Epoch [1808/30000]: Train loss: 1.2818, Valid loss: 1.2545\n",
            "Epoch [1809/30000]: Train loss: 1.2796, Valid loss: 1.2496\n",
            "Epoch [1810/30000]: Train loss: 1.2834, Valid loss: 1.2745\n",
            "Epoch [1811/30000]: Train loss: 1.2809, Valid loss: 1.2641\n",
            "Epoch [1812/30000]: Train loss: 1.2826, Valid loss: 1.2549\n",
            "Epoch [1813/30000]: Train loss: 1.2787, Valid loss: 1.2593\n",
            "Epoch [1814/30000]: Train loss: 1.2831, Valid loss: 1.2577\n",
            "Epoch [1815/30000]: Train loss: 1.2884, Valid loss: 1.2449\n",
            "Epoch [1816/30000]: Train loss: 1.2842, Valid loss: 1.2439\n",
            "Epoch [1817/30000]: Train loss: 1.2776, Valid loss: 1.2548\n",
            "Epoch [1818/30000]: Train loss: 1.2835, Valid loss: 1.2611\n",
            "Epoch [1819/30000]: Train loss: 1.2801, Valid loss: 1.2540\n",
            "Epoch [1820/30000]: Train loss: 1.2837, Valid loss: 1.2606\n",
            "Epoch [1821/30000]: Train loss: 1.2807, Valid loss: 1.2650\n",
            "Epoch [1822/30000]: Train loss: 1.2835, Valid loss: 1.2633\n",
            "Epoch [1823/30000]: Train loss: 1.2799, Valid loss: 1.2602\n",
            "Epoch [1824/30000]: Train loss: 1.2824, Valid loss: 1.2508\n",
            "Epoch [1825/30000]: Train loss: 1.2839, Valid loss: 1.2697\n",
            "Epoch [1826/30000]: Train loss: 1.2799, Valid loss: 1.2622\n",
            "Epoch [1827/30000]: Train loss: 1.2826, Valid loss: 1.2456\n",
            "Epoch [1828/30000]: Train loss: 1.2818, Valid loss: 1.2763\n",
            "Epoch [1829/30000]: Train loss: 1.2808, Valid loss: 1.2628\n",
            "Epoch [1830/30000]: Train loss: 1.2824, Valid loss: 1.2580\n",
            "Epoch [1831/30000]: Train loss: 1.2806, Valid loss: 1.2567\n",
            "Epoch [1832/30000]: Train loss: 1.2840, Valid loss: 1.2501\n",
            "Epoch [1833/30000]: Train loss: 1.2806, Valid loss: 1.2627\n",
            "Epoch [1834/30000]: Train loss: 1.2807, Valid loss: 1.2422\n",
            "Epoch [1835/30000]: Train loss: 1.2796, Valid loss: 1.2518\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1f55fb7e93b6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMy_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# put your model and data on the same computation device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-a02110f78344>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(train_data, model, config, device)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Set your model to evaluation mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "model = My_Model(input_dim=train_data.shape[1]-1).to(device) # put your model and data on the same computation device.\n",
        "trainer(train_data, model, config, device)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mNnGeuu72qdu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "18b33f2c-ab4c-48f3-a344-e45e69d5d0e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 962.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8. 7. 5. ... 4. 3. 8.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cbbceda4-a53b-48f0-a5f4-b385c45059b1\", \"sample_submission.csv\", 69482)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'Danceability'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([i+17170, p])\n",
        "model.load_state_dict(torch.load(config['save_path']))\n",
        "preds = predict(test_loader, model, device)\n",
        "print(preds)\n",
        "save_pred(preds, 'sample_submission.csv')\n",
        "from google.colab import files\n",
        "files.download('sample_submission.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}